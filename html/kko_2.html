<div class="container">

<table style="width: 100%;"><tr>
<td>kko</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>variable selection for additive model via KKO</h2>

<h3>Description</h3>

<p>The function applys KKO to compute importance scores of components.
</p>


<h3>Usage</h3>

<pre><code class="language-R">kko(
  X,
  y,
  X_k,
  rfn_range = c(2, 3, 4),
  n_stb_tune = 50,
  n_stb = 100,
  cv_folds = 10,
  frac_stb = 1/2,
  nCores_para = 4,
  rkernel = c("laplacian", "gaussian", "cauchy"),
  rk_scale = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>design matrix of additive model; rows are observations and columns are variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>response of addtive model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X_k</code></td>
<td>
<p>knockoffs matrix of design; the same size as X.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rfn_range</code></td>
<td>
<p>a vector of random feature expansion numbers to be tuned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_stb_tune</code></td>
<td>
<p>number of subsampling for tuning random feature numbers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n_stb</code></td>
<td>
<p>number of subsampling for computing importance scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv_folds</code></td>
<td>
<p>the folds of cross-validation for tuning group lasso penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>frac_stb</code></td>
<td>
<p>fraction of subsample size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nCores_para</code></td>
<td>
<p>number of cores for parallelizing subsampling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rkernel</code></td>
<td>
<p>kernel choices. Default is "laplacian". Other choices are "cauchy" and "gaussian".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rk_scale</code></td>
<td>
<p>scale parameter of sampling distribution for random feature expansion. For gaussian kernel, it is standard deviation of gaussian sampling distribution.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list of selection results.
</p>

<table>
<tr>
<td style="text-align: left;">
<code>importance_score</code>  </td>
<td style="text-align: left;">  importance scores of variables for knockoff filtering.  </td>
</tr>
<tr>
<td style="text-align: left;">
<code>selection_frequency</code>  </td>
<td style="text-align: left;"> a 0/1 matrix of selection results on subsamples.
Rows are subsamples, and columns are variables.
The first half columns are variables of design X, and the latter are knockoffs X_k  </td>
</tr>
<tr>
<td style="text-align: left;">
<code>rfn_tune</code>  </td>
<td style="text-align: left;">  tuned optimal random feature number.  </td>
</tr>
<tr>
<td style="text-align: left;">
<code>rfn_range</code>  </td>
<td style="text-align: left;"> range of random feature numbers. </td>
</tr>
<tr>
<td style="text-align: left;">
<code>tune_result</code> </td>
<td style="text-align: left;"> a list of tuning results.  </td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Xiaowu Dai, Xiang Lyu, Lexin Li
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(knockoff)
p=4 # number of predictors
sig_mag=100 # signal strength
n= 100 # sample size
rkernel="laplacian" # kernel choice
s=2  # sparsity, number of nonzero component functions
rk_scale=1  # scaling paramtere of kernel
rfn_range=c(2,3,4)  # number of random features
cv_folds=15  # folds of cross-validation in group lasso
n_stb=10 # number of subsampling for importance scores
n_stb_tune=5 # number of subsampling for tuning random feature number
frac_stb=1/2 # fraction of subsample
nCores_para=2 # number of cores for parallelization
X=matrix(rnorm(n*p),n,p)%*%chol(toeplitz(0.3^(0:(p-1))))   # generate design
X_k = create.second_order(X) # generate knockoff
reg_coef=c(rep(1,s),rep(0,p-s))  # regression coefficient
reg_coef=reg_coef*(2*(rnorm(p)&gt;0)-1)*sig_mag
y=X%*% reg_coef + rnorm(n) # response

kko(X,y,X_k,rfn_range,n_stb_tune,n_stb,cv_folds,frac_stb,nCores_para,rkernel,rk_scale)



</code></pre>


</div>