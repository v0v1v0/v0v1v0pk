<div class="container">

<table style="width: 100%;"><tr>
<td>ad.test.combined</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Combined Anderson-Darling k-Sample Tests
</h2>

<h3>Description</h3>

<p>This function combines several independent Anderson-Darling <code class="reqn">k</code>-sample tests
into one overall test of the hypothesis that the independent samples within 
each block come from a common unspecified distribution, while the common
distributions may vary from block to block.  Both versions of the 
Anderson-Darling test statistic are provided.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ad.test.combined(..., data = NULL,
	method = c("asymptotic", "simulated", "exact"),
	dist = FALSE, Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Either a sequence of several lists, say <code class="reqn">L_1, \ldots, L_M</code> (<code class="reqn">M &gt; 1</code>)
where list <code class="reqn">L_i</code> contains <code class="reqn">k_i &gt; 1</code>  sample vectors of respective 
sizes <code class="reqn">n_{i1}, \ldots, n_{ik_i}</code>, 
where <code class="reqn">n_{ij} &gt; 4</code> is recommended
for reasonable asymptotic <code class="reqn">P</code>-value calculation. 
<code class="reqn">N_i=n_{i1}+\ldots+n_{ik_i}</code>
is the pooled sample size for block <code class="reqn">i</code>,
</p>
<p>or a list of such lists,
</p>
<p>or a formula, like y ~ g | b, where y is a numeric response vector,
g is a factor with levels indicating different treatments and
b is a factor indicating different blocks; y, g, b are or equal length. 
y is split separately for each block level into separate samples 
according to the g levels. The same g level may occur in different blocks. 
The variable names may correspond to variables in an optionally supplied 
data frame via the data = argument,
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>= an optional data frame providing the variables in formula input
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>= <code>c("asymptotic","simulated","exact")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic <code class="reqn">P</code>-value approximation, reasonable 
for P in [0.00001, .99999], linearly extrapolated via 
<code class="reqn">\log(P/(1-P))</code> outside 
that range. See <code>ad.pval</code> for details. 		
The adequacy of the asymptotic <code class="reqn">P</code>-value calculation may be checked using 
<code>pp.kSamples</code>.
</p>
<p><code>"simulated"</code> uses simulation to get <code>Nsim</code> simulated <code class="reqn">AD</code> statistics 
for each block of samples, adding them across blocks component wise to get <code>Nsim</code> 
combined values. These are compared with the observed combined value to obtain the 
estimated	<code class="reqn">P</code>-value.
</p>
<p><code>"exact"</code> uses full enumeration of the test statistic values 
for all sample splits of the pooled samples within each block.
The test statistic vectors for the first 2 blocks are added 
(each component against each component, as in the R <code>outer(x,y,</code> <code>"+")</code> command) 
to get the convolution enumeration for the combined test statistic. The resulting
vector is convoluted against the next block vector in the same fashion, and so on.
It is possible only for small problems, and is attempted only when <code>Nsim</code>
is at least the (conservatively maximal) length 
</p>
<p style="text-align: center;"><code class="reqn">\frac{N_1!}{n_{11}!\ldots n_{1k_1}!}\times\ldots\times 
			\frac{N_M!}{n_{M1}!\ldots n_{Mk_M}!}</code>
</p>

<p>of the final distribution vector. Otherwise, it reverts to the 
simulation method using the provided <code>Nsim</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dist</code></td>
<td>
<p><code>FALSE</code> (default) or <code>TRUE</code>. If <code>TRUE</code>, the 
simulated or fully enumerated convolution vectors 
<code>null.dist1</code> and <code>null.dist2</code> are returned for the respective
test statistic versions. Otherwise, <code>NULL</code> is returned for each.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulation splits to use within 
each block of samples. It is only used when <code>method = "simulated"</code>
or when <code>method =</code> <code>"exact"</code> reverts to <code>method = "simulated"</code>, 
as previously explained. Simulations are independent across blocks, 
using <code>Nsim</code> for each block. <code>Nsim</code> is limited by <code>1e7</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code class="reqn">AD_i</code> is the Anderson-Darling criterion for the i-th block of 
<code class="reqn">k_i</code> samples, 
its standardized test statistic is 
<code class="reqn">T_i = (AD_i - \mu_i)/\sigma_i</code>, with 
<code class="reqn">\mu_i</code> and
<code class="reqn">\sigma_i</code> representing mean and standard deviation of 
<code class="reqn">AD_i</code>. This statistic 
is used to test the hypothesis that the samples in the i-th block all come 
from the same but unspecified continuous distribution function <code class="reqn">F_i(x)</code>.
</p>
<p>The combined Anderson-Darling criterion is 
<code class="reqn">AD_{comb}=AD_1 + \ldots + AD_M</code> and 
<code class="reqn">T_{comb} = </code> <code class="reqn">(AD_{comb} - \mu_c)/\sigma_c</code> is the standardized form, 
where <code class="reqn">\mu_c=\mu_1+\ldots+\mu_M</code> and <code class="reqn">\sigma_c =
\sqrt{\sigma_1^2 +\ldots+\sigma_M^2}</code> 
represent the mean and standard deviation of <code class="reqn">AD_{comb}</code>.
The statistic <code class="reqn">T_{comb}</code> is used to simultaneously 
test whether the samples 
in each block come from the same continuous distribution function 
<code class="reqn">F_i(x), i=1,\ldots,M</code>. 
The unspecified common distribution function <code class="reqn">F_i(x)</code> may change 
from block to block. According to the reference article, two versions
of the test statistic and its corresponding combinations are provided.
</p>
<p>The <code class="reqn">k_i</code> for each block of <code class="reqn">k_i</code>
independent samples may change from block to block.
</p>
<p>NA values are removed and the user is alerted with the total NA count.
It is up to the user to judge whether the removal of NA's is appropriate.
</p>
<p>The continuity assumption can be dispensed with if we deal with 
independent random samples, or if randomization was used in allocating
subjects to samples or treatments, independently from block to block, and if we view
the simulated or exact <code class="reqn">P</code>-values conditionally, given the tie patterns
within each block. Of course, under such randomization any conclusions 
are valid only with respect to the blocks of subjects that were randomly allocated.
The asymptotic <code class="reqn">P</code>-value calculation assumes distribution continuity. No adjustment 
for lack thereof is known at this point. The same comment holds for the means
and standard deviations of respective statistics.
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>test.name</code></td>
<td>
<p><code class="reqn">=</code> <code>"Anderson-Darling"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>number of blocks of samples being compared</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.samples</code></td>
<td>
<p>list of <code>M</code> vectors, each vector giving the sample sizes for 
each block of samples being compared</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nt</code></td>
<td>
<p><code class="reqn">= (N_1,\ldots,N_M)</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.ties</code></td>
<td>
<p>vector giving the number of ties in each the <code>M</code>
comparison blocks</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ad.list</code></td>
<td>
<p>list of <code>M</code> matrices giving the <code>ad</code> results 
for <code>ad.test</code> applied to the samples in each of
the <code>M</code> blocks</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p>vector of means of the <code class="reqn">AD</code> statistic for the  <code>M</code> blocks</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sig</code></td>
<td>
<p>vector of standard deviations of the <code class="reqn">AD</code> statistic for the  <code>M</code> blocks</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ad.c</code></td>
<td>
<p>2 x 3 (2 x 4) matrix containing 
<code class="reqn">AD_{comb}, T_{comb}</code>, asymptotic <code class="reqn">P</code>-value, 
(simulated or exact <code class="reqn">P</code>-value), for each version of the combined test statistic,
version 1 in row 1 and version 2 in row 2</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu.c</code></td>
<td>
<p>mean of <code class="reqn">AD_{comb}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sig.c</code></td>
<td>
<p>standard deviation of <code class="reqn">AD_{comb}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>warning</code></td>
<td>
<p>logical indicator, <code>warning = TRUE</code> when at least one 
<code class="reqn">n_{ij} &lt; 5</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.dist1</code></td>
<td>
<p>simulated or enumerated null distribution of version 1 
of <code class="reqn">AD_{comb}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.dist2</code></td>
<td>
<p>simulated or enumerated null distribution of version 2 
of <code class="reqn">AD_{comb}</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Nsim</code></td>
<td>
<p>the number of simulations used for each block of samples.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>This test is useful in analyzing treatment effects in randomized 
(incomplete) block experiments and in examining performance 
equivalence of several laboratories when presented with different 
test materials for comparison.
</p>


<h3>References</h3>

<p>Scholz, F. W. and Stephens, M. A. (1987), K-sample Anderson-Darling Tests, 
<em>Journal of the American Statistical Association</em>, 
<b>Vol 82, No. 399</b>, 918–924. 
</p>


<h3>See Also</h3>

<p><code>ad.test</code>, <code>ad.pval</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Create two lists of sample vectors.
x1 &lt;- list( c(1, 3, 2, 5, 7), c(2, 8, 1, 6, 9, 4), c(12, 5, 7, 9, 11) )
x2 &lt;- list( c(51, 43, 31, 53, 21, 75), c(23, 45, 61, 17, 60) )
# and a corresponding data frame datx1x2
x1x2 &lt;- c(unlist(x1),unlist(x2))
gx1x2 &lt;- as.factor(c(rep(1,5),rep(2,6),rep(3,5),rep(1,6),rep(2,5)))
bx1x2 &lt;- as.factor(c(rep(1,16),rep(2,11)))
datx1x2 &lt;- data.frame(A = x1x2, G = gx1x2, B = bx1x2)

## Run ad.test.combined.
set.seed(2627)
ad.test.combined(x1, x2, method = "simulated", Nsim = 1000) 
# or with same seed
# ad.test.combined(list(x1, x2), method = "simulated", Nsim = 1000)
# ad.test.combined(A~G|B,data=datx1x2,method="simulated",Nsim=1000)


</code></pre>


</div>