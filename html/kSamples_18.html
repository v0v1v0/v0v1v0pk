<div class="container">

<table style="width: 100%;"><tr>
<td>SteelConfInt</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Simultaneous Confidence Bounds Based on Steel's Multiple Comparison Wilcoxon Tests
</h2>

<h3>Description</h3>

<p>This function inverts pairwise Wilcoxon tests, comparing a common control sample with each of
several treatment samples to provide simultaneous confidence bounds
for the respective shift parameters by which the sampled treatment populations may differ
from the control population. It is assumed that all samples are independent 
and
that the sampled distributions are continuous to avoid ties.
The joint coverage probability for all bounds/intervals is calculated, estimated, or approximated, see
Details. For treatment of ties also see Details.
</p>


<h3>Usage</h3>

<pre><code class="language-R">SteelConfInt(..., data = NULL, conf.level = 0.95, 
	alternative = c("less", "greater", "two.sided"), 
     	method = c("asymptotic", "exact", "simulated"), Nsim = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>Either several sample vectors, say 
<code class="reqn">x_1, \ldots, x_k</code>, 
with <code class="reqn">x_i</code> containing <code class="reqn">n_i</code> sample values.
<code class="reqn">n_i &gt; 4</code> is recommended for reasonable asymptotic 
<code class="reqn">P</code>-value calculation. The pooled sample size is denoted 
by <code class="reqn">N=n_1+\ldots+n_k</code>. The first vector serves as control sample,
the others as treatment samples.
</p>
<p>or a list of such sample vectors.
</p>
<p>or a formula y ~ g, where y contains the pooled sample values 
and g (same length as y) is a factor with levels identifying 
the samples to which the elements of y belong. The lowest factor level
corresponds to the control sample, the other levels to treatment samples. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>= an optional data frame providing the variables in formula y ~ g.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conf.level</code></td>
<td>
<p><code>= 0.95</code> (default) the target joint confidence level for all bounds/intervals.
</p>
<p><code>0 &lt; conf.level &lt; 1</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>= <code>c("less", "greater", "two.sided")</code>, where <code>"less"</code> results in
simultaneous upper confidence bounds for all shift parameters and any negative upper bound
should lead to the rejection of the null hypothesis of all shift parameters 
being zero or positive in favor of at least one being less than zero.
</p>
<p><code>"greater"</code> results in simultaneous lower confidence bounds for all shift parameters 
and any positive lower bound should lead to the rejection of the null hypothesis of all
shift parameters being zero or negative in favor of at least one being greater 
than zero.
</p>
<p><code>"two.sided"</code> results in simultaneous confidence intervals for all shift parameters 
and any interval not straddling zero should lead to the rejection of the null hypothesis 
of all shift parameters being zero in favor of at least one being different from zero.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>= <code>c("asymptotic", "exact", "simulated")</code>, where
</p>
<p><code>"asymptotic"</code> uses only an asymptotic normal approximation 
to approximate the achieved joint coverage probability. 
This calculation is always done.
</p>
<p><code>"exact"</code> uses full enumeration of all sample splits to obtain the exact achieved 
joint coverage probability (see Details).
It is used only when <code>Nsim</code> is at least as large as the number of full enumerations. 
Otherwise, <code>method</code> reverts to <code>"simulated"</code> using the given <code>Nsim</code>.
</p>
<p><code>"simulated"</code> uses <code>Nsim</code> simulated random splits of the 
pooled samples into samples of sizes <code class="reqn">n_1, \ldots, n_k</code>, 
to estimate the achieved joint coverage probability.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Nsim</code></td>
<td>
<p><code>= 10000</code> (default), number of simulated sample splits to use.	
It is only used when <code>method = "simulated"</code>,
or when <code>method = "exact"</code> reverts to <code>method =</code>
<code>"simulated"</code>, as previously explained.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The first sample is treated as control sample with sample size <code class="reqn">n_1</code>. The remaining 
<code class="reqn">s=k-1</code> samples are treatment samples.
Let <code class="reqn">W_{1i}, i=2,\ldots,k</code> denote the respective Wilcoxon statistics comparing the common control sample (index 1)
with each of the <code class="reqn">s</code> treatment samples (indexed by <code class="reqn">i</code>). 
For each comparison of control and treatment <code class="reqn">i</code>
sample
only the observations of the two samples involved are ranked.
By <code class="reqn">W_i=W_{1i}-n_i(n_i+1)/2</code> we denote
the corresponding Mann-Whitney test statistic.
Furthermore, let <code class="reqn">D_{i(j)}</code> denote the <code class="reqn">j</code>-th ordered value (ascending order) of the <code class="reqn">n_1n_i</code>
paired differences between the observations in treatment sample <code class="reqn">i</code> and those of the control
sample. By simple extension of results in Lehmann (2006), pages 87 and 92, the following equations hold, 
relating the null distribution of the 
Mann-Whitney statistics and the joint coverage probabilities of the <code class="reqn">D_{i(j_i)}</code> for any set of
<code class="reqn">j_1,\ldots,j_s</code> with <code class="reqn">1\le j_i \le n_1 n_i</code>.
</p>
<p style="text-align: center;"><code class="reqn">P_\Delta(\Delta_i \le D_{i(j_i)}, i=2,\ldots,k)=P_0(W_i\le j_i -1, i=2,\ldots,k)</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">P_\Delta(\Delta_i \ge D_{i(j_i)}, i=2,\ldots,s)=P_0(W_{i}\le n_1 n_i -j_i, i=2,\ldots,k)</code>
</p>

<p>where <code class="reqn">P_\Delta</code> refers to the distribution under <code class="reqn">\Delta=(\Delta_2,\ldots,\Delta_k)</code>
and <code class="reqn">P_0</code> refers to the joint null distribution of the <code class="reqn">W_i</code> when all sampled 
distributions are the same and continuous. There are <code class="reqn">k-1</code> indices <code class="reqn">j_i</code> that can be manipulated
to affect the achieved confidence level. To limit the computational complexity
standardized versions of the <code class="reqn">W_i</code>, i.e.,  <code class="reqn">(W_i-\mu_i)/\tau_i</code> with 
<code class="reqn">\mu_i</code> and <code class="reqn">\tau_i</code> representing mean and standard deviation of <code class="reqn">W_i</code>,
are used to choose a common value for <code class="reqn">(j_i -1-\mu_i)/\tau_i</code>  (satisfying the 
<code class="reqn">\gamma</code> level) from the multivariate normal approximation 
for the <code class="reqn">W_i</code> (see Miller (1981) and Scholz (2016)), and reduce that 
to integer values for <code class="reqn">j_i</code>, rounding up, rounding down, and rounding to the nearest integer. These
integers  <code class="reqn">j_i</code> are then used in approximating the actual joint probabilities
<code class="reqn">P_0(W_i\le j_i -1, i=2,\ldots,k)</code>, and from these three coverage probabilities 
the one that is closest to the nominal confidence level <code class="reqn">\gamma</code> and <code class="reqn">\ge \gamma</code>
and also also the one that is closest without the restriction <code class="reqn">\ge \gamma</code> are chosen.
</p>
<p>When <code>method = "exact"</code> or <code>= "simulated"</code> is specified, the same process
is used, using either the fully enumerated exact distribution of <code class="reqn">W_i, i=2,\ldots,k</code> (based on a recursive 
version of Chase's sequence as presented in Knuth (2011)) for all sample splits,
or the simulated distribution of <code class="reqn">W_i, i=2,\ldots,k</code>. However, since these distributions are discrete
the starting point before rounding up is the smallest quantile such that the proportion of distribution values less 
or equal to it is at least <code class="reqn">\gamma</code>. The starting point before rounding down is the highest quantile such that 
the proportion of distribution values less 
or equal to it is at most <code class="reqn">\gamma</code>. The third option of rounding to the closest integer is performed using 
the average of the first two.
</p>
<p>Confidence intervals are constructed by using upper and lower confidence bounds, each with
same confidence level of <code class="reqn">(1+\gamma)/2</code>.
</p>
<p>When the original sample data appear to be rounded, and especially when there are ties,
one should widen the computed intervals or bounds by the rounding <code class="reqn">\epsilon</code>, as illustrated
in Lehmann (2006), pages 85 and 94. For example, when all sample values appear to end in one of <code class="reqn">.0, .2, .4, .6, .8</code>,
the rounding <code class="reqn">\epsilon</code> would be <code class="reqn">.2</code>. Ultimately, this is a judgment call for the user. Such widening
of intervals will make the actually achieved confidence level <code class="reqn">\ge</code> the stated achieved level. 
</p>


<h3>Value</h3>

<p>A list of class <code>kSamples</code> with components 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>test.name</code></td>
<td>
<p><code>"Steel.bounds"</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n1</code></td>
<td>
<p>the control sample size <code class="reqn">= n_1</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ns</code></td>
<td>
<p>vector <code class="reqn">(n_2,\ldots,n_k)</code> of the <code class="reqn">s=k-1</code> treatment sample sizes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>size of the pooled sample <code class="reqn">= n_1+\ldots+n_k</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.ties</code></td>
<td>
<p>number of ties in the pooled sample</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bounds</code></td>
<td>
<p>a list of data frames. When <code>method = "asymptotic"</code> is specified, the list
consists of two data frames named <code>conservative.bounds.asymptotic</code>
and <code>closest.bounds.asymptotic</code>. Each data frame consists of <code class="reqn">s</code> rows
corresponding to the <code class="reqn">s</code> shift parameters <code class="reqn">\Delta_i</code> and three columns,
the first column giving the lower bound, the second column the upper bound, while
the first row of the third column states the computed confidence level by asymptotic 
approximation, applying jointly to all <code class="reqn">s</code> sets of bounds. For one-sided bounds
the corresponding other bound is set to <code>Inf</code> or <code>-Inf</code>, respectively.
</p>
<p>In case of <code>conservative.bounds.asymptotic</code> the achieved asymptotic confidence level is 
targeted to be <code class="reqn">\ge</code> <code>conf.level</code>, but closest to it among three possible choices (see Details).
</p>
<p>In the case of <code>closest.bounds.asymptotic</code> the achieved level is targeted to
be closest to <code>conf.level</code>.
</p>
<p>When <code>method = "exact"</code> or <code>method = "simulated"</code>
is specified the list consists in addition of two further data frames named either
</p>
<p><code>conservative.bounds.exact</code> and 
<code>closest.bounds.exact</code> or
</p>
<p><code>conservative.bounds.simulated</code> and 
<code>closest.bounds.simulated</code>. 
</p>
<p>In either case the structure and meaning
of these data frames parallels that of the <code>"asymptotic"</code> case. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>the <code>method</code> used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Nsim</code></td>
<td>
<p>the number of simulations used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>j.LU</code></td>
<td>
<p>an <code class="reqn">s</code> by 4 matrix giving the indices <code class="reqn">j_i</code> used for computing the bounds
<code class="reqn">D_{i(j_i)}</code> for <code class="reqn">\Delta_i, i=1,\ldots, s</code>.
</p>
</td>
</tr>
</table>
<h3>warning</h3>

<p><code>method = "exact"</code> should only be used with caution.
Computation time is proportional to the number of enumerations. 
Experiment with <code>system.time</code> and trial values for
<code>Nsim</code> to get a sense of the required computing time.</p>


<h3>References</h3>

<p>Knuth, D.E. (2011), <em>The Art of Computer Programming, Volume 4A 
Combinatorial Algorithms Part 1</em>, Addison-Wesley
</p>
<p>Lehmann, E.L. (2006),
<em>Nonparametrics, Statistical Methods Based on Ranks, Revised First Edition</em>,
Springer Verlag.
</p>
<p>Miller, Rupert G., Jr. (1981), <em>Simultaneous Statistical Inference, Second Edition</em>,
Springer Verlag, New York.
</p>
<p>Scholz, F.W. (2023), "On Steel's Test with Ties", <a href="https://arxiv.org/abs/2308.05873">https://arxiv.org/abs/2308.05873</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">z1 &lt;- c(103, 111, 136, 106, 122, 114)
z2 &lt;- c(119, 100,  97,  89, 112,  86)
z3 &lt;- c( 89, 132,  86, 114, 114, 125)
z4 &lt;- c( 92, 114,  86, 119, 131,  94)
set.seed(2627)
SteelConfInt(list(z1,z2,z3,z4),conf.level=0.95,alternative="two.sided", 
   method="simulated",Nsim=10000)
# or with same seed
# SteelConfInt(z1,z2,z3,z4,conf.level=0.95,alternative="two.sided", 
#   method="simulated",Nsim=10000)
</code></pre>


</div>