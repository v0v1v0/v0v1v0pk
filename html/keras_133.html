<div class="container">

<table style="width: 100%;"><tr>
<td>image_dataset_from_directory</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Create a dataset from a directory</h2>

<h3>Description</h3>

<p>Generates a <code>tf.data.Dataset</code> from image files in a directory.
</p>


<h3>Usage</h3>

<pre><code class="language-R">image_dataset_from_directory(
  directory,
  labels = "inferred",
  label_mode = "int",
  class_names = NULL,
  color_mode = "rgb",
  batch_size = 32,
  image_size = c(256, 256),
  shuffle = TRUE,
  seed = NULL,
  validation_split = NULL,
  subset = NULL,
  interpolation = "bilinear",
  follow_links = FALSE,
  crop_to_aspect_ratio = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>directory</code></td>
<td>
<p>Directory where the data is located. If labels is
"inferred", it should contain subdirectories, each containing images for a
class. Otherwise, the directory structure is ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>labels</code></td>
<td>
<p>Either "inferred" (labels are generated from the directory
structure), or a list/tuple of integer labels of the same size as the
number of image files found in the directory. Labels should be sorted
according to the alphanumeric order of the image file paths (obtained via
os.walk(directory) in Python).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>label_mode</code></td>
<td>
<p>Valid values:
</p>

<ul>
<li>
<p> 'int': labels are encoded as integers (e.g.
for sparse_categorical_crossentropy loss).
</p>
</li>
<li>
<p> 'categorical': labels are encoded as a categorical vector (e.g. for
categorical_crossentropy loss).
</p>
</li>
<li>
<p> 'binary': labels (there can be only 2) are encoded as float32 scalars
with values 0 or 1 (e.g. for binary_crossentropy).
</p>
</li>
<li> <p><code>NULL</code>: (no labels).
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class_names</code></td>
<td>
<p>Only valid if "labels" is "inferred". This is the explict
list of class names (must match names of subdirectories). Used to control
the order of the classes (otherwise alphanumerical order is used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>color_mode</code></td>
<td>
<p>One of "grayscale", "rgb", "rgba". Default: "rgb". Whether
the images will be converted to have 1, 3, or 4 channels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batch_size</code></td>
<td>
<p>Size of the batches of data. Default: 32.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>image_size</code></td>
<td>
<p>Size to resize images to after they are read from disk.
Defaults to (256, 256). Since the pipeline processes batches of images that
must all have the same size, this must be provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>shuffle</code></td>
<td>
<p>Whether to shuffle the data. Default: TRUE. If set to FALSE,
sorts the data in alphanumeric order.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Optional random seed for shuffling and transformations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validation_split</code></td>
<td>
<p>Optional float between 0 and 1, fraction of data to
reserve for validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>One of "training", "validation", or "both" (available for TF&gt;=2.10).
Only used if validation_split is set. When <code>subset="both"</code>, the utility returns
a tuple of two datasets (the training and validation datasets respectively).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interpolation</code></td>
<td>
<p>String, the interpolation method used when resizing
images. Defaults to bilinear. Supports bilinear, nearest, bicubic, area,
lanczos3, lanczos5, gaussian, mitchellcubic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>follow_links</code></td>
<td>
<p>Whether to visits subdirectories pointed to by symlinks.
Defaults to FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>crop_to_aspect_ratio</code></td>
<td>
<p>If <code>TRUE</code>, resize the images without aspect ratio
distortion. When the original aspect ratio differs from the target aspect
ratio, the output image will be cropped so as to return the largest
possible window in the image (of size image_size) that matches the target
aspect ratio. By default (crop_to_aspect_ratio=False), aspect ratio may not
be preserved.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Legacy arguments</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If your directory structure is:
</p>
<div class="sourceCode"><pre>main_directory/
...class_a/
......a_image_1.jpg
......a_image_2.jpg
...class_b/
......b_image_1.jpg
......b_image_2.jpg
</pre></div>
<p>Then calling <code>image_dataset_from_directory(main_directory, labels='inferred')</code>
will return a <code>tf.data.Dataset</code> that yields batches of images from the
subdirectories class_a and class_b, together with labels 0 and 1 (0
corresponding to class_a and 1 corresponding to class_b).
</p>
<p>Supported image formats: jpeg, png, bmp, gif. Animated gifs are truncated to
the first frame.
</p>


<h3>Value</h3>

<p>A tf.data.Dataset object. If label_mode is <code>NULL</code>, it yields float32
tensors of shape <code style="white-space: pre;">⁠(batch_size, image_size[1], image_size[2], num_channels)⁠</code>,
encoding images (see below for rules regarding <code>num_channels</code>).
</p>
<p>Otherwise, it yields pairs of <code style="white-space: pre;">⁠(images, labels)⁠</code>, where images has shape
<code style="white-space: pre;">⁠(batch_size, image_size[1], image_size[2], num_channels)⁠</code>, and labels
follows the format described below.
</p>
<p>Rules regarding labels format:
</p>

<ul>
<li>
<p> if label_mode is int, the labels are an int32 tensor of shape
<code>(batch_size)</code>.
</p>
</li>
<li>
<p> if label_mode is binary, the labels are a float32 tensor of 1s and 0s of
shape <code style="white-space: pre;">⁠(batch_size, 1)⁠</code>.
</p>
</li>
<li>
<p> if label_mode is categorial, the labels are a float32 tensor of shape
<code style="white-space: pre;">⁠(batch_size, num_classes)⁠</code>, representing a one-hot encoding of the class
index.
</p>
</li>
</ul>
<p>Rules regarding number of channels in the yielded images:
</p>

<ul>
<li>
<p> if color_mode is grayscale, there's 1 channel in the image tensors.
</p>
</li>
<li>
<p> if color_mode is rgb, there are 3 channel in the image tensors.
</p>
</li>
<li>
<p> if color_mode is rgba, there are 4 channel in the image tensors.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory">https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory</a>
</p>


</div>