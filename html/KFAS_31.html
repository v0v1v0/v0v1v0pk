<div class="container">

<table style="width: 100%;"><tr>
<td>rstandard.KFS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Extract Standardized Residuals from KFS output</h2>

<h3>Description</h3>

<p>Extract Standardized Residuals from KFS output
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'KFS'
rstandard(
  model,
  type = c("recursive", "pearson", "state"),
  standardization_type = c("marginal", "cholesky"),
  zerotol = 0,
  expected = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>KFS object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>Type of residuals. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardization_type</code></td>
<td>
<p>Type of standardization. Either <code>"marginal"</code>
(default) for marginal standardization or  <code>"cholesky"</code> for Cholesky-type standardization.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>zerotol</code></td>
<td>
<p>Tolerance parameter for positivity checking in standardization. Default is zero.
The values of D &lt;= zerotol * max(D, 0) are deemed to zero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expected</code></td>
<td>
<p>Logical value defining the approximation of H_t in case of Gamma
and negative binomial distribution. Default is <code>FALSE</code> which matches the
algorithm of Durbin &amp; Koopman (1997), whereas <code>TRUE</code> uses the expected value
of observations in the equations, leading to results which match with <code>glm</code> (where applicable).
The latter case was the default behaviour of KFAS before version 1.3.8.
Essentially this is the difference between observed and expected information.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Ignored.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For object of class KFS with fully Gaussian observations, several
types of standardized residuals can be computed. Also the standardization
for multivariate residuals can be done either by Cholesky decomposition
<code class="reqn">L^{-1}_t residual_t,</code> or component-wise
<code class="reqn">residual_t/sd(residual_t),</code>.
</p>

<ul>
<li>
<p> "recursive": For Gaussian models the vector standardized one-step-ahead prediction
residuals are defined as
</p>
<p style="text-align: center;"><code class="reqn">v_{t,i}/\sqrt{F_{i,t}},</code>
</p>
<p> with residuals
being undefined in diffuse phase. Note that even in multivariate case these
standardized residuals coincide with the ones obtained from the Kalman
filter without the sequential processing (which is not true for the
non-standardized innovations).
For non-Gaussian models the vector standardized recursive residuals are obtained as
</p>
<p style="text-align: center;"><code class="reqn">L^{-1}_t (y_{t}-\mu_{t}),</code>
</p>
<p> where
<code class="reqn">L_t</code> is the lower triangular matrix from Cholesky decomposition
of <code class="reqn">Var(y_t|y_{t-1},\ldots,y_1)</code>. Computing these for large
non-Gaussian models can be time consuming as filtering is needed.
</p>
<p>For Gaussian models the component-wise standardized one-step-ahead prediction
residuals are defined as
</p>
<p style="text-align: center;"><code class="reqn">v_{t}/\sqrt{diag(F_{t})},</code>
</p>
<p> where <code class="reqn">v_{t}</code> and
<code class="reqn">F_{t}</code> are based on the standard multivariate processing.
For non-Gaussian models these are obtained as
</p>
<p style="text-align: center;"><code class="reqn">(y_{t}-\mu_{t})/\sqrt{diag(F_t)},</code>
</p>
<p> where
<code class="reqn">F_t=Var(y_t|y_{t-1},\ldots,y_1)</code>.
</p>
</li>
<li>
<p> "state":  Residuals based on the smoothed state disturbance terms
<code class="reqn">\eta</code> are defined as </p>
<p style="text-align: center;"><code class="reqn">L^{-1}_t \hat \eta_t, \quad
  t=1,\ldots,n,</code>
</p>
<p> where <code class="reqn">L_t</code> is
either the lower triangular matrix from Cholesky decomposition of
<code class="reqn">Var(\hat\eta_t) = Q_t - V_{\eta,t}</code>, or the diagonal of the same
matrix.
</p>
</li>
<li>
<p> "pearson":  Standardized Pearson residuals
</p>
<p style="text-align: center;"><code class="reqn">L^{-1}_t(y_{t}-\theta_{i}), \quad t=1,\ldots,n,</code>
</p>
<p> where
<code class="reqn">L_t</code> is the lower triangular matrix from Cholesky decomposition
of <code class="reqn">Var(\hat\mu_t) = H_t - V_{\mu,t}</code>, or the diagonal of the same
matrix. For Gaussian models, these coincide with the standardized smoothed
<code class="reqn">\epsilon</code> disturbance residuals
(as <code class="reqn">V_{\mu,t} = V_{\epsilon,t}</code>),
and for generalized linear models
these coincide with the standardized Pearson residuals (hence the name).
</p>
</li>
</ul>
<p>Note that the variance estimates from <code>KFS</code> are of form Var(x | y),
e.g., <code>V_eps</code> from <code>KFS</code> is <code class="reqn">Var(\epsilon_t | Y)</code>
and matches with equation 4.69 in Section 4.5.3 of Durbin and Koopman (2012).
(in case of univariate Gaussian model). But for the standardization we need
Var(E(x | y)) (e.g., Var(<code>epshat</code>) which we get with the law
of total variance as <code class="reqn">H_t - V_eps</code> for example.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Replication of residual plot of Section 8.2 of Durbin and Koopman (2012)
model &lt;- SSModel(log(drivers) ~ SSMtrend(1, Q = list(NA))+
    SSMseasonal(period = 12, sea.type = "trigonometric", Q = NA),
  data = Seatbelts, H = NA)

updatefn &lt;- function(pars, model){
  model$H[] &lt;- exp(pars[1])
  diag(model$Q[, , 1]) &lt;- exp(c(pars[2], rep(pars[3], 11)))
  model
}

fit &lt;- fitSSM(model = model,
  inits = log(c(var(log(Seatbelts[, "drivers"])), 0.001, 0.0001)),
  updatefn = updatefn)

# tiny differences due to different optimization algorithms
setNames(c(diag(fit$model$Q[,,1])[1:2], fit$model$H[1]),
  c("level", "seasonal", "irregular"))

out &lt;- KFS(fit$model, smoothing = c("state", "mean", "disturbance"))

plot(cbind(
  recursive = rstandard(out),
  irregular = rstandard(out, "pearson"),
  state = rstandard(out, "state")[,1]),
  main = "recursive and state residuals", type = "h")

# Figure 2.8 in DK2012
model_Nile &lt;- SSModel(Nile ~
    SSMtrend(1, Q = list(matrix(NA))), H = matrix(NA))
model_Nile &lt;- fitSSM(model_Nile, c(log(var(Nile)), log(var(Nile))),
  method = "BFGS")$model

out_Nile &lt;- KFS(model_Nile,  smoothing = c("state", "mean", "disturbance"))

par(mfrow = c(2, 2))
res_p &lt;- rstandard(out_Nile, "pearson")
ts.plot(res_p)
abline(a = 0, b= 0, lty = 2)
hist(res_p, freq = FALSE)
lines(density(res_p))
res_s &lt;- rstandard(out_Nile, "state")
ts.plot(res_s)
abline(a = 0, b= 0, lty = 2)
hist(res_s, freq = FALSE)
lines(density(res_s))

</code></pre>


</div>