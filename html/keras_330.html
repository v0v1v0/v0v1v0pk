<div class="container">

<table style="width: 100%;"><tr>
<td>layer_alpha_dropout</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Applies Alpha Dropout to the input.</h2>

<h3>Description</h3>

<p>Alpha Dropout is a dropout that keeps mean and variance of inputs to their
original values, in order to ensure the self-normalizing property even after
this dropout.
</p>


<h3>Usage</h3>

<pre><code class="language-R">layer_alpha_dropout(object, rate, noise_shape = NULL, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li>
<p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li>
<p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li>
<p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rate</code></td>
<td>
<p>float, drop probability (as with <code>layer_dropout()</code>). The
multiplicative noise will have standard deviation <code>sqrt(rate / (1 - rate))</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noise_shape</code></td>
<td>
<p>Noise shape</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>An integer to use as random seed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>standard layer arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Alpha Dropout fits well to Scaled Exponential Linear Units by randomly
setting activations to the negative saturation value.
</p>


<h3>Input shape</h3>

<p>Arbitrary. Use the keyword argument <code>input_shape</code> (list
of integers, does not include the samples axis) when using this layer as
the first layer in a model.
</p>


<h3>Output shape</h3>

<p>Same shape as input.
</p>


<h3>References</h3>


<ul><li> <p><a href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a>
</p>
</li></ul>
<h3>See Also</h3>

<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/AlphaDropout">https://www.tensorflow.org/api_docs/python/tf/keras/layers/AlphaDropout</a>
</p>
<p>Other noise layers: 
<code>layer_gaussian_dropout()</code>,
<code>layer_gaussian_noise()</code>
</p>


</div>