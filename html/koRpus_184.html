<div class="container">

<table style="width: 100%;"><tr>
<td>readability</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Measure readability</h2>

<h3>Description</h3>

<p>These methods calculate several readability indices.
</p>


<h3>Usage</h3>

<pre><code class="language-R">readability(txt.file, ...)

## S4 method for signature 'kRp.text'
readability(
  txt.file,
  hyphen = NULL,
  index = c("ARI", "Bormuth", "Coleman", "Coleman.Liau", "Dale.Chall",
    "Danielson.Bryan", "Dickes.Steiwer", "DRP", "ELF", "Farr.Jenkins.Paterson", "Flesch",
    "Flesch.Kincaid", "FOG", "FORCAST", "Fucks", "Gutierrez", "Harris.Jacobson",
    "Linsear.Write", "LIX", "nWS", "RIX", "SMOG", "Spache", "Strain", "Traenkle.Bailer",
    "TRI", "Tuldava", "Wheeler.Smith"),
  parameters = list(),
  word.lists = list(Bormuth = NULL, Dale.Chall = NULL, Harris.Jacobson = NULL, Spache =
    NULL),
  fileEncoding = "UTF-8",
  sentc.tag = "sentc",
  nonword.class = "nonpunct",
  nonword.tag = c(),
  quiet = FALSE,
  keep.input = NULL,
  as.feature = FALSE
)

## S4 method for signature 'missing'
readability(txt.file, index)

## S4 method for signature 'kRp.readability,ANY,ANY,ANY'
x[i]

## S4 method for signature 'kRp.readability'
x[[i]]
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>txt.file</code></td>
<td>
<p>An object of class <code>kRp.text</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments for the generics.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hyphen</code></td>
<td>
<p>An object of class <code>kRp.hyphen</code>. If <code>NULL</code>,
the text will be hyphenated automatically. All syllable handling will
be skipped automatically if it's not needed for the selected indices.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>index</code></td>
<td>
<p>A character vector,
indicating which indices should actually be computed. If set to <code>"all"</code>, then all available indices
will be tried (meaning all variations of all measures). If set to <code>"fast"</code>,
a subset of the default values is used that is
known to compute fast (currently,
this only excludes "FOG"). You can also set it to <code>"validation"</code> to get information on the current
status of validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameters</code></td>
<td>
<p>A list with named magic numbers,
defining the relevant parameters for each index. If none are given,
the default values are used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>word.lists</code></td>
<td>
<p>A named list providing the word lists for indices which need one. If <code>NULL</code> or missing,
the indices will be
skipped and a warning is giving. Actual word lists can be provided as either a vector (or matrix or data.frame with only one column),
or as a file name, where this file must contain one word per line. Alternatively,
you can provide the number of words which are not
on the list, directly.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fileEncoding</code></td>
<td>
<p>A character string defining the character encoding of the <code>word.lists</code> in case they are provided as files,
like <code>"Latin1"</code> or <code>"UTF-8"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sentc.tag</code></td>
<td>
<p>A character vector with POS tags which indicate a sentence ending. The default value <code>"sentc"</code> has special meaning and
will cause the result of <code>kRp.POS.tags(lang, tags="sentc",
      list.tags=TRUE)</code> to be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nonword.class</code></td>
<td>
<p>A character vector with word classes which should be ignored for readability analysis. The default value
<code>"nonpunct"</code> has special meaning and will cause the result of <code>kRp.POS.tags(lang,
      tags=c("punct","sentc"), list.classes=TRUE)</code>
to be used. Will only be of consequence if <code>hyphen</code> is not set!</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nonword.tag</code></td>
<td>
<p>A character vector with POS tags which should be ignored for readability analysis. Will only be
of consequence if <code>hyphen</code> is not set!</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quiet</code></td>
<td>
<p>Logical. If <code>FALSE</code>, short status messages will be shown.
<code>TRUE</code> will also suppress all potential warnings regarding the validation status of measures.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep.input</code></td>
<td>
<p>Logical. If <code>FALSE</code>,
neither the object provided by (or generated from) <code>txt.file</code> nor
<code>hyphen</code> will be kept in the output object. By default (<code>NULL</code>) they are kept if the input was not already of the needed object class
(e.g., <code>kRp.text</code>) or missing,
to allow for re-use without the need to tag or hyphenate the text again.
If <code>TRUE</code>, they are always kept. In cases where you want smaller object sizes,
set this to <code>FALSE</code> to always drop these slots.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>as.feature</code></td>
<td>
<p>Logical,
whether the output should be just the analysis results or the input object with
the results added as a feature. Use <code>corpusReadability</code>
to get the results from such an aggregated object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An object of class <code>kRp.readability</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>i</code></td>
<td>
<p>Defines the row selector (<code>[</code>) or the name to match (<code>[[</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>In the following formulae, <code class="reqn">W</code> stands for the number of words,
<code class="reqn">St</code> for the number of sentences, <code class="reqn">C</code> for the number of
characters (usually meaning letters), <code class="reqn">Sy</code> for the number of syllables,
<code class="reqn">W_{3Sy}</code> for the number of words with at least three syllables,
<code class="reqn">W_{&lt;3Sy}</code> for the number of words with less than three syllables, <code class="reqn">W^{1Sy}</code>
for words with exactly one syllable,
<code class="reqn">W_{6C}</code> for the number of words with at least six letters, and <code class="reqn">W_{-WL}</code> for the number
of words which are not on a certain word list (explained where needed).
</p>

<dl>
<dt>
<code>"ARI"</code>:</dt>
<dd>
<p><em>Automated Readability Index</em>:
</p>
<p style="text-align: center;"><code class="reqn">ARI = 0.5 \times \frac{W}{St} + 4.71 \times \frac{C}{W} - 21.43</code>
</p>

<p>If <code>parameters</code> is set to <code>ARI="NRI"</code>,
the revised parameters from the Navy Readability Indexes are used:
</p>
<p style="text-align: center;"><code class="reqn">ARI_{NRI} = 0.4 \times \frac{W}{St} + 6 \times \frac{C}{W} - 27.4</code>
</p>

<p>If <code>parameters</code> is set to <code>ARI="simple"</code>,
the simplified formula is calculated:
</p>
<p style="text-align: center;"><code class="reqn">ARI_{simple} = \frac{W}{St} + 9 \times \frac{C}{W}</code>
</p>

<p>Wrapper function: <code>ARI</code>
</p>
</dd>
<dt>
<code>"Bormuth"</code>:</dt>
<dd>
<p><em>Bormuth Mean Cloze</em> &amp; Grade Placement:
</p>
<p style="text-align: center;"><code class="reqn">
     B_{MC} = 0.886593 - \left( 0.08364 \times \frac{C}{W} \right) +  0.161911 \times \left(\frac{W_{-WL}}{W} \right)^3
     </code>
</p>

<p style="text-align: center;"><code class="reqn">
      - 0.21401 \times \left(\frac{W}{St} \right) + 0.000577 \times \left(\frac{W}{St} \right)^2
     </code>
</p>

<p style="text-align: center;"><code class="reqn">
      - 0.000005 \times \left(\frac{W}{St} \right)^3
     </code>
</p>

<p><strong>Note:</strong> This index needs the long Dale-Chall list of 3000 familiar (english) words to compute <code class="reqn">W_{-WL}</code>. That is,
you must have a copy of
this word list and provide it via the <code>word.lists=list(Bormuth=&lt;your.list&gt;)</code> parameter!
</p>
<p style="text-align: center;"><code class="reqn">
     B_{GP} = 4.275 + 12.881 \times B_{MC} - (34.934 \times B_{MC}^2) + (20.388 \times B_{MC}^3)
     </code>
</p>

<p style="text-align: center;"><code class="reqn">
      + (26.194C - 2.046 C_{CS}^2) - (11.767 C_{CS}^3) - (44.285 \times B_{MC} \times C_{CS})
     </code>
</p>

<p style="text-align: center;"><code class="reqn">
      + (97.620 \times (B_{MC} \times C_{CS})^2) - (59.538 \times (B_{MC} \times C_{CS})^3)</code>
</p>

<p>Where <code class="reqn">C_{CS}</code> represents the cloze criterion score (35% by default).
</p>
<p>Wrapper function: <code>bormuth</code>
</p>
</dd>
<dt>
<code>"Coleman"</code>:</dt>
<dd>
<p><em>Coleman's Readability Formulas</em>:
</p>
<p style="text-align: center;"><code class="reqn">C_1 = 1.29 \times \left( \frac{100 \times W^{1Sy}}{W} \right) - 38.45</code>
</p>

<p style="text-align: center;"><code class="reqn">C_2 = 1.16 \times \left( \frac{100 \times W^{1Sy}}{W} \right) + 1.48 \times \left( \frac{100 \times St}{W} \right) - 37.95</code>
</p>

<p style="text-align: center;"><code class="reqn">C_3 = 1.07 \times \left( \frac{100 \times W^{1Sy}}{W} \right) + 1.18 \times \left( \frac{100 \times St}{W} \right)
       + 0.76 \times \left( \frac{100 \times W_{pron}}{W} \right) - 34.02</code>
</p>

<p style="text-align: center;"><code class="reqn">C_4 = 1.04 \times \left( \frac{100 \times W^{1Sy}}{W} \right) + 1.06 \times \left( \frac{100 \times St}{W} \right) \\
       + 0.56 \times \left( \frac{100 \times W_{pron}}{W} \right) - 0.36  \times \left( \frac{100 \times W_{prep}}{W} \right) - 26.01</code>
</p>

<p>Where <code class="reqn">W_{pron}</code> is the number of pronouns,
and <code class="reqn">W_{prep}</code> the number of prepositions.
</p>
<p>Wrapper function: <code>coleman</code>
</p>
</dd>
<dt>
<code>"Coleman.Liau"</code>:</dt>
<dd>
<p>First estimates cloze percentage,
then calculates grade equivalent:
</p>
<p style="text-align: center;"><code class="reqn">CL_{ECP} = 141.8401 - 0.214590 \times \frac{100 \times C}{W} + 1.079812 \times \frac{100 \times St}{W}</code>
</p>

<p style="text-align: center;"><code class="reqn">CL_{grade} = -27.4004 \times \frac{CL_{ECP}}{100} + 23.06395</code>
</p>

<p>The short form is also calculated:
</p>
<p style="text-align: center;"><code class="reqn">CL_{short} = 5.88 \times \frac{C}{W} - 29.6 \times \frac{St}{W} - 15.8</code>
</p>

<p>Wrapper function: <code>coleman.liau</code>
</p>
</dd>
<dt>
<code>"Dale.Chall"</code>:</dt>
<dd>
<p><em>New Dale-Chall Readability Formula</em>. By default the revised formula (1995) is calculated:
</p>
<p style="text-align: center;"><code class="reqn">DC_{new} = 64 - 0.95 \times{} \frac{100 \times{} W_{-WL}}{W} - 0.69 \times{} \frac{W}{St} </code>
</p>

<p>This will result in a cloze score which is then looked up in a grading table. If <code>parameters</code> is set to <code>Dale.Chall="old"</code>,
the original formula (1948) is used:
</p>
<p style="text-align: center;"><code class="reqn">DC_{old} = 0.1579 \times{} \frac{100 \times{} W_{-WL}}{W} + 0.0496 \times{} \frac{W}{St} + 3.6365 </code>
</p>

<p>If <code>parameters</code> is set to <code>Dale.Chall="PSK"</code>,
the revised parameters by Powers-Sumner-Kearl (1958) are used:
</p>
<p style="text-align: center;"><code class="reqn">DC_{PSK} =  0.1155 \times{} \frac{100 \times{} W_{-WL}}{W} + 0.0596  \times{} \frac{W}{St} + 3.2672 </code>
</p>

<p><strong>Note:</strong> This index needs the long Dale-Chall list of 3000 familiar (english) words to compute <code class="reqn">W_{-WL}</code>. That is,
you must have a copy of
this word list and provide it via the <code>word.lists=list(Dale.Chall=&lt;your.list&gt;)</code> parameter!
</p>
<p>Wrapper function: <code>dale.chall</code>
</p>
</dd>
<dt>
<code>"Danielson.Bryan"</code>:</dt>
<dd>
<p style="text-align: center;"><code class="reqn">DB_1 = \left( 1.0364 \times \frac{C}{Bl} \right) + \left( 0.0194 \times \frac{C}{St} \right) - 0.6059</code>
</p>

<p style="text-align: center;"><code class="reqn">DB_2 = 131.059 - \left( 10.364 \times \frac{C}{Bl} \right) - \left( 0.194 \times \frac{C}{St} \right)</code>
</p>

<p>Where <code class="reqn">Bl</code> means blanks between words,
which is not really counted in this implementation, but estimated
by <code class="reqn">words - 1</code>. <code class="reqn">C</code> is interpreted as literally all characters.
</p>
<p>Wrapper function: <code>danielson.bryan</code>
</p>
</dd>
<dt>
<code>"Dickes.Steiwer"</code>:</dt>
<dd>
<p><em>Dickes-Steiwer Handformel</em>:
</p>
<p style="text-align: center;"><code class="reqn">DS = 235.95993 - \left( 73.021 \times \frac{C}{W} \right) - \left(12.56438 \times \frac{W}{St} \right) - \left(50.03293 \times TTR \right)</code>
</p>

<p>Where <code class="reqn">TTR</code> refers to the type-token ratio,
which will be calculated case-insensitive by default.
</p>
<p>Wrapper function: <code>dickes.steiwer</code>
</p>
</dd>
<dt>
<code>"DRP"</code>:</dt>
<dd>
<p><em>Degrees of Reading Power</em>. Uses the Bormuth Mean Cloze Score:
</p>
<p style="text-align: center;"><code class="reqn">DRP = (1 - B_{MC}) \times 100</code>
</p>

<p>This formula itself has no parameters.
<strong>Note:</strong> The Bormuth index needs the long Dale-Chall list of 3000 familiar (english) words to compute <code class="reqn">W_{-WL}</code>.
That is,
you must have a copy of this word list and provide it via the <code>word.lists=list(Bormuth=&lt;your.list&gt;)</code> parameter!
Wrapper function: <code>DRP</code>
</p>
</dd>
<dt>
<code>"ELF"</code>:</dt>
<dd>
<p>Fang's <em>Easy Listening Formula</em>:
</p>
<p style="text-align: center;"><code class="reqn">ELF = \frac{W_{2Sy}}{St}</code>
</p>

<p>Wrapper function: <code>ELF</code>
</p>
</dd>
<dt>
<code>"Farr.Jenkins.Paterson"</code>:</dt>
<dd>
<p>A simplified version of Flesch Reading Ease:
</p>
<p style="text-align: center;"><code class="reqn">FJP = -31.517 - 1.015 \times \frac{W}{St} + 1.599 \times \frac{W^{1Sy}}{W}</code>
</p>

<p>If <code>parameters</code> is set to <code>Farr.Jenkins.Paterson="PSK"</code>,
the revised parameters by Powers-Sumner-Kearl (1958) are used:
</p>
<p style="text-align: center;"><code class="reqn">FJP_{PSK} = 8.4335 + 0.0923 \times \frac{W}{St} - 0.0648 \times \frac{W^{1Sy}}{W}</code>
</p>

<p>Wrapper function: <code>farr.jenkins.paterson</code>
</p>
</dd>
<dt>
<code>"Flesch"</code>:</dt>
<dd>
<p><em>Flesch Reading Ease</em>:
</p>
<p style="text-align: center;"><code class="reqn">F_{EN} = 206.835 - 1.015 \times \frac{W}{St} - 84.6 \times \frac{Sy}{W}</code>
</p>

<p>Certain internationalisations of the parameters are also implemented. They can be used by setting
the <code>Flesch</code> parameter to one of the following language abbreviations.
</p>
<p><code>"de"</code> (Amstad's Verständlichkeitsindex):
</p>
<p style="text-align: center;"><code class="reqn">F_{DE} = 180 - \frac{W}{St} - 58.5 \times \frac{Sy}{W}</code>
</p>

<p><code>"es"</code> (Fernandez-Huerta):
</p>
<p style="text-align: center;"><code class="reqn">F_{ES} = 206.835 - 1.02 \times \frac{W}{St} - 60 \times \frac{Sy}{W}</code>
</p>

<p><code>"es-s"</code> (Szigriszt):
</p>
<p style="text-align: center;"><code class="reqn">F_{ES S} = 206.835 - \frac{W}{St} - 62.3 \times \frac{Sy}{W}</code>
</p>

<p><code>"nl"</code> (Douma):
</p>
<p style="text-align: center;"><code class="reqn">F_{NL} = 206.835 - 0.93 \times \frac{W}{St} - 77 \times \frac{Sy}{W}</code>
</p>

<p><code>"nl-b"</code> (Brouwer Leesindex):
</p>
<p style="text-align: center;"><code class="reqn">F_{NL B} = 195 - 2 \times \frac{W}{St} - 67 \times \frac{Sy}{W}</code>
</p>

<p><code>"fr"</code> (Kandel-Moles):
</p>
<p style="text-align: center;"><code class="reqn">F_{FR} = 209 - 1.15 \times \frac{W}{St} - 68 \times \frac{Sy}{W}</code>
</p>

<p>If <code>parameters</code> is set to <code>Flesch="PSK"</code>,
the revised parameters by Powers-Sumner-Kearl (1958) are used
to calculate a grade level:
</p>
<p style="text-align: center;"><code class="reqn">F_{PSK} = 0.0778 \times \frac{W}{St} + 4.55 \times \frac{Sy}{W} - 2.2029</code>
</p>

<p>Wrapper function: <code>flesch</code>
</p>
</dd>
<dt>
<code>"Flesch.Kincaid"</code>:</dt>
<dd>
<p><em>Flesch-Kincaid Grade Level</em>:
</p>
<p style="text-align: center;"><code class="reqn">FK = 0.39 \times \frac{W}{St} + 11.8 \times \frac{Sy}{W} - 15.59</code>
</p>

<p>Wrapper function: <code>flesch.kincaid</code>
</p>
</dd>
<dt>
<code>"FOG"</code>:</dt>
<dd>
<p>Gunning <em>Frequency of Gobbledygook</em>:
</p>
<p style="text-align: center;"><code class="reqn">FOG = 0.4 \times \left( \frac{W}{St} + \frac{100 \times W_{3Sy}}{W} \right)</code>
</p>

<p>If <code>parameters</code> is set to <code>FOG="PSK"</code>,
the revised parameters by Powers-Sumner-Kearl (1958) are used:
</p>
<p style="text-align: center;"><code class="reqn">FOG_{PSK} = 3.0680 + \left( 0.0877 \times \frac{W}{St} \right) + \left(0.0984 \times \frac{100 \times W_{3Sy}}{W} \right)</code>
</p>

<p>If <code>parameters</code> is set to <code>FOG="NRI"</code>,
the new FOG count from the Navy Readability Indexes is used:
</p>
<p style="text-align: center;"><code class="reqn">FOG_{new} = \frac{\frac{W_{&lt;3Sy} + (3 * W_{3Sy})}{\frac{100 \times St}{W}} - 3}{2}</code>
</p>

<p>If the text was POS-tagged accordingly,
proper nouns and combinations of only easy words will not be counted as hard words,
and the syllables of verbs ending in "-ed",
"-es" or "-ing" will be counted without these suffixes.
</p>
<p>Due to the need to re-hyphenate combined words after splitting them up,
this formula takes considerably longer to compute than most others.
If will be omitted if you set <code>index="fast"</code> instead of the default.
</p>
<p>Wrapper function: <code>FOG</code>
</p>
</dd>
<dt>
<code>"FORCAST"</code>:</dt>
<dd>
<p style="text-align: center;"><code class="reqn">FORCAST = 20 - \frac{W^{1Sy} \times \frac{150}{W}}{10}</code>
</p>

<p>If <code>parameters</code> is set to <code>FORCAST="RGL"</code>,
the parameters for the precise reading grade level are used (see Klare, 1975, pp. 84–85):
</p>
<p style="text-align: center;"><code class="reqn">FORCAST_{RGL} = 20.43 - 0.11 \times W^{1Sy} \times \frac{150}{W}</code>
</p>

<p>Wrapper function: <code>FORCAST</code>
</p>
</dd>
<dt>
<code>"Fucks"</code>:</dt>
<dd>
<p>Fucks' <em>Stilcharakteristik</em> (Fucks, 1955,
as cited in Briest, 1974):
</p>
<p style="text-align: center;"><code class="reqn">Fucks = \frac{Sy}{W} \times \frac{W}{St}</code>
</p>

<p>This simple formula has no parameters.
</p>
<p>Wrapper function: <code>fucks</code>
</p>
</dd>
<dt>
<code>"Gutierrez"</code>:</dt>
<dd>
<p>Gutiérrez de Polini's <em>Fórmula de comprensibilidad</em> (Gutiérrez,
1972, as cited in Fernández, 2016)
for Spanish:
</p>
<p style="text-align: center;"><code class="reqn">Gutierrez = 95.2 - \frac{9.7 \times C}{W} - \frac{0.35 \times W}{St}</code>
</p>

<p>Wrapper function: <code>gutierrez</code>
</p>
</dd>
<dt>
<code>"Harris.Jacobson"</code>:</dt>
<dd>
<p><em>Revised Harris-Jacobson Readability Formulas</em> (Harris &amp; Jacobson,
1974):
For primary-grade material:
</p>
<p style="text-align: center;"><code class="reqn">HJ_1 = 0.094 \times \frac{100 \times{} W_{-WL}}{W} + 0.168 \times \frac{W}{St} + 0.502</code>
</p>

<p>For material above third grade:
</p>
<p style="text-align: center;"><code class="reqn">HJ_2 = 0.140 \times \frac{100 \times{} W_{-WL}}{W} + 0.153 \times \frac{W}{St} + 0.560</code>
</p>

<p>For material below forth grade:
</p>
<p style="text-align: center;"><code class="reqn">HJ_3 = 0.158 \times \frac{W}{St} + 0.055 \times \frac{100 \times{} W_{6C}}{W} + 0.355</code>
</p>

<p>For material below forth grade:
</p>
<p style="text-align: center;"><code class="reqn">HJ_4 = 0.070 \times \frac{100 \times{} W_{-WL}}{W} + 0.125 \times \frac{W}{St} + 0.037 \times \frac{100 \times{} W_{6C}}{W} + 0.497</code>
</p>

<p>For material above third grade:
</p>
<p style="text-align: center;"><code class="reqn">HJ_5 = 0.118 \times \frac{100 \times{} W_{-WL}}{W} + 0.134 \times \frac{W}{St} + 0.032 \times \frac{100 \times{} W_{6C}}{W} + 0.424</code>
</p>

<p><strong>Note:</strong> This index needs the short Harris-Jacobson word list for grades 1 and 2 (english) to compute <code class="reqn">W_{-WL}</code>. That is,
you must have a copy of
this word list and provide it via the <code>word.lists=list(Harris.Jacobson=&lt;your.list&gt;)</code> parameter!
</p>
<p>Wrapper function: <code>harris.jacobson</code>
</p>
</dd>
<dt>
<code>"Linsear.Write"</code> (O'Hayre, undated, see Klare, 1975, p. 85):</dt>
<dd>
<p style="text-align: center;"><code class="reqn">LW_{raw} = \frac{100 - \frac{100 \times W_{&lt;3Sy}}{W} + \left( 3 \times \frac{100 \times W_{3Sy}}{W} \right)}{\frac{100 \times St}{W}} </code>
</p>

<p style="text-align: center;"><code class="reqn">LW(LW_{raw} \leq 20) = \frac{LW_{raw} - 2}{2}</code>
</p>

<p style="text-align: center;"><code class="reqn">LW(LW_{raw} &gt; 20) = \frac{LW_{raw}}{2}</code>
</p>

<p>Wrapper function: <code>linsear.write</code>
</p>
</dd>
<dt><code>"LIX"</code></dt>
<dd>
<p>Björnsson's <em>Läsbarhetsindex</em>. Originally proposed for Swedish texts,
calculated by:
</p>
<p style="text-align: center;"><code class="reqn">LIX = \frac{W}{St} + \frac{100 \times{} W_{7C}}{W}</code>
</p>

<p>Texts with a LIX &lt; 25 are considered very easy, around 40 normal,
and &gt; 55 very difficult to read.
</p>
<p>Wrapper function: <code>LIX</code>
</p>
</dd>
<dt>
<code>"nWS"</code>:</dt>
<dd>
<p><em>Neue Wiener Sachtextformeln</em> (Bamberger &amp; Vanecek, 1984):
</p>
<p style="text-align: center;"><code class="reqn">nWS_1 = 19.35 \times \frac{W_{3Sy}}{W} + 0.1672 \times \frac{W}{St} + 12.97 \times \frac{W_{6C}}{W} - 3.27 \times \frac{W^{1Sy}}{W} - 0.875</code>
</p>

<p style="text-align: center;"><code class="reqn">nWS_2 = 20.07 \times \frac{W_{3Sy}}{W} + 0.1682 \times \frac{W}{St} + 13.73 \times \frac{W_{6C}}{W} - 2.779</code>
</p>

<p style="text-align: center;"><code class="reqn">nWS_3 = 29.63 \times \frac{W_{3Sy}}{W} + 0.1905 \times \frac{W}{St} - 1.1144</code>
</p>

<p style="text-align: center;"><code class="reqn">nWS_4 = 27.44 \times \frac{W_{3Sy}}{W} + 0.2656 \times \frac{W}{St} - 1.693</code>
</p>

<p>Wrapper function: <code>nWS</code>
</p>
</dd>
<dt><code>"RIX"</code></dt>
<dd>
<p>Anderson's <em>Readability Index</em>. A simplified version of LIX:
</p>
<p style="text-align: center;"><code class="reqn">RIX = \frac{W_{7C}}{St}</code>
</p>

<p>Texts with a RIX &lt; 1.8 are considered very easy, around 3.7 normal,
and &gt; 7.2 very difficult to read.
</p>
<p>Wrapper function: <code>RIX</code>
</p>
</dd>
<dt>
<code>"SMOG"</code>:</dt>
<dd>
<p><em>Simple Measure of Gobbledygook</em>. By default calculates formula D by McLaughlin (1969):
</p>
<p style="text-align: center;"><code class="reqn">SMOG = 1.043 \times \sqrt{W_{3Sy} \times \frac{30}{St}} + 3.1291</code>
</p>

<p>If <code>parameters</code> is set to <code>SMOG="C"</code>, formula C will be calculated:
</p>
<p style="text-align: center;"><code class="reqn">SMOG_{C} = 0.9986 \times \sqrt{W_{3Sy} \times \frac{30}{St} + 5} + 2.8795</code>
</p>

<p>If <code>parameters</code> is set to <code>SMOG="simple"</code>, the simplified formula is used:
</p>
<p style="text-align: center;"><code class="reqn">SMOG_{simple} = \sqrt{W_{3Sy} \times \frac{30}{St}} + 3</code>
</p>

<p>If <code>parameters</code> is set to <code>SMOG="de"</code>,
the formula adapted to German texts ("Qu", Bamberger &amp; Vanecek, 1984, p. 78) is used:
</p>
<p style="text-align: center;"><code class="reqn">SMOG_{de} = \sqrt{W_{3Sy} \times \frac{30}{St}} - 2</code>
</p>

<p>Wrapper function: <code>SMOG</code>
</p>
</dd>
<dt>
<code>"Spache"</code>:</dt>
<dd>
<p><em>Spache Revised Formula (1974)</em>:
</p>
<p style="text-align: center;"><code class="reqn">Spache = 0.121 \times \frac{W}{St} + 0.082 \times{} \frac{100 \times{} W_{-WL}}{W} + 0.659</code>
</p>

<p>If <code>parameters</code> is set to <code>Spache="old"</code>, the original parameters (Spache,
1953) are used:
</p>
<p style="text-align: center;"><code class="reqn">Spache_{old} = 0.141 \times \frac{W}{St} + 0.086 \times{} \frac{100 \times{} W_{-WL}}{W} + 0.839</code>
</p>

<p><strong>Note:</strong> The revised index needs the revised Spache word list (see Klare, 1975,
p. 73), and the old index the short Dale-Chall list of
769 familiar (english) words to compute <code class="reqn">W_{-WL}</code>. That is,
you must have a copy of this word list and provide it via the
<code>word.lists=list(Spache=&lt;your.list&gt;)</code> parameter!
</p>
<p>Wrapper function: <code>spache</code>
</p>
</dd>
<dt>
<code>"Strain"</code>:</dt>
<dd>
<p><em>Strain Index</em>. This index was proposed in [1]:
</p>
<p style="text-align: center;"><code class="reqn">S = Sy \times{} \frac{1}{St / 3} \times{} \frac{1}{10}</code>
</p>

<p>Wrapper function: <code>strain</code>
</p>
</dd>
<dt>
<code>"Traenkle.Bailer"</code>:</dt>
<dd>
<p><em>Tränkle-Bailer Formeln</em>. These two formulas were the result of a re-examination of the ones proposed
by Dickes-Steiwer. They try to avoid the usage of the type-token ratio,
which is dependent on text length (Tränkle &amp; Bailer, 1984):
</p>
<p style="text-align: center;"><code class="reqn">TB1 = 224.6814 - \left(79.8304 \times \frac{C}{W} \right) - \left(12.24032 \times \frac{W}{St} \right) - \left(1.292857 \times \frac{100 \times{} W_{prep}}{W} \right)</code>
</p>

<p style="text-align: center;"><code class="reqn">TB2 = 234.1063 - \left(96.11069 \times \frac{C}{W} \right) - \left(2.05444 \times \frac{100 \times{} W_{prep}}{W} \right) - \left(1.02805 \times \frac{100 \times{} W_{conj}}{W} \right)</code>
</p>

<p>Where <code class="reqn">W_{prep}</code> refers to the number of prepositions,
and <code class="reqn">W_{conj}</code> to the number of conjunctions.
</p>
<p>Wrapper function: <code>traenkle.bailer</code>
</p>
</dd>
<dt>
<code>"TRI"</code>:</dt>
<dd>
<p>Kuntzsch's <em>Text-Redundanz-Index</em>. Intended mainly for German newspaper comments.
</p>
<p style="text-align: center;"><code class="reqn">TRI = \left(0.449 \times W^{1Sy}\right) - \left(2.467 \times Ptn\right) - \left(0.937 \times Frg\right) - 14.417</code>
</p>

<p>Where <code class="reqn">Ptn</code> is the number of punctuation marks and <code class="reqn">Frg</code> the number of foreign words.
</p>
<p>Wrapper function: <code>TRI</code>
</p>
</dd>
<dt>
<code>"Tuldava"</code>:</dt>
<dd>
<p>Tuldava's <em>Text Difficulty Formula</em>. Supposed to be rather independent of specific languages (Grzybek,
2010).
</p>
<p style="text-align: center;"><code class="reqn">TD = \frac{Sy}{W} \times ln\left( \frac{W}{St} \right)</code>
</p>

<p>Wrapper function: <code>tuldava</code>
</p>
</dd>
<dt>
<code>"Wheeler.Smith"</code>:</dt>
<dd>
<p>Intended for english texts in primary grades 1–4 (Wheeler &amp; Smith,
1954):
</p>
<p style="text-align: center;"><code class="reqn">WS = \frac{W}{St} \times \frac{10 \times{} W_{2Sy}}{W}</code>
</p>

<p>If <code>parameters</code> is set to <code>Wheeler.Smith="de"</code>,
the calculation stays the same, but grade placement
is done according to Bamberger &amp; Vanecek (1984), that is for german texts.
</p>
<p>Wrapper function: <code>wheeler.smith</code>
</p>
</dd>
</dl>
<p>By default, if the text has to be tagged yet,
the language definition is queried by calling <code>get.kRp.env(lang=TRUE)</code> internally.
Or, if <code>txt</code> has already been tagged,
by default the language definition of that tagged object is read
and used. Set <code>force.lang=get.kRp.env(lang=TRUE)</code> or to any other valid value,
if you want to forcibly overwrite this
default behaviour,
and only then. See <code>kRp.POS.tags</code> for all supported languages.
</p>


<h3>Value</h3>

<p>Depending on <code>as.feature</code>,
either an object of class <code>kRp.readability</code>,
or an object of class <code>kRp.text</code> with the added feature <code>readability</code> containing it.
</p>


<h3>Note</h3>

<p>To get a printout of the default parameters like they're set if no other parameters are specified,
call <code>readability(parameters="dput")</code>.
In case you want to provide different parameters,
you must provide a complete set for an index, or special parameters that are
mentioned in the index descriptions above (e.g., "PSK", if appropriate).
</p>


<h3>References</h3>

<p>Anderson,
J. (1981). Analysing the readability of english and non-english texts in the classroom with Lix. In
<em>Annual Meeting of the Australian Reading Association</em>, Darwin, Australia.
</p>
<p>Anderson,
J. (1983). Lix and Rix: Variations on a little-known readability index. <em>Journal of Reading</em>, 26(6), 490–496.
</p>
<p>Bamberger, R. &amp; Vanecek,
E. (1984). <em>Lesen–Verstehen–Lernen–Schreiben</em>. Wien: Jugend und Volk.
</p>
<p>Briest, W. (1974). Kann man Verständlichkeit messen? <em>Zeitschrift für Phonetik,
Sprachwissenschaft und Kommunikationsforschung</em>, 27, 543–563.
</p>
<p>Coleman, M. &amp; Liau,
T.L. (1975). A computer readability formula designed for machine scoring, <em>Journal of Applied Psychology</em>, 60(2), 283–284.
</p>
<p>Dickes, P. &amp; Steiwer,
L. (1977). Ausarbeitung von Lesbarkeitsformeln für die deutsche Sprache.
<em>Zeitschrift für Entwicklungspsychologie und Pädagogische Psychologie</em>, 9(1),
20–28.
</p>
<p>DuBay,
W.H. (2004). <em>The Principles of Readability</em>. Costa Mesa: Impact Information.
WWW: <a href="http://www.impact-information.com/impactinfo/readability02.pdf">http://www.impact-information.com/impactinfo/readability02.pdf</a>; 22.03.2011.
</p>
<p>Farr, J.N., Jenkins, J.J. &amp; Paterson,
D.G. (1951). Simplification of Flesch Reading Ease formula. <em>Journal of Applied Psychology</em>, 35(5), 333–337.
</p>
<p>Fernández, A. M. (2016,
November 30). <em>Fórmula de comprensibilidad de Gutiérrez de Polini</em>.
<a href="https://legible.es/blog/comprensibilidad-gutierrez-de-polini/">https://legible.es/blog/comprensibilidad-gutierrez-de-polini/</a>
</p>
<p>Flesch, R. (1948). A new readability yardstick. <em>Journal of Applied Psychology</em>,
32(3), 221–233.
</p>
<p>Grzybek, P. (2010). Text difficulty and the Arens-Altmann law. In Peter Grzybek,
Emmerich Kelih, Ján Mačutek (Eds.),
<em>Text and Language. Structures – Functions – Interrelations. Quantitative Perspectives</em>. Wien: Praesens,
57–70.
</p>
<p>Harris, A.J. &amp; Jacobson,
M.D. (1974). Revised Harris-Jacobson readability formulas. In <em>18th Annual Meeting of the College Reading Association</em>, Bethesda.
</p>
<p>Klare, G.R. (1975). Assessing readability. <em>Reading Research Quarterly</em>, 10(1),
62–102.
</p>
<p>McLaughlin,
G.H. (1969). SMOG grading – A new readability formula. <em>Journal of Reading</em>, 12(8), 639–646.
</p>
<p>Powers, R.D, Sumner, W.A, &amp; Kearl,
B.E. (1958). A recalculation of four adult readability formulas, <em>Journal of Educational Psychology</em>, 49(2), 99–105.
</p>
<p>Smith, E.A. &amp; Senter,
R.J. (1967). <em>Automated readability index</em>. AMRL-TR-66-22. Wright-Paterson AFB, Ohio: Aerospace Medical Division.
</p>
<p>Spache,
G. (1953). A new readability formula for primary-grade reading materials. <em>The Elementary School Journal</em>, 53, 410–413.
</p>
<p>Tränkle, U. &amp; Bailer,
H. (1984). Kreuzvalidierung und Neuberechnung von Lesbarkeitsformeln für die deutsche Sprache.
<em>Zeitschrift für Entwicklungspsychologie und Pädagogische Psychologie</em>, 16(3),
231–244.
</p>
<p>Wheeler, L.R. &amp; Smith,
E.H. (1954). A practical readability formula for the classroom teacher in the primary grades. <em>Elementary English</em>,
31, 397–399.
</p>
<p>[1] <a href="https://strainindex.wordpress.com/2007/09/25/hello-world/">https://strainindex.wordpress.com/2007/09/25/hello-world/</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># code is only run when the english language package can be loaded
if(require("koRpus.lang.en", quietly = TRUE)){
  sample_file &lt;- file.path(
    path.package("koRpus"), "examples", "corpus", "Reality_Winner.txt"
  )
  # call readability() on a tokenized text
  tokenized.obj &lt;- tokenize(
    txt=sample_file,
    lang="en"
  )
  # if you call readability() without arguments,
  # you will get its results directly
  rdb.results &lt;- readability(tokenized.obj)

  # there are [ and [[ methods for these objects
  rdb.results[["ARI"]]

  # alternatively, you can also store those results as a
  # feature in the object itself
  tokenized.obj &lt;- readability(
    tokenized.obj,
    as.feature=TRUE
  )
  # results are now part of the object
  hasFeature(tokenized.obj)
  corpusReadability(tokenized.obj)
} else {}
</code></pre>


</div>