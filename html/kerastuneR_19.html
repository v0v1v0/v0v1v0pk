<div class="container">

<table style="width: 100%;"><tr>
<td>RandomSearch</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>RandomSearch</h2>

<h3>Description</h3>

<p>Random search tuner.
</p>


<h3>Usage</h3>

<pre><code class="language-R">RandomSearch(
  hypermodel,
  objective,
  max_trials,
  seed = NULL,
  hyperparameters = NULL,
  tune_new_entries = TRUE,
  allow_new_entries = TRUE,
  max_retries_per_trial = 0,
  max_consecutive_failed_trials = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>hypermodel</code></td>
<td>
<p>Define a model-building function. It takes an argument "hp" from which 
you can sample hyperparameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objective</code></td>
<td>
<p>A loss metrics function for tracking the model performance e.g. "val_precision". The name of 
the objective to optimize (whether to minimize or maximize is automatically inferred for built-in metrics)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_trials</code></td>
<td>
<p>the total number of trials (max_trials) to test</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Int. Random seed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hyperparameters</code></td>
<td>
<p>HyperParameters class instance. Can be used to override (or register in advance) hyperparamters 
in the search space</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune_new_entries</code></td>
<td>
<p>Whether hyperparameter entries that are requested by the hypermodel 
but that were not specified in hyperparameters should be added to the search space, or not. 
If not, then the default value for these parameters will be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allow_new_entries</code></td>
<td>
<p>Whether the hypermodel is allowed to request hyperparameter entries not listed in hyperparameters</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_retries_per_trial</code></td>
<td>
<p>Integer. Defaults to 0. The maximum number of times to retry a 'Trial' if the trial crashed or the results are invalid.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_consecutive_failed_trials</code></td>
<td>
<p>Integer. Defaults to 3. The maximum number of consecutive failed 'Trial's. When this number is reached, the search will be stopped. A 'Trial' is marked as failed when none of the retries succeeded. **kwargs: Keyword arguments relevant to all 'Tuner' subclasses. Please see the docstring for 'Tuner'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Some additional arguments</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a hyperparameter tuner object RandomSearch
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 

x_data &lt;- matrix(data = runif(500,0,1),nrow = 50,ncol = 5) 
y_data &lt;-  ifelse(runif(50,0,1) &gt; 0.6, 1L,0L) %&gt;% as.matrix()
x_data2 &lt;- matrix(data = runif(500,0,1),nrow = 50,ncol = 5)
y_data2 &lt;-  ifelse(runif(50,0,1) &gt; 0.6, 1L,0L) %&gt;% as.matrix()

build_model = function(hp) {
 model = keras_model_sequential()
  model %&gt;% layer_dense(units=hp$Int('units',
                                    min_value=32L,
                                    max_value=512L,
                                    step=32L),
                                    input_shape = ncol(x_data),
                                    activation='relu') %&gt;%
   layer_dense(units=1L, activation='softmax') %&gt;%
   compile(
     optimizer= tf$keras$optimizers$Adam(
       hp$Choice('learning_rate',
                 values=c(1e-2, 1e-3, 1e-4))),
    loss='binary_crossentropy',
     metrics='accuracy')
     return(model)
 }
 tuner = RandomSearch(hypermodel = build_model,
                       objective = 'val_accuracy',
                       max_trials = 2,
                       executions_per_trial = 1)

## End(Not run)

</code></pre>


</div>