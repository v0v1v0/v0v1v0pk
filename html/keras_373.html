<div class="container">

<table style="width: 100%;"><tr>
<td>layer_hashing</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>A preprocessing layer which hashes and bins categorical features.</h2>

<h3>Description</h3>

<p>A preprocessing layer which hashes and bins categorical features.
</p>


<h3>Usage</h3>

<pre><code class="language-R">layer_hashing(
  object,
  num_bins,
  mask_value = NULL,
  salt = NULL,
  output_mode = "int",
  sparse = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li>
<p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li>
<p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li>
<p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_bins</code></td>
<td>
<p>Number of hash bins. Note that this includes the <code>mask_value</code> bin,
so the effective number of bins is <code>(num_bins - 1)</code> if <code>mask_value</code> is
set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mask_value</code></td>
<td>
<p>A value that represents masked inputs, which are mapped to
index 0. Defaults to NULL, meaning no mask term will be added and the
hashing will start at index 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>salt</code></td>
<td>
<p>A single unsigned integer or NULL.
If passed, the hash function used will be SipHash64, with these values
used as an additional input (known as a "salt" in cryptography).
These should be non-zero. Defaults to <code>NULL</code> (in that
case, the FarmHash64 hash function is used). It also supports
list of 2 unsigned integer numbers, see reference paper for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_mode</code></td>
<td>
<p>Specification for the output of the layer. Defaults to
<code>"int"</code>.  Values can be <code>"int"</code>, <code>"one_hot"</code>, <code>"multi_hot"</code>, or
<code>"count"</code> configuring the layer as follows:
</p>

<ul>
<li> <p><code>"int"</code>: Return the integer bin indices directly.
</p>
</li>
<li> <p><code>"one_hot"</code>: Encodes each individual element in the input into an
array the same size as <code>num_bins</code>, containing a 1 at the input's bin
index. If the last dimension is size 1, will encode on that
dimension.  If the last dimension is not size 1, will append a new
dimension for the encoded output.
</p>
</li>
<li> <p><code>"multi_hot"</code>: Encodes each sample in the input into a single array
the same size as <code>num_bins</code>, containing a 1 for each bin index
index present in the sample. Treats the last dimension as the sample
dimension, if input shape is <code style="white-space: pre;">⁠(..., sample_length)⁠</code>, output shape
will be <code style="white-space: pre;">⁠(..., num_tokens)⁠</code>.
</p>
</li>
<li> <p><code>"count"</code>: As <code>"multi_hot"</code>, but the int array contains a count of
the number of times the bin index appeared in the sample.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sparse</code></td>
<td>
<p>Boolean. Only applicable to <code>"one_hot"</code>, <code>"multi_hot"</code>,
and <code>"count"</code> output modes. If <code>TRUE</code>, returns a <code>SparseTensor</code> instead of
a dense <code>Tensor</code>. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>standard layer arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This layer transforms single or multiple categorical inputs to hashed output.
It converts a sequence of int or string to a sequence of int. The stable hash
function uses <code style="white-space: pre;">⁠tensorflow::ops::Fingerprint⁠</code> to produce the same output
consistently across all platforms.
</p>
<p>This layer uses <a href="https://github.com/google/farmhash">FarmHash64</a> by default,
which provides a consistent hashed output across different platforms and is
stable across invocations, regardless of device and context, by mixing the
input bits thoroughly.
</p>
<p>If you want to obfuscate the hashed output, you can also pass a random <code>salt</code>
argument in the constructor. In that case, the layer will use the
<a href="https://github.com/google/highwayhash">SipHash64</a> hash function, with
the <code>salt</code> value serving as additional input to the hash function.
</p>
<p><strong>Example (FarmHash64)</strong>
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_hashing(num_bins=3)
inp &lt;- matrix(c('A', 'B', 'C', 'D', 'E'))
layer(inp)
# &lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#   array([[1],
#          [0],
#          [1],
#          [1],
#          [2]])&gt;
</pre></div>
<p><strong>Example (FarmHash64) with a mask value</strong>
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_hashing(num_bins=3, mask_value='')
inp &lt;- matrix(c('A', 'B', 'C', 'D', 'E'))
layer(inp)
# &lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#   array([[1],
#          [1],
#          [0],
#          [2],
#          [2]])&gt;
</pre></div>
<p><strong>Example (SipHash64)</strong>
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_hashing(num_bins=3, salt=c(133, 137))
inp &lt;- matrix(c('A', 'B', 'C', 'D', 'E'))
layer(inp)
# &lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#   array([[1],
#          [2],
#          [1],
#          [0],
#          [2]])&gt;
</pre></div>
<p><strong>Example (Siphash64 with a single integer, same as <code style="white-space: pre;">⁠salt=[133, 133]⁠</code>)</strong>
</p>
<div class="sourceCode r"><pre>layer &lt;- layer_hashing(num_bins=3, salt=133)
inp &lt;- matrix(c('A', 'B', 'C', 'D', 'E'))
layer(inp)
# &lt;tf.Tensor: shape=(5, 1), dtype=int64, numpy=
#   array([[0],
#          [0],
#          [2],
#          [1],
#          [0]])&gt;
</pre></div>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/preprocessing_layers/categorical/hashing/">https://keras.io/api/layers/preprocessing_layers/categorical/hashing/</a>
</p>
</li>
</ul>
<p>Other categorical features preprocessing layers: 
<code>layer_category_encoding()</code>,
<code>layer_integer_lookup()</code>,
<code>layer_string_lookup()</code>
</p>
<p>Other preprocessing layers: 
<code>layer_category_encoding()</code>,
<code>layer_center_crop()</code>,
<code>layer_discretization()</code>,
<code>layer_integer_lookup()</code>,
<code>layer_normalization()</code>,
<code>layer_random_brightness()</code>,
<code>layer_random_contrast()</code>,
<code>layer_random_crop()</code>,
<code>layer_random_flip()</code>,
<code>layer_random_height()</code>,
<code>layer_random_rotation()</code>,
<code>layer_random_translation()</code>,
<code>layer_random_width()</code>,
<code>layer_random_zoom()</code>,
<code>layer_rescaling()</code>,
<code>layer_resizing()</code>,
<code>layer_string_lookup()</code>,
<code>layer_text_vectorization()</code>
</p>


</div>