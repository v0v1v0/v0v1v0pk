<div class="container">

<table style="width: 100%;"><tr>
<td>layer_random_brightness</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>A preprocessing layer which randomly adjusts brightness during training.</h2>

<h3>Description</h3>

<p>This layer will randomly increase/reduce the brightness for the input RGB
images. At inference time, the output will be identical to the input.
Call the layer with <code>training=TRUE</code> to adjust the brightness of the input.
</p>
<p><strong>Note:</strong> This layer is safe to use inside a <code>tf.data</code> pipeline
(independently of which backend you're using).
</p>


<h3>Usage</h3>

<pre><code class="language-R">layer_random_brightness(
  object,
  factor,
  value_range = list(0L, 255L),
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Object to compose the layer with. A tensor, array, or sequential model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor</code></td>
<td>
<p>Float or a list of 2 floats between -1.0 and 1.0. The
factor is used to determine the lower bound and upper bound of the
brightness adjustment. A float value will be chosen randomly between
the limits. When -1.0 is chosen, the output image will be black, and
when 1.0 is chosen, the image will be fully white.
When only one float is provided, eg, 0.2,
then -0.2 will be used for lower bound and 0.2
will be used for upper bound.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>value_range</code></td>
<td>
<p>Optional list of 2 floats
for the lower and upper limit
of the values of the input data.
To make no change, use <code>c(0.0, 1.0)</code>, e.g., if the image input
has been scaled before this layer. Defaults to <code>c(0.0, 255.0)</code>.
The brightness adjustment will be scaled to this range, and the
output values will be clipped to this range.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>optional integer, for fixed RNG behavior.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For forward/backward compatability.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The return value depends on the value provided for the first argument.
If  <code>object</code> is:
</p>

<ul>
<li>
<p> a <code>keras_model_sequential()</code>, then the layer is added to the sequential model
(which is modified in place). To enable piping, the sequential model is also
returned, invisibly.
</p>
</li>
<li>
<p> a <code>keras_input()</code>, then the output tensor from calling <code>layer(input)</code> is returned.
</p>
</li>
<li> <p><code>NULL</code> or missing, then a <code>Layer</code> instance is returned.
</p>
</li>
</ul>
<h3>Inputs</h3>

<p>3D (HWC) or 4D (NHWC) tensor, with float or int dtype. Input pixel
values can be of any range (e.g. <code style="white-space: pre;">⁠[0., 1.)⁠</code> or <code style="white-space: pre;">⁠[0, 255]⁠</code>)
</p>


<h3>Output</h3>

<p>3D (HWC) or 4D (NHWC) tensor with brightness adjusted based on the
<code>factor</code>. By default, the layer will output floats.
The output value will be clipped to the range <code style="white-space: pre;">⁠[0, 255]⁠</code>,
the valid range of RGB colors, and
rescaled based on the <code>value_range</code> if needed.
</p>


<h3>Example</h3>

<div class="sourceCode r"><pre>random_bright &lt;- layer_random_brightness(factor=0.2, seed = 1)

# An image with shape [2, 2, 3]
image &lt;- array(1:12, dim=c(2, 2, 3))

# Assume we randomly select the factor to be 0.1, then it will apply
# 0.1 * 255 to all the channel
output &lt;- random_bright(image, training=TRUE)
output
</pre></div>
<div class="sourceCode"><pre>## tf.Tensor(
## [[[39.605797 43.605797 47.605797]
##   [41.605797 45.605797 49.605797]]
##
##  [[40.605797 44.605797 48.605797]
##   [42.605797 46.605797 50.605797]]], shape=(2, 2, 3), dtype=float32)

</pre></div>


<h3>See Also</h3>


<ul><li> <p><a href="https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_brightness#randombrightness-class">https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_brightness#randombrightness-class</a>
</p>
</li></ul>
<p>Other image augmentation layers: <br><code>layer_random_contrast()</code> <br><code>layer_random_crop()</code> <br><code>layer_random_flip()</code> <br><code>layer_random_rotation()</code> <br><code>layer_random_translation()</code> <br><code>layer_random_zoom()</code> <br></p>
<p>Other preprocessing layers: <br><code>layer_category_encoding()</code> <br><code>layer_center_crop()</code> <br><code>layer_discretization()</code> <br><code>layer_feature_space()</code> <br><code>layer_hashed_crossing()</code> <br><code>layer_hashing()</code> <br><code>layer_integer_lookup()</code> <br><code>layer_mel_spectrogram()</code> <br><code>layer_normalization()</code> <br><code>layer_random_contrast()</code> <br><code>layer_random_crop()</code> <br><code>layer_random_flip()</code> <br><code>layer_random_rotation()</code> <br><code>layer_random_translation()</code> <br><code>layer_random_zoom()</code> <br><code>layer_rescaling()</code> <br><code>layer_resizing()</code> <br><code>layer_string_lookup()</code> <br><code>layer_text_vectorization()</code> <br></p>
<p>Other layers: <br><code>Layer()</code> <br><code>layer_activation()</code> <br><code>layer_activation_elu()</code> <br><code>layer_activation_leaky_relu()</code> <br><code>layer_activation_parametric_relu()</code> <br><code>layer_activation_relu()</code> <br><code>layer_activation_softmax()</code> <br><code>layer_activity_regularization()</code> <br><code>layer_add()</code> <br><code>layer_additive_attention()</code> <br><code>layer_alpha_dropout()</code> <br><code>layer_attention()</code> <br><code>layer_average()</code> <br><code>layer_average_pooling_1d()</code> <br><code>layer_average_pooling_2d()</code> <br><code>layer_average_pooling_3d()</code> <br><code>layer_batch_normalization()</code> <br><code>layer_bidirectional()</code> <br><code>layer_category_encoding()</code> <br><code>layer_center_crop()</code> <br><code>layer_concatenate()</code> <br><code>layer_conv_1d()</code> <br><code>layer_conv_1d_transpose()</code> <br><code>layer_conv_2d()</code> <br><code>layer_conv_2d_transpose()</code> <br><code>layer_conv_3d()</code> <br><code>layer_conv_3d_transpose()</code> <br><code>layer_conv_lstm_1d()</code> <br><code>layer_conv_lstm_2d()</code> <br><code>layer_conv_lstm_3d()</code> <br><code>layer_cropping_1d()</code> <br><code>layer_cropping_2d()</code> <br><code>layer_cropping_3d()</code> <br><code>layer_dense()</code> <br><code>layer_depthwise_conv_1d()</code> <br><code>layer_depthwise_conv_2d()</code> <br><code>layer_discretization()</code> <br><code>layer_dot()</code> <br><code>layer_dropout()</code> <br><code>layer_einsum_dense()</code> <br><code>layer_embedding()</code> <br><code>layer_feature_space()</code> <br><code>layer_flatten()</code> <br><code>layer_flax_module_wrapper()</code> <br><code>layer_gaussian_dropout()</code> <br><code>layer_gaussian_noise()</code> <br><code>layer_global_average_pooling_1d()</code> <br><code>layer_global_average_pooling_2d()</code> <br><code>layer_global_average_pooling_3d()</code> <br><code>layer_global_max_pooling_1d()</code> <br><code>layer_global_max_pooling_2d()</code> <br><code>layer_global_max_pooling_3d()</code> <br><code>layer_group_normalization()</code> <br><code>layer_group_query_attention()</code> <br><code>layer_gru()</code> <br><code>layer_hashed_crossing()</code> <br><code>layer_hashing()</code> <br><code>layer_identity()</code> <br><code>layer_integer_lookup()</code> <br><code>layer_jax_model_wrapper()</code> <br><code>layer_lambda()</code> <br><code>layer_layer_normalization()</code> <br><code>layer_lstm()</code> <br><code>layer_masking()</code> <br><code>layer_max_pooling_1d()</code> <br><code>layer_max_pooling_2d()</code> <br><code>layer_max_pooling_3d()</code> <br><code>layer_maximum()</code> <br><code>layer_mel_spectrogram()</code> <br><code>layer_minimum()</code> <br><code>layer_multi_head_attention()</code> <br><code>layer_multiply()</code> <br><code>layer_normalization()</code> <br><code>layer_permute()</code> <br><code>layer_random_contrast()</code> <br><code>layer_random_crop()</code> <br><code>layer_random_flip()</code> <br><code>layer_random_rotation()</code> <br><code>layer_random_translation()</code> <br><code>layer_random_zoom()</code> <br><code>layer_repeat_vector()</code> <br><code>layer_rescaling()</code> <br><code>layer_reshape()</code> <br><code>layer_resizing()</code> <br><code>layer_rnn()</code> <br><code>layer_separable_conv_1d()</code> <br><code>layer_separable_conv_2d()</code> <br><code>layer_simple_rnn()</code> <br><code>layer_spatial_dropout_1d()</code> <br><code>layer_spatial_dropout_2d()</code> <br><code>layer_spatial_dropout_3d()</code> <br><code>layer_spectral_normalization()</code> <br><code>layer_string_lookup()</code> <br><code>layer_subtract()</code> <br><code>layer_text_vectorization()</code> <br><code>layer_tfsm()</code> <br><code>layer_time_distributed()</code> <br><code>layer_torch_module_wrapper()</code> <br><code>layer_unit_normalization()</code> <br><code>layer_upsampling_1d()</code> <br><code>layer_upsampling_2d()</code> <br><code>layer_upsampling_3d()</code> <br><code>layer_zero_padding_1d()</code> <br><code>layer_zero_padding_2d()</code> <br><code>layer_zero_padding_3d()</code> <br><code>rnn_cell_gru()</code> <br><code>rnn_cell_lstm()</code> <br><code>rnn_cell_simple()</code> <br><code>rnn_cells_stack()</code> <br></p>


</div>