<div class="container">

<table style="width: 100%;"><tr>
<td>layer_random_zoom</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>A preprocessing layer which randomly zooms images during training.</h2>

<h3>Description</h3>

<p>This layer will randomly zoom in or out on each axis of an image
independently, filling empty space according to <code>fill_mode</code>.
</p>
<p>Input pixel values can be of any range (e.g. <code style="white-space: pre;">⁠[0., 1.)⁠</code> or <code style="white-space: pre;">⁠[0, 255]⁠</code>) and
of integer or floating point dtype.
By default, the layer will output floats.
</p>


<h3>Usage</h3>

<pre><code class="language-R">layer_random_zoom(
  object,
  height_factor,
  width_factor = NULL,
  fill_mode = "reflect",
  interpolation = "bilinear",
  seed = NULL,
  fill_value = 0,
  data_format = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Object to compose the layer with. A tensor, array, or sequential model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>height_factor</code></td>
<td>
<p>a float represented as fraction of value, or a list of
size 2 representing lower and upper bound for zooming vertically.
When represented as a single float, this value is used for both the
upper and lower bound. A positive value means zooming out, while a
negative value means zooming in. For instance,
<code>height_factor=c(0.2, 0.3)</code> result in an output zoomed out by a
random amount in the range <code style="white-space: pre;">⁠[+20%, +30%]⁠</code>.
<code>height_factor=c(-0.3, -0.2)</code> result in an output zoomed in by a
random amount in the range <code style="white-space: pre;">⁠[+20%, +30%]⁠</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>width_factor</code></td>
<td>
<p>a float represented as fraction of value, or a list of
size 2 representing lower and upper bound for zooming horizontally.
When represented as a single float, this value is used for both the
upper and lower bound. For instance, <code>width_factor=c(0.2, 0.3)</code>
result in an output zooming out between 20% to 30%.
<code>width_factor=c(-0.3, -0.2)</code> result in an output zooming in between
20% to 30%. <code>NULL</code> means i.e., zooming vertical and horizontal
directions by preserving the aspect ratio. Defaults to <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fill_mode</code></td>
<td>
<p>Points outside the boundaries of the input are filled
according to the given mode. Available methods are <code>"constant"</code>,
<code>"nearest"</code>, <code>"wrap"</code> and <code>"reflect"</code>. Defaults to <code>"constant"</code>.
</p>

<ul>
<li> <p><code>"reflect"</code>: <code style="white-space: pre;">⁠(d c b a | a b c d | d c b a)⁠</code>
The input is extended by reflecting about the edge of the last
pixel.
</p>
</li>
<li> <p><code>"constant"</code>: <code style="white-space: pre;">⁠(k k k k | a b c d | k k k k)⁠</code>
The input is extended by filling all values beyond
the edge with the same constant value k specified by
<code>fill_value</code>.
</p>
</li>
<li> <p><code>"wrap"</code>: <code style="white-space: pre;">⁠(a b c d | a b c d | a b c d)⁠</code>
The input is extended by wrapping around to the opposite edge.
</p>
</li>
<li> <p><code>"nearest"</code>: <code style="white-space: pre;">⁠(a a a a | a b c d | d d d d)⁠</code>
The input is extended by the nearest pixel.
Note that when using torch backend, <code>"reflect"</code> is redirected to
<code>"mirror"</code> <code style="white-space: pre;">⁠(c d c b | a b c d | c b a b)⁠</code> because torch does not
support <code>"reflect"</code>.
Note that torch backend does not support <code>"wrap"</code>.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interpolation</code></td>
<td>
<p>Interpolation mode. Supported values: <code>"nearest"</code>,
<code>"bilinear"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Integer. Used to create a random seed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fill_value</code></td>
<td>
<p>a float that represents the value to be filled outside
the boundaries when <code>fill_mode="constant"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data_format</code></td>
<td>
<p>string, either <code>"channels_last"</code> or <code>"channels_first"</code>.
The ordering of the dimensions in the inputs. <code>"channels_last"</code>
corresponds to inputs with shape <code style="white-space: pre;">⁠(batch, height, width, channels)⁠</code>
while <code>"channels_first"</code> corresponds to inputs with shape
<code style="white-space: pre;">⁠(batch, channels, height, width)⁠</code>. It defaults to the
<code>image_data_format</code> value found in your Keras config file at
<code style="white-space: pre;">⁠~/.keras/keras.json⁠</code>. If you never set it, then it will be
<code>"channels_last"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Base layer keyword arguments, such as <code>name</code> and <code>dtype</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The return value depends on the value provided for the first argument.
If  <code>object</code> is:
</p>

<ul>
<li>
<p> a <code>keras_model_sequential()</code>, then the layer is added to the sequential model
(which is modified in place). To enable piping, the sequential model is also
returned, invisibly.
</p>
</li>
<li>
<p> a <code>keras_input()</code>, then the output tensor from calling <code>layer(input)</code> is returned.
</p>
</li>
<li> <p><code>NULL</code> or missing, then a <code>Layer</code> instance is returned.
</p>
</li>
</ul>
<h3>Input Shape</h3>

<p>3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">⁠(..., height, width, channels)⁠</code>, in <code>"channels_last"</code> format,
or <code style="white-space: pre;">⁠(..., channels, height, width)⁠</code>, in <code>"channels_first"</code> format.
</p>


<h3>Output Shape</h3>

<p>3D (unbatched) or 4D (batched) tensor with shape:
<code style="white-space: pre;">⁠(..., target_height, target_width, channels)⁠</code>,
or <code style="white-space: pre;">⁠(..., channels, target_height, target_width)⁠</code>,
in <code>"channels_first"</code> format.
</p>
<p><strong>Note:</strong> This layer is safe to use inside a <code>tf.data</code> pipeline
(independently of which backend you're using).
</p>


<h3>Examples</h3>

<div class="sourceCode r"><pre>input_img &lt;- random_uniform(c(32, 224, 224, 3))
layer &lt;- layer_random_zoom(height_factor = .5, width_factor = .2)
out_img &lt;- layer(input_img)
</pre></div>


<h3>See Also</h3>


<ul><li> <p><a href="https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom#randomzoom-class">https://keras.io/api/layers/preprocessing_layers/image_augmentation/random_zoom#randomzoom-class</a>
</p>
</li></ul>
<p>Other image augmentation layers: <br><code>layer_random_brightness()</code> <br><code>layer_random_contrast()</code> <br><code>layer_random_crop()</code> <br><code>layer_random_flip()</code> <br><code>layer_random_rotation()</code> <br><code>layer_random_translation()</code> <br></p>
<p>Other preprocessing layers: <br><code>layer_category_encoding()</code> <br><code>layer_center_crop()</code> <br><code>layer_discretization()</code> <br><code>layer_feature_space()</code> <br><code>layer_hashed_crossing()</code> <br><code>layer_hashing()</code> <br><code>layer_integer_lookup()</code> <br><code>layer_mel_spectrogram()</code> <br><code>layer_normalization()</code> <br><code>layer_random_brightness()</code> <br><code>layer_random_contrast()</code> <br><code>layer_random_crop()</code> <br><code>layer_random_flip()</code> <br><code>layer_random_rotation()</code> <br><code>layer_random_translation()</code> <br><code>layer_rescaling()</code> <br><code>layer_resizing()</code> <br><code>layer_string_lookup()</code> <br><code>layer_text_vectorization()</code> <br></p>
<p>Other layers: <br><code>Layer()</code> <br><code>layer_activation()</code> <br><code>layer_activation_elu()</code> <br><code>layer_activation_leaky_relu()</code> <br><code>layer_activation_parametric_relu()</code> <br><code>layer_activation_relu()</code> <br><code>layer_activation_softmax()</code> <br><code>layer_activity_regularization()</code> <br><code>layer_add()</code> <br><code>layer_additive_attention()</code> <br><code>layer_alpha_dropout()</code> <br><code>layer_attention()</code> <br><code>layer_average()</code> <br><code>layer_average_pooling_1d()</code> <br><code>layer_average_pooling_2d()</code> <br><code>layer_average_pooling_3d()</code> <br><code>layer_batch_normalization()</code> <br><code>layer_bidirectional()</code> <br><code>layer_category_encoding()</code> <br><code>layer_center_crop()</code> <br><code>layer_concatenate()</code> <br><code>layer_conv_1d()</code> <br><code>layer_conv_1d_transpose()</code> <br><code>layer_conv_2d()</code> <br><code>layer_conv_2d_transpose()</code> <br><code>layer_conv_3d()</code> <br><code>layer_conv_3d_transpose()</code> <br><code>layer_conv_lstm_1d()</code> <br><code>layer_conv_lstm_2d()</code> <br><code>layer_conv_lstm_3d()</code> <br><code>layer_cropping_1d()</code> <br><code>layer_cropping_2d()</code> <br><code>layer_cropping_3d()</code> <br><code>layer_dense()</code> <br><code>layer_depthwise_conv_1d()</code> <br><code>layer_depthwise_conv_2d()</code> <br><code>layer_discretization()</code> <br><code>layer_dot()</code> <br><code>layer_dropout()</code> <br><code>layer_einsum_dense()</code> <br><code>layer_embedding()</code> <br><code>layer_feature_space()</code> <br><code>layer_flatten()</code> <br><code>layer_flax_module_wrapper()</code> <br><code>layer_gaussian_dropout()</code> <br><code>layer_gaussian_noise()</code> <br><code>layer_global_average_pooling_1d()</code> <br><code>layer_global_average_pooling_2d()</code> <br><code>layer_global_average_pooling_3d()</code> <br><code>layer_global_max_pooling_1d()</code> <br><code>layer_global_max_pooling_2d()</code> <br><code>layer_global_max_pooling_3d()</code> <br><code>layer_group_normalization()</code> <br><code>layer_group_query_attention()</code> <br><code>layer_gru()</code> <br><code>layer_hashed_crossing()</code> <br><code>layer_hashing()</code> <br><code>layer_identity()</code> <br><code>layer_integer_lookup()</code> <br><code>layer_jax_model_wrapper()</code> <br><code>layer_lambda()</code> <br><code>layer_layer_normalization()</code> <br><code>layer_lstm()</code> <br><code>layer_masking()</code> <br><code>layer_max_pooling_1d()</code> <br><code>layer_max_pooling_2d()</code> <br><code>layer_max_pooling_3d()</code> <br><code>layer_maximum()</code> <br><code>layer_mel_spectrogram()</code> <br><code>layer_minimum()</code> <br><code>layer_multi_head_attention()</code> <br><code>layer_multiply()</code> <br><code>layer_normalization()</code> <br><code>layer_permute()</code> <br><code>layer_random_brightness()</code> <br><code>layer_random_contrast()</code> <br><code>layer_random_crop()</code> <br><code>layer_random_flip()</code> <br><code>layer_random_rotation()</code> <br><code>layer_random_translation()</code> <br><code>layer_repeat_vector()</code> <br><code>layer_rescaling()</code> <br><code>layer_reshape()</code> <br><code>layer_resizing()</code> <br><code>layer_rnn()</code> <br><code>layer_separable_conv_1d()</code> <br><code>layer_separable_conv_2d()</code> <br><code>layer_simple_rnn()</code> <br><code>layer_spatial_dropout_1d()</code> <br><code>layer_spatial_dropout_2d()</code> <br><code>layer_spatial_dropout_3d()</code> <br><code>layer_spectral_normalization()</code> <br><code>layer_string_lookup()</code> <br><code>layer_subtract()</code> <br><code>layer_text_vectorization()</code> <br><code>layer_tfsm()</code> <br><code>layer_time_distributed()</code> <br><code>layer_torch_module_wrapper()</code> <br><code>layer_unit_normalization()</code> <br><code>layer_upsampling_1d()</code> <br><code>layer_upsampling_2d()</code> <br><code>layer_upsampling_3d()</code> <br><code>layer_zero_padding_1d()</code> <br><code>layer_zero_padding_2d()</code> <br><code>layer_zero_padding_3d()</code> <br><code>rnn_cell_gru()</code> <br><code>rnn_cell_lstm()</code> <br><code>rnn_cell_simple()</code> <br><code>rnn_cells_stack()</code> <br></p>


</div>