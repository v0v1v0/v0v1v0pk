<div class="container">

<table style="width: 100%;"><tr>
<td>Hyperband</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Hyperband</h2>

<h3>Description</h3>

<p>Variation of HyperBand algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">Hyperband(
  hypermodel = NULL,
  objective = NULL,
  max_epochs = 100,
  factor = 3,
  hyperband_iterations = 1,
  seed = NULL,
  hyperparameters = NULL,
  tune_new_entries = TRUE,
  allow_new_entries = TRUE,
  max_retries_per_trial = 0,
  max_consecutive_failed_trials = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>hypermodel</code></td>
<td>
<p>Instance of 'HyperModel' class (or callable that takes hyperparameters and returns a 'Model' instance). It is optional when 'Tuner.run_trial()' is overriden and does not use 'self.hypermodel'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>objective</code></td>
<td>
<p>A string, 'keras_tuner.Objective' instance, or a list of 'keras_tuner.Objective's and strings. If a string, the direction of the optimization (min or max) will be inferred. If a list of 'keras_tuner.Objective', we will minimize the sum of all the objectives to minimize subtracting the sum of all the objectives to maximize. The 'objective' argument is optional when 'Tuner.run_trial()' or 'HyperModel.fit()' returns a single float as the objective to minimize.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_epochs</code></td>
<td>
<p>Integer, the maximum number of epochs to train one model. It is recommended to set this to a value slightly higher than the expected epochs to convergence for your largest Model, and to use early stopping during training (for example, via 'tf.keras.callbacks.EarlyStopping'). Defaults to 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor</code></td>
<td>
<p>Integer, the reduction factor for the number of epochs and number of models for each bracket. Defaults to 3.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hyperband_iterations</code></td>
<td>
<p>Integer, at least 1, the number of times to iterate over the full Hyperband algorithm. One iteration will run approximately 'max_epochs * (math.log(max_epochs, factor) ** 2)' cumulative epochs across all trials. It is recommended to set this to as high a value as is within your resource budget. Defaults to 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Optional integer, the random seed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hyperparameters</code></td>
<td>
<p>Optional HyperParameters instance. Can be used to override (or register in advance) hyperparameters in the search space.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tune_new_entries</code></td>
<td>
<p>Boolean, whether hyperparameter entries that are requested by the hypermodel but that were not specified in 'hyperparameters' should be added to the search space, or not. If not, then the default value for these parameters will be used. Defaults to TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>allow_new_entries</code></td>
<td>
<p>Boolean, whether the hypermodel is allowed to request hyperparameter entries not listed in 'hyperparameters'. Defaults to TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_retries_per_trial</code></td>
<td>
<p>Integer. Defaults to 0. The maximum number of times to retry a 'Trial' if the trial crashed or the results are invalid.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_consecutive_failed_trials</code></td>
<td>
<p>Integer. Defaults to 3. The maximum number of consecutive failed 'Trial's. When this number is reached, the search will be stopped. A 'Trial' is marked as failed when none of the retries succeeded. **kwargs: Keyword arguments relevant to all 'Tuner' subclasses. Please see the docstring for 'Tuner'.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Some additional arguments</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Reference: Li, Lisha, and Kevin Jamieson. ["Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization." Journal of Machine Learning Research 18 (2018): 1-52]( http://jmlr.org/papers/v18/16-558.html).
</p>


<h3>Value</h3>

<p>a hyperparameter tuner object Hyperband
</p>


<h3>Reference</h3>

<p>Li, Lisha, and Kevin Jamieson. ["Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization." Journal of Machine Learning Research 18 (2018): 1-52]( http://jmlr.org/papers/v18/16-558.html).
</p>


</div>