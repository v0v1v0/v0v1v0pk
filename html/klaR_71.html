<div class="container">

<table style="width: 100%;"><tr>
<td>pvs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Pairwise variable selection for classification</h2>

<h3>Description</h3>

<p>Pairwise variable selection for numerical data, allowing the use of different classifiers and different variable selection methods.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pvs(x, ...)

## Default S3 method:
pvs(x, grouping, prior=NULL, method="lda", 
    vs.method=c("ks.test","stepclass","greedy.wilks"), niveau=0.05, 
    fold=10, impr=0.1, direct="backward", out=FALSE, ...)
    
## S3 method for class 'formula'
pvs(formula, data = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>matrix or data frame containing the explanatory variables 
(required, if <code>formula</code> is not given). x must consist of numerical data only. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>A formula of the form <code>groups ~ x1 + x2 + ...</code>. 
That is, the response is the grouping factor (the classes) and the right hand side 
specifies the (numerical) discriminators. 
Interaction terms are not supported.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data matrix (rows=cases, columns=variables)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>grouping</code></td>
<td>
<p>class indicator vector (a factor)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>prior probabilites for the classes. If not specified the prior probabilities will be set according to proportion in “grouping”. If specified the order of prior 
probabilities must be the same as in “grouping”. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>character, name of classification function (e.g. “<code>lda</code>” (default)).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vs.method</code></td>
<td>
<p>character, name of variable selection method. Must be one of “<code>ks.test</code>” (default),
“<code>stepclass</code>” or “<code>greedy.wilks</code>”. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>niveau</code></td>
<td>
<p>used niveau for “<code>ks.test</code>”</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fold</code></td>
<td>
<p>parameter for cross-validation, if “<code>stepclass</code>” is chosen ‘<code>vs.method</code>’</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>impr</code></td>
<td>
<p>least improvement of performance measure desired to include or exclude any variable (&lt;=1), if “<code>stepclass</code>” is chosen ‘<code>vs.method</code>’ </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>direct</code></td>
<td>
<p>direction of variable selection, if “<code>stepclass</code>” is chosen ‘<code>vs.method</code>’. 
Must be one if “<code>forward</code>”, “<code>backward</code>” (default) or “<code>both</code>”. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>out</code></td>
<td>
<p>indicator (logical) for textoutput during computation (slows down computation!), if “<code>stepclass</code>” is chosen ‘<code>vs.method</code>’ </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further parameters passed to classification function (‘<code>method</code>’) or variable selection method (‘<code>vs.method</code>’) </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The classification “method” (e.g. ‘<code>lda</code>’) must have its own 
‘<code>predict</code>’ method (like ‘<code>predict.lda</code>’ for ‘<code>lda</code>’) 
returns a list with an element ‘<code>posterior</code>’ containing the posterior probabilties. It must be able to deal with matrices as in <code>method(x, grouping, ...)</code>. 
Examples of such classification methods are ‘<code>lda</code>’, ‘<code>qda</code>’, ‘<code>rda</code>’, 
‘<code>NaiveBayes</code>’ or ‘<code>sknn</code>’.\
For the classification methods “<code>svm</code>” and “<code>randomForest</code>” there are special routines implemented, to make them work with ‘<code>pvs</code>’ method even though their ‘<code>predict</code>’ methods don't provide the demanded posteriors. However those two classfiers can not be used together with variable selection method “<code>stepclass</code>”.
</p>
<p>‘<code>pvs</code>’ performs a variable selection using the selection method chosen in ‘<code>vs.method</code>’ for each pair of classes in ‘<code>x</code>’. 
Then for each pair of classes a submodel using ‘<code>method</code>’ is trained (using only the earlier selected variables for this class-pair).
</p>
<p>If ‘<code>method</code>’ is “<code>ks.test</code>”, then for each variable the empirical distribution functions of the cases of both classes are compared via “<code>ks.test</code>”. Only variables with a p-values below ‘<code>niveau</code>’ are used for training the submodel for this pair of classes.
</p>
<p>If ‘<code>method</code>’ is “<code>stepclass</code>” the variable selection is performed using the “<code>stepclass</code>” method.
</p>
<p>If ‘<code>method</code>’ is “<code>greedy.wilks</code>” the variable selection is performed using Wilk's lambda criterion.
</p>


<h3>Value</h3>

<p>An object of class ‘<code>pvs</code>’ containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>classes</code></td>
<td>
<p>the classes in grouping</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>used prior probabilities</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>name of used classification function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vs.method</code></td>
<td>
<p>name of used function for variable selection</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>submodels</code></td>
<td>
<p>containing a list of submodels. For each pair of classes there is a list element being another list of 3 containing the class-pair of this submodel, the selected variables 
for the subspace of classes and the result of the trained classification function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the (matched) function call</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Gero Szepannek, <a href="mailto:szepannek@statistik.tu-dortmund.de">szepannek@statistik.tu-dortmund.de</a>, Christian Neumann</p>


<h3>References</h3>


<ul>
<li>
<p> Szepannek, G. and Weihs, C. (2006)  Variable Selection for Classification of More than Two 
Classes Where the Data are Sparse. In <em>From Data and Information Analysis to Kwnowledge Engineering.</em>,
eds Spiliopolou, M., Kruse, R., Borgelt, C., Nuernberger, A. and Gaul, W. pp. 700-708. Springer, Heidelberg.
</p>
</li>
<li>
<p> Szepannek, G. (2008): Different Subspace Classification - Datenanalyse, -interpretation, -visualisierung und 
Vorhersage in hochdimensionalen Raeumen, ISBN 978-3-8364-6302-7, vdm, Saarbruecken.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>predict.pvs</code> for predicting ‘<code>pvs</code>’ models and <code>locpvs</code> for pairwisevariable selection in local models of several subclasses
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Example 1: learn an "lda" model on the waveform data using pairwise variable 
## selection (pvs) using "ks.test" and compare it to using lda without pvs 

library("mlbench")
trainset &lt;- mlbench.waveform(300) 
pvsmodel &lt;- pvs(trainset$x, trainset$classes, niveau=0.05) # default: using method="lda"
## short summary, showing the class-pairs of the submodels and the selected variables
pvsmodel
 
testset &lt;-  mlbench.waveform(500)
## prediction of the test data set: 
prediction &lt;- predict(pvsmodel, testset$x)

## calculating the test error rate
1-sum(testset$classes==prediction$class)/length(testset$classes)
## Bayes error is 0.149

## comparison to performance of simple lda
ldamodel &lt;- lda(trainset$x, trainset$classes)
LDAprediction &lt;- predict(ldamodel, testset$x)

## test error rate
1-sum(testset$classes==LDAprediction$class)/length(testset$classes)


## Example 2: learn a "qda" model with pvs on half of the Satellite dataset, 
## using "ks.test" 


library("mlbench")
data("Satellite")

## takes few seconds as exact KS tests are calculated here:
model &lt;- pvs(classes ~ ., Satellite[1:3218,], method="qda", vs.method="ks.test")
## short summary, showing the class-pairs of the submodels and the selected variables
model 

## now predict on the rest of the data set:
## pred &lt;- predict(model,Satellite[3219:6435,]) # takes some time
pred &lt;- predict(model,Satellite[3219:6435,], quick=TRUE) # that's much quicker

## now you can look at the predicted classes:
pred$class 
## or the posterior probabilities:
pred$posterior

</code></pre>


</div>