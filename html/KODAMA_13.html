<div class="container">

<table style="width: 100%;"><tr>
<td>knn.kodama</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>k-Nearest Neighbors Classifier.</h2>

<h3>Description</h3>

<p>k-nearest neighbour classification for a test set from a training set.</p>


<h3>Usage</h3>

<pre><code class="language-R">knn.kodama(Xtrain, 
           Ytrain, 
           Xtest,
           Ytest=NULL, 
           k, 
           scaling = c("centering","autoscaling"),
           perm.test=FALSE,
           times=1000)

</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Xtrain</code></td>
<td>
<p>a matrix of training set cases.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ytrain</code></td>
<td>
<p>a classification vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Xtest</code></td>
<td>
<p>a matrix of test set cases.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Ytest</code></td>
<td>
<p>a classification vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the number of nearest neighbors to consider.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scaling</code></td>
<td>
<p>the scaling method to be used. Choices are "<code>centering</code>" or "<code>autoscaling</code>" (by default = "<code>centering</code>"). A partial string sufficient to uniquely identify the choice is permitted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>perm.test</code></td>
<td>
<p>a classification vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>times</code></td>
<td>
<p>a classification vector.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function utilizes the Approximate Nearest Neighbor (ANN) C++ library, 
which can give the exact nearest neighbours or (as the name suggests) 
approximate nearest neighbours to within a specified error bound.  For more 
information on the ANN library please visit http://www.cs.umd.edu/~mount/ANN/.
</p>


<h3>Value</h3>

<p>The function returns a vector of predicted labels.</p>


<h3>Author(s)</h3>

<p>Stefano Cacciatore and Leonardo Tenori</p>


<h3>References</h3>

<p>Bentley JL (1975)<br>
Multidimensional binary search trees used for associative search. <br><em>Communication ACM</em> 1975;18:309-517.<br><br></p>
<p>Arya S, Mount DM<br>
Approximate nearest neighbor searching<br><em>Proc. 4th Ann. ACM-SIAM Symposium on Discrete Algorithms (SODA'93)</em>;271-280.<br><br></p>
<p>Arya S, Mount DM, Netanyahu NS, Silverman R, Wu AY<br>
An optimal algorithm for approximate nearest neighbor searching<br><em>Journal of the ACM</em> 1998;45:891-923.<br><br></p>
<p>Cacciatore S, Luchinat C, Tenori L	<br>
Knowledge discovery by accuracy maximization.<br><em>Proc Natl Acad Sci U S A</em> 2014;111(14):5117-22. doi: 10.1073/pnas.1220873111. <a href="https://www.pnas.org/doi/10.1073/pnas.1220873111">Link</a>
<br><br>
Cacciatore S, Tenori L, Luchinat C, Bennett PR, MacIntyre DA	<br>
KODAMA: an updated R package for knowledge discovery and data mining.	<br><em>Bioinformatics</em> 2017;33(4):621-623. doi: 10.1093/bioinformatics/btw705. <a href="https://academic.oup.com/bioinformatics/article/33/4/621/2667156">Link</a>
</p>


<h3>See Also</h3>

<p><code>KODAMA.matrix</code>,<code>KODAMA.visualization</code></p>


<h3>Examples</h3>

<pre><code class="language-R"> data(iris)
 data=iris[,-5]
 labels=iris[,5]
 ss=sample(150,15)

 z=knn.kodama(data[-ss,], labels[-ss], data[ss,], k=5) 
 table(z$Ypred[,5],labels[ss])
</code></pre>


</div>