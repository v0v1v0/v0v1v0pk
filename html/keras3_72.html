<div class="container">

<table style="width: 100%;"><tr>
<td>application_vgg16</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Instantiates the VGG16 model.</h2>

<h3>Description</h3>

<p>Instantiates the VGG16 model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">application_vgg16(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000L,
  classifier_activation = "softmax",
  name = "vgg16"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>include_top</code></td>
<td>
<p>whether to include the 3 fully-connected
layers at the top of the network.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>one of <code>NULL</code> (random initialization),
<code>"imagenet"</code> (pre-training on ImageNet),
or the path to the weights file to be loaded.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_tensor</code></td>
<td>
<p>optional Keras tensor
(i.e. output of <code>keras_input()</code>)
to use as image input for the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_shape</code></td>
<td>
<p>optional shape tuple, only to be specified
if <code>include_top</code> is <code>FALSE</code> (otherwise the input shape
has to be <code style="white-space: pre;">⁠(224, 224, 3)⁠</code>
(with <code>channels_last</code> data format) or
<code style="white-space: pre;">⁠(3, 224, 224)⁠</code> (with <code>"channels_first"</code> data format).
It should have exactly 3 input channels,
and width and height should be no smaller than 32.
E.g. <code style="white-space: pre;">⁠(200, 200, 3)⁠</code> would be one valid value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model will be
the 4D tensor output of the
last convolutional block.
</p>
</li>
<li> <p><code>avg</code> means that global average pooling
will be applied to the output of the
last convolutional block, and thus
the output of the model will be a 2D tensor.
</p>
</li>
<li> <p><code>max</code> means that global max pooling will
be applied.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classes</code></td>
<td>
<p>optional number of classes to classify images
into, only to be specified if <code>include_top</code> is <code>TRUE</code>, and
if no <code>weights</code> argument is specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifier_activation</code></td>
<td>
<p>A <code>str</code> or callable. The activation function to
use on the "top" layer. Ignored unless <code>include_top=TRUE</code>. Set
<code>classifier_activation=NULL</code> to return the logits of the "top"
layer.  When loading pretrained weights, <code>classifier_activation</code>
can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>The name of the model (string).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A <code>Model</code> instance.
</p>


<h3>Reference</h3>


<ul><li> <p><a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> (ICLR 2015)
</p>
</li></ul>
<p>For image classification use cases, see
<a href="https://keras.io/api/applications/#usage-examples-for-image-classification-models">this page for detailed examples</a>.
</p>
<p>For transfer learning use cases, make sure to read the
<a href="https://keras.io/guides/transfer_learning/">guide to transfer learning &amp; fine-tuning</a>.
</p>
<p>The default input size for this model is 224x224.
</p>


<h3>Note</h3>

<p>Each Keras Application expects a specific kind of input preprocessing.
For VGG16, call <code>application_preprocess_inputs()</code> on your
inputs before passing them to the model.
<code>application_preprocess_inputs()</code> will convert the input images from RGB to BGR,
then will zero-center each color channel with respect to the ImageNet
dataset, without scaling.
</p>


<h3>See Also</h3>


<ul><li> <p><a href="https://keras.io/api/applications/vgg#vgg16-function">https://keras.io/api/applications/vgg#vgg16-function</a>
</p>
</li></ul>
</div>