<div class="container">

<table style="width: 100%;"><tr>
<td>kedd-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Kernel Estimator and Bandwidth Selection for Density and Its Derivatives
</h2>

<h3>Description</h3>

<p>Smoothing techniques and computing bandwidth selectors of the 
r'th derivative of a probability density for one-dimensional data.
</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> kedd</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 1.0.4</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2024-01-27</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL (&gt;= 2) </td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<p>There are four main types of functions in this package:
</p>

<ol>
<li>
<p> Compute the derivatives and convolutions of a kernel function (1-d). 
</p>
</li>
<li>
<p> Compute the kernel estimators for density and its derivatives (1-d). 
</p>
</li>
<li>
<p> Computing the bandwidth selectors (1-d).
</p>
</li>
<li>
<p> Displaying kernel estimators.
</p>
</li>
</ol>
<h3>Main Features</h3>

<p><b>Convolutions and derivatives in kernel function:</b><br><br>
In non-parametric statistics, a kernel is a weighting function used in non-parametric estimation techniques. 
The kernels functions <code class="reqn">K(x)</code> are used in derivatives of kernel density estimator to estimate 
<code class="reqn">\hat{f}^{(r)}_{h}(x)</code>, satisfying the following three requirements:
</p>

<ol>
<li> <p><code class="reqn">\int_{R} K(x) dx = 1</code>
</p>
</li>
<li> <p><code class="reqn">\int_{R} xK(x) dx = 0</code>
</p>
</li>
<li> <p><code class="reqn">\mu_{2}(K) = \int_{R}x^{2} K(x) dx &lt; \infty</code>
</p>
</li>
</ol>
<p>Several types of kernel functions <code class="reqn">K(x)</code> are commonly used in this package: Gaussian, Epanechnikov, Uniform (rectangular), Triangular, 
Triweight, Tricube, Biweight (quartic), Cosine.<br></p>
<p>The function <code>kernel.fun</code> for kernel derivative <code class="reqn">K^{(r)}(x)</code> and <code>kernel.conv</code> for 
kernel convolution <code class="reqn">K^{(r)}\ast K^{(r)} (x)</code>, where the write formally:
</p>
<p style="text-align: center;"><code class="reqn">K^{(r)}(x) = \frac{d^{r}}{d x^{r}} K(x)</code>
</p>
  
<p style="text-align: center;"><code class="reqn">K^{(r)} \ast K^{(r)} (x) = \int_{-\infty}^{+\infty} K^{(r)}(y)K^{(r)}(x-y)dy</code>
</p>

<p>for <code class="reqn">r = 0, 1, 2, \dots</code><br></p>
<p><b>Estimators of r'th derivative of a density function:</b><br><br>
A <dfn>natural estimator</dfn> of the r'th derivative of a density function <code class="reqn">f(x)</code> is:   
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}^{(r)}_{h}(x)= \frac{d^{r}}{d x^{r}} \frac{1}{nh} \sum_{i=1}^{n} K\left(\frac{x-X_{i}}{h}\right) =
                          \frac{1}{nh^{r+1}}\sum_{i=1}^{n} K^{(r)}\left(\frac{x-X_{i}}{h}\right)</code>
</p>

<p>Here, <code class="reqn">X_{1}, X_{2}, \dots,X_{n}</code> is an i.i.d, sample of size <code class="reqn">n</code> from the distribution with density 
<code class="reqn">f(x)</code>, <code class="reqn">K(x)</code> is the kernel function which we take to be a symmetric probability density with 
at least <code class="reqn">r</code> non zero derivatives when estimating <code class="reqn">f^{(r)}(x)</code>, and <code class="reqn">h</code> is the bandwidth,
this parameter is very important that controls the degree of smoothing applied to the data.<br></p>
<p>The case <code class="reqn">(r=0)</code> is the standard kernel density estimator (e.g. Silverman 1986, Wolfgang 1991, Scott 1992, 
Wand and Jones 1995, Jeffrey 1996, Bowman and Azzalini 1997, Alexandre 2009), properties of such derivative 
estimators are well known e.g. Sheather and Jones (1991), Jones and Kappenman (1991), Wolfgang (1991). For 
the case <code class="reqn">(r &gt; 0)</code>, is derivative of kernel density estimator (e.g. Bhattacharya 1967, Schuster 1969, Alekseev 1972, 
Wolfgang et all 1990, Jones 1992, Stoker 1993) and for applications which require the estimation of density derivatives can 
be found in Singh (1977).<br></p>
<p>For r'th derivatives of kernel density estimator one-dimensional, the main function is <code>dkde</code>. For display, 
its plot method calls <code>plot.dkde</code>, and if to add a plot using <code>lines.dkde</code>.
</p>
<pre>
  R&gt; data(trimodal)
  R&gt; dkde(x = trimodal, deriv.order = 0, kernel = "gaussian")
   
    Data: trimodal (200 obs.);      Kernel: gaussian
    Derivative order: 0;    Bandwidth 'h' = 0.1007
          eval.points           est.fx         
    Min.   :-2.91274   Min.   :0.0000066  
    1st Qu.:-1.46519   1st Qu.:0.0669750  
    Median :-0.01765   Median :0.1682045  
    Mean   :-0.01765   Mean   :0.1723692  
    3rd Qu.: 1.42989   3rd Qu.:0.2484626  
    Max.   : 2.87743   Max.   :0.4157340 
   
  R&gt; dkde(x = trimodal, deriv.order = 1, kernel = "gaussian")
  
    Data: trimodal (200 obs.);      Kernel: gaussian
    Derivative order: 1;    Bandwidth 'h' = 0.09094
          eval.points           est.fx         
    Min.   :-2.87358   Min.   :-1.740447  
    1st Qu.:-1.44562   1st Qu.:-0.343952  
    Median :-0.01765   Median : 0.009057  
    Mean   :-0.01765   Mean   : 0.000000  
    3rd Qu.: 1.41031   3rd Qu.: 0.415343  
    Max.   : 2.83828   Max.   : 1.256891  
  </pre>
<p><b>Bandwidth selectors:</b><br><br>
The most important factor in the r'th derivative kernel density estimate is a choice of the bandwidth 
<code class="reqn">h</code> for one-dimensional observations. Because of its role in controlling both the amount and 
the direction of smoothing, this choice is particularly important. We present the popular bandwidth 
selection (for more details see references) methods in this package:
</p>

<ul>
<li>
<p> Optimal Bandwidth (AMISE); with <code>deriv.order &gt;= 0</code>, name of this function is <code>h.amise</code>.<br> 
For display, its plot method calls <code>plot.h.amise</code>, and to add a plot used <code>lines.h.amise</code>.
</p>
</li>
<li>
<p> Maximum-likelihood cross-validation (MLCV); with <code>deriv.order = 0</code>, name of this function is <code>h.mlcv</code>.<br>
For display, its plot method calls <code>plot.h.mlcv</code>, and to add a plot used <code>lines.h.mlcv</code>. 
</p>
</li>
<li>
<p> Unbiased cross validation (UCV); with <code>deriv.order &gt;= 0</code>, name of this function is <code>h.ucv</code>.<br>
For display, its plot method calls <code>plot.h.ucv</code>, and to add a plot used <code>lines.h.ucv</code>.
</p>
</li>
<li>
<p> Biased cross validation (BCV); with <code>deriv.order &gt;= 0</code>, name of this function is <code>h.bcv</code>.<br>
For display, its plot method calls <code>plot.h.bcv</code>, and to add a plot used <code>lines.h.bcv</code>.
</p>
</li>
<li>
<p> Complete cross-validation (CCV); with <code>deriv.order &gt;= 0</code>, name of this function is <code>h.ccv</code>.<br>
For display, its plot method calls <code>plot.h.ccv</code>, and to add a plot used <code>lines.h.ccv</code>.
</p>
</li>
<li>
<p> Modified cross-validation (MCV); with <code>deriv.order &gt;= 0</code>, name of this function is <code>h.mcv</code>.<br>
For display, its plot method calls <code>plot.h.mcv</code>, and to add a plot used <code>lines.h.mcv</code>.
</p>
</li>
<li>
<p> Trimmed cross-validation (TCV); with <code>deriv.order &gt;= 0</code>, name of this function is <code>h.tcv</code>.<br>
For display, its plot method calls <code>plot.h.tcv</code>, and to add a plot used <code>lines.h.tcv</code>.
</p>
</li>
</ul>
<pre>
  R&gt; data(trimodal)
  R&gt; h.bcv(x = trimodal, whichbcv = 1, deriv.order = 0, kernel = "gaussian")
  
    Call:           Biased Cross-Validation 1
    Derivative order = 0
    Data: trimodal (200 obs.);      Kernel: gaussian
    Min BCV = 0.004511636;  Bandwidth 'h' = 0.4357812 
	
  R&gt; h.ccv(x = trimodal, deriv.order = 1, kernel = "gaussian")	
  
    Call:           Complete Cross-Validation
    Derivative order = 1 
    Data: trimodal (200 obs.);      Kernel: gaussian
    Min CCV = 0.01985078;   Bandwidth 'h' = 0.5828336
	
  R&gt; h.tcv(x = trimodal, deriv.order = 2, kernel = "gaussian")
  
    Call:           Trimmed Cross-Validation
    Derivative order = 2
    Data: trimodal (200 obs.);      Kernel: gaussian
    Min TCV = -295.563;     Bandwidth 'h' = 0.08908582
	
  R&gt; h.ucv(x = trimodal, deriv.order = 3, kernel = "gaussian")

    Call:           Unbiased Cross-Validation
    Derivative order = 3
    Data: trimodal (200 obs.);      Kernel: gaussian
    Min UCV = -63165.18;    Bandwidth 'h' = 0.1067236  
  </pre>
<p>For an overview of this package, see <code>vignette("kedd")</code>.  
</p>


<h3>Requirements</h3>

<p><span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> version &gt;= 2.15.0
</p>


<h3>Licence</h3>

<p>This package and its documentation are usable under the terms of the "GNU
General Public License", a copy of which is distributed with the package.
</p>


<h3>References</h3>

<p>Alekseev, V. G. (1972).
Estimation of a probability density function and its derivatives.
<em>Mathematical notes of the Academy of Sciences of the USSR</em>. <b>12</b>(5), 808–811.
</p>
<p>Alexandre, B. T. (2009).
<em>Introduction to Nonparametric Estimation</em>.
Springer-Verlag, New York.
</p>
<p>Bowman, A. W. (1984). 
An alternative method of cross-validation for the smoothing 
of kernel density estimates. 
<em>Biometrika</em>, <b>71</b>, 353–360.
</p>
<p>Bowman, A. W. and Azzalini, A. (1997). 
<em>Applied Smoothing Techniques for
Data Analysis: the Kernel Approach with 
S-Plus Illustrations</em>.
Oxford University Press, Oxford.
</p>
<p>Bowman, A.W. and Azzalini, A. (2003).
Computational aspects of nonparametric smoothing
with illustrations from the <a href="https://CRAN.R-project.org/package=sm"><span class="pkg">sm</span></a> library.
<em>Computational Statistics and Data Analysis</em>, <b>42</b>, 545–560.
</p>
<p>Bowman, A.W. and Azzalini, A. (2013).
<a href="https://CRAN.R-project.org/package=sm"><span class="pkg">sm</span></a>: Smoothing methods for nonparametric 
regression and density estimation. 
<em><span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> package version 2.2-5.3</em>. Ported to <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> by B. D. Ripley.
</p>
<p>Bhattacharya, P. K. (1967).
Estimation of a probability density function and Its derivatives.
<em>Sankhya: The Indian Journal of Statistics, Series A</em>, <b>29</b>, 373–382. 
</p>
<p>Duin, R. P. W. (1976).
On the choice of smoothing parameters of Parzen estimators of probability density functions. 
<em>IEEE Transactions on Computers</em>, <b>C-25</b>, 1175–1179.
</p>
<p>Feluch, W. and Koronacki, J. (1992).
A note on modified cross-validation in density estimation.
<em>Computational Statistics and Data Analysis</em>, <b>13</b>, 143–151.
</p>
<p>George, R. T. (1990).
The maximal smoothing principle in density estimation. 
<em>Journal of the American Statistical Association</em>, <b>85</b>, 470–477.
</p>
<p>George, R. T. and Scott, D. W. (1985).
Oversmoothed nonparametric density estimates. 
<em>Journal of the American Statistical Association</em>, <b>80</b>, 209–214.
</p>
<p>Habbema, J. D. F., Hermans, J., and Van den Broek, K. (1974)
A stepwise discrimination analysis program using density estimation. 
<em>Compstat 1974: Proceedings in Computational Statistics</em>. Physica Verlag, Vienna.
</p>
<p>Heidenreich, N. B., Schindler, A. and Sperlich, S. (2013).
Bandwidth selection for kernel density estimation: 
a review of fully automatic selectors.
<em>Advances in Statistical Analysis</em>.
</p>
<p>Jeffrey, S. S. (1996).
<em>Smoothing Methods in Statistics</em>.
Springer-Verlag, New York.
</p>
<p>Jones, M. C. (1992).
Differences and derivatives in kernel estimation. 
<em>Metrika</em>, <b>39</b>, 335–340.
</p>
<p>Jones, M. C., Marron, J. S. and Sheather,S. J. (1996).
A brief survey of bandwidth selection for density estimation. 
<em>Journal of the American Statistical Association</em>, <b>91</b>, 401–407.
</p>
<p>Jones, M. C. and Kappenman, R. F. (1991). 
On a class of kernel density estimate bandwidth selectors. 
<em>Scandinavian Journal of Statistics</em>, <b>19</b>, 337–349.
</p>
<p>Loader, C. (1999). 
<em>Local Regression and Likelihood</em>. 
Springer, New York.
</p>
<p>Olver, F. W., Lozier, D. W., Boisvert, R. F. and Clark, C. W. (2010).
<em>NIST Handbook of Mathematical Functions</em>.
Cambridge University Press, New York, USA.
</p>
<p>Peter, H. and Marron, J.S. (1987).
Estimation of integrated squared density derivatives.
<em>Statistics and Probability Letters</em>, <b>6</b>, 109–115.
</p>
<p>Peter, H. and Marron, J.S. (1991).
Local minima in cross-validation functions.
<em>Journal of the Royal Statistical Society, Series B</em>, <b>53</b>, 245–252.
</p>
<p>Radhey, S. S. (1987).
MISE of kernel estimates of a density and its derivatives.
<em>Statistics and Probability Letters</em>, <b>5</b>, 153–159.
</p>
<p>Rudemo, M. (1982). 
Empirical choice of histograms and kernel density estimators. 
<em>Scandinavian Journal of Statistics</em>, <b>9</b>, 65–78.
</p>
<p>Scott, D. W. (1992).
<em>Multivariate Density Estimation. Theory, Practice and Visualization</em>.
New York: Wiley.
</p>
<p>Scott, D.W. and George, R. T. (1987).
Biased and unbiased cross-validation in density estimation. 
<em>Journal of the American Statistical Association</em>, <b>82</b>, 1131–1146.
</p>
<p>Schuster, E. F. (1969) 
Estimation of a probability density function and its derivatives. 
<em>The Annals of Mathematical Statistics</em>, <b>40</b> (4), 1187–1195.
</p>
<p>Sheather, S. J. (2004).
Density estimation.
<em>Statistical Science</em>, <b>19</b>, 588–597.
</p>
<p>Sheather, S. J. and Jones, M. C. (1991).
A reliable data-based bandwidth selection method for 
kernel density estimation.
<em>Journal of the Royal Statistical Society, Series B</em>, <b>53</b>, 683–690.
</p>
<p>Silverman, B. W. (1986).
<em>Density Estimation for Statistics and Data Analysis</em>.
Chapman &amp; Hall/CRC. London.
</p>
<p>Singh, R. S. (1977).                            
Applications of estimators of a density and 
its derivatives to certain statistical problems.
<em>Journal of the Royal Statistical Society, Series B</em>, <b>39</b>(3), 357–363.
</p>
<p>Stoker, T. M. (1993).
Smoothing bias in density derivative estimation. 
<em>Journal of the American Statistical Association</em>, <b>88</b>, 855–863.
</p>
<p>Stute, W. (1992).
Modified cross validation in density estimation.
<em>Journal of Statistical Planning and Inference</em>, <b>30</b>, 293–305.
</p>
<p>Tarn, D. (2007).
<a href="https://CRAN.R-project.org/package=ks"><span class="pkg">ks</span></a>: Kernel density estimation and kernel discriminant
analysis for multivariate data in <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>.
<em>Journal of Statistical Software</em>, <b>21</b>(7), 1–16. 
</p>
<p>Tristen, H. and Jeffrey, S. R. (2008).
Nonparametric Econometrics: The <a href="https://CRAN.R-project.org/package=np"><span class="pkg">np</span></a> Package.
<em>Journal of Statistical Software</em>,<b>27</b>(5).
</p>
<p>Venables, W. N. and Ripley, B. D. (2002).
<em>Modern Applied Statistics with S</em>.
New York: Springer.
</p>
<p>Wand, M. P. and Jones, M. C. (1995).
<em>Kernel Smoothing</em>.
Chapman and Hall, London.
</p>
<p>Wand, M.P. and Ripley, B. D. (2013). 
<a href="https://CRAN.R-project.org/package=KernSmooth"><span class="pkg">KernSmooth</span></a>: Functions for Kernel Smoothing 
for Wand and Jones (1995). 
<em><span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> package version 2.23-10</em>. 
</p>
<p>Wolfgang, H. (1991).
<em>Smoothing Techniques</em>, 
<em>With Implementation in S</em>.
Springer-Verlag, New York.
</p>
<p>Wolfgang, H., Marlene, M., Stefan, S. and Axel, W. (2004).
<em>Nonparametric and Semiparametric Models</em>.
Springer-Verlag, Berlin Heidelberg.
</p>
<p>Wolfgang, H., Marron, J. S. and Wand, M. P. (1990).
Bandwidth choice for density derivatives.
<em>Journal of the Royal Statistical Society, Series B</em>, 223–232.
</p>


<h3>See Also</h3>

<p><a href="https://CRAN.R-project.org/package=ks"><span class="pkg">ks</span></a>, <a href="https://CRAN.R-project.org/package=KernSmooth"><span class="pkg">KernSmooth</span></a>, <a href="https://CRAN.R-project.org/package=sm"><span class="pkg">sm</span></a>, <a href="https://CRAN.R-project.org/package=np"><span class="pkg">np</span></a>, <a href="https://CRAN.R-project.org/package=locfit"><span class="pkg">locfit</span></a>, <a href="https://CRAN.R-project.org/package=feature"><span class="pkg">feature</span></a>, <a href="https://CRAN.R-project.org/package=GenKern"><span class="pkg">GenKern</span></a>.
</p>


</div>