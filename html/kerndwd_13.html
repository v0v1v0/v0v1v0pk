<div class="container">

<table style="width: 100%;"><tr>
<td>plot.cv.kerndwd</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>plot the cross-validation curve</h2>

<h3>Description</h3>

<p>Plot cross-validation error curves with the upper and lower standard deviations versus log <code>lambda</code> values.</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'cv.kerndwd'
plot(x, sign.lambda, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A fitted <code>cv.kerndwd</code> object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sign.lambda</code></td>
<td>
<p>Against <code>log(lambda)</code> (default) or its negative if <code>sign.lambda=-1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other graphical parameters being passed to <code>plot</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function plots the cross-validation error curves. This function is modified based on the <code>plot.cv</code> function of the <code>glmnet</code> package.
</p>


<h3>Author(s)</h3>

<p>Boxiang Wang and Hui Zou<br>
Maintainer: Boxiang Wang  <a href="mailto:boxiang-wang@uiowa.edu">boxiang-wang@uiowa.edu</a></p>


<h3>References</h3>

<p>Wang, B. and Zou, H. (2018)
“Another Look at Distance Weighted Discrimination," 
<em>Journal of Royal Statistical Society, Series B</em>, <b>80</b>(1), 177–198. <br><a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12244">https://rss.onlinelibrary.wiley.com/doi/10.1111/rssb.12244</a><br></p>
<p>Friedman, J., Hastie, T., and Tibshirani, R. (2010), "Regularization paths for generalized
linear models via coordinate descent," <em>Journal of Statistical Software</em>, <b>33</b>(1), 1–22.<br><a href="https://www.jstatsoft.org/v33/i01/paper">https://www.jstatsoft.org/v33/i01/paper</a>
</p>


<h3>See Also</h3>

<p><code>cv.kerndwd</code>.</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(1)
data(BUPA)
BUPA$X = scale(BUPA$X, center=TRUE, scale=TRUE)
lambda = 10^(seq(-3, 3, length.out=10))
kern = rbfdot(sigma=sigest(BUPA$X))
m.cv = cv.kerndwd(BUPA$X, BUPA$y, kern,
  qval=1, lambda=lambda, eps=1e-5, maxit=1e5)
m.cv
</code></pre>


</div>