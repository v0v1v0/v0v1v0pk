<div class="container">

<table style="width: 100%;"><tr>
<td>KS2sample</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Computes the p-value for a (weighted) two-sample Kolmogorov-Smirnov test, given an arbitrary positive weight function and arbitrary data samples with possibly repeated observations (i.e. ties)
</h2>

<h3>Description</h3>

<p>Computes the p-value <code class="reqn">P(D_{m,n} \ge q)</code>, where <code class="reqn">D_{m,n}</code> is the one- or two-sided two-sample Kolmogorov-Smirnov test statistic with weight function <code>weight</code>, when <code class="reqn">q</code> = <code>d</code>, i.e. the observed value of KS statistic computed based on two data samples <code class="reqn">\{x_{1},..., x_{m}\}</code> and <code class="reqn">\{y_{1},..., y_{n}\}</code> that may come from continuous, discrete or mixed distribution, i.e. they may have repeated observations (ties).
</p>


<h3>Usage</h3>

<pre><code class="language-R">KS2sample(x, y, alternative = c("two.sided", "less", "greater"),
conservative = F, weight = 0, tol = 1e-08, tail = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{x_{1}, ..., x_{m}\}</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{y_{1}, ..., y_{n}\}</code>
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>

<p>Indicates the alternative hypothesis and must be one of "two.sided" (default), "less", or "greater". One can specify just the initial letter of the string, but the argument name must be given in full, e.g. <code>alternative = "t"</code>.   See ‘Details’ for the meaning of the possible values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conservative</code></td>
<td>

<p>logical variable indicating whether ties should be considered. See ‘Details’ for the meaning.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight</code></td>
<td>

<p>either a numeric value between 0 and 1 which specifies the form of the weight function from a class of pre-defined functions, or a user-defined strictly positive function of one variable. By default, no weight function is assumed. See ‘Details’ for the meaning of the possible values.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
 
<p>the value of <code class="reqn">\epsilon</code> for computing <code class="reqn">P(D_{m,n} &gt;q- \epsilon)</code>, which is equivalent to <code class="reqn">P(D_{m,n} \geq q)</code>. Non-positive input (<code>tol</code> <code class="reqn">\leq 0</code>) or large input (<code>tol</code> <code class="reqn">&gt;</code><code>1e-6</code>) are replaced by <code>tol = 1e-6</code>. In cases when <code>m</code> and <code>n</code> have large least common multiple, a smaller value is highly recommended.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tail</code></td>
<td>

<p>logical variable indicating whether a p-value, <code class="reqn">P(D_{m,n} \ge q)</code> or one minus the p-value, <code class="reqn">P(D_{m,n} &lt; q)</code>, should be computed. By default, the p-value <code class="reqn">P(D_{m,n} \ge q)</code> is computed.  See ‘Details’ for the meaning.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Given a pair of random samples <code class="reqn">\bm{X}_m=(X_{1},..., X_{m})</code> and <code class="reqn">\bm{Y}_n=(Y_{1},..., Y_{n})</code> of sizes <code>m</code> and <code>n</code> with empirical cdfs <code class="reqn">F_{m}(t)</code> and <code class="reqn">G_{n}(t)</code> respectively, coming from some unknown cdfs <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code>. It is assumed that <code class="reqn">F(x)</code> and <code class="reqn">G(x)</code> could be either <em>continuous</em>, <em>discrete</em> or <em>mixed</em>, which means that repeated observations are allowed in the corresponding observed samples. The task is to test the null hypothesis <code class="reqn">H_0: F(x) = G(x)</code>  for all <code class="reqn">x</code>,  either against the alternative hypothesis <code class="reqn">H_1: F(x)\neq G(x)</code>  for at least one <code class="reqn">x</code>, which corresponds to the two-sided test, or against <code class="reqn">H_1: F(x)&gt; G(x)</code>  and <code class="reqn">H_1: F(x)&lt; G(x)</code>   for at least one <code class="reqn">x</code>, which corresponds to the two one-sided tests. The (weighted) two-sample Kolmogorov-Smirnov goodness-of-fit statistics that are used to test these hypotheses are generally defined as:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{m,n} = \sup |F_{m}(t) - G_n(t)|W(E_{m+n}(t), \textnormal{ to test against the alternative } H_1: F(x)\neq G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{+} = \sup [F_{m}(t) - G_n(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&gt; G(x)</code>
</p>
 
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}^{-} = \sup [G_n(t) - F_{m}(x)]W(E_{m+n}(t)), \textnormal{ to test against the alternative } H_1: F(x)&lt; G(x), </code>
</p>

<p>where <code class="reqn">E_{m+n}(t)</code> is the empirical cdf of the pooled sample <code class="reqn">\bm{Z}_{m,n}=(X_{1},..., X_{m},Y_{1},..., Y_{n})</code>, <code class="reqn">W( )</code> is a strictly positive weight function defined on <code class="reqn">[0,1]</code>. 
</p>
<p>Possible values of <code>alternative</code> are <code>"two.sided"</code>, <code>"greater"</code> and <code>"less"</code> which specify the alternative hypothesis, i.e. specify the test statistics to be either <code class="reqn">\Delta_{m,n}</code>, <code class="reqn">\Delta_{m,n}^{+}</code> or  <code class="reqn">\Delta_{m,n}^{-}</code> respectively. 
</p>
<p>When <code>weight</code> is assigned with a numeric value <code class="reqn">\nu</code> between <code>0</code> and <code>1</code>, the test statistic is specified as the weighted two-sample Kolmorogov-Smirnov test with generalized Anderson-Darling weight <code class="reqn">W(t)=1/[t(1-t)]^{\nu}</code> (see Finner and Gontscharuk 2018). Then for example, the two-sided two-sample Kolmogorov-Smirnov statistic has the following form:
</p>
<p style="text-align: center;"><code class="reqn">\Delta_{m,n}=\sup\limits_{t} \frac{|F_m(t)-G_n(t)|}{[E_{m+n}(t)(1-E_{m+n}(t))]^{\nu}}</code>
</p>

<p>The latter specification defines a family of weighted Kolmogorov-Smirnov tests, covering the unweighted test (when <code>weight = </code> <code class="reqn">\nu = 0</code>), and the widely-known weighted Kolmogorov-Smirnov test with Anderson-Darling weight (when <code>weight = 0.5</code>, see definition of this statistic also in Canner 1975).
If one wants to implement a weighted test with a user-specified weight function, for example, <code class="reqn">W(t)=1/[t(2-t)]^{1/2}</code> suggested by Buning (2001), which ensures higher power when both <code>x</code> and <code>y</code> come from distributions that are left-skewed and heavy-tailed, one can directly assign a univariate function with output value <code>1/sqrt(t*(2-t))</code> to <code>weight</code>.  See ‘Examples’ for this demonstration.
</p>
<p>For a particular realization of the pooled sample <code class="reqn">\bm{Z}_{m,n}</code>, let there be <code class="reqn">k</code> distinct values, <code class="reqn">a_1&lt;a_2&lt;...&lt;a_k</code>, in the ordered, pooled sample <code class="reqn">(z_1\leq z_2\leq \ldots \leq z_{m+n})</code>, where <code class="reqn">k\leq m+n</code>, and where <code class="reqn">m_i</code> is the number of times <code class="reqn">a_i</code>, <code class="reqn">i=1,\ldots,k</code> appears in the pooled sample. The p-value is then defined as the probability
</p>
<p style="text-align: center;"><code class="reqn">p=P\left(D_{m,n}\geq q\right),</code>
</p>

<p>where <code class="reqn">D_{m,n}</code> is the two-sample Kolmogorov-Smirnov test statistic defined according to the value of <code>weight</code> and <code>alternative</code>, for two samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code> of sizes <code class="reqn">m</code> and <code class="reqn">n</code>, <em>randomly drawn from the pooled sample without replacement</em> and <code class="reqn">q</code> = <code>d</code>, the observed value of the statistic calculated based on the user provided data samples <code>x</code> and <code>y</code>. By default <code>tail = T</code>, the p-value is returned, otherwise <code class="reqn">1 - p</code> is returned.
</p>
<p>Note that, <code class="reqn">D_{m,n}</code> is defined on the space <code class="reqn">\Omega</code> of all possible pairs,  <code class="reqn">C = \frac{(m+n)!}{m!n!}</code>  of edfs <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code>, <code class="reqn">\omega \in \Omega</code>, that correspond to the pairs of samples <code class="reqn">\bm{X}'_m</code> and  <code class="reqn">\bm{Y}'_n</code>, randomly drawn from, <code class="reqn">\bm{Z}_{m+n}</code>, as follows.  First, <code class="reqn">m</code> observations are drawn at random without replacement, forming the first sample <code class="reqn">\bm{X}'_m</code>, with corresponding edf, <code class="reqn">F_m(x,\omega)</code>. The remaining <code class="reqn">n</code> observations are then assigned to the second sample <code class="reqn">\bm{Y}'_n</code>, with corresponding edf <code class="reqn">G_n(x,\omega)</code>. Observations are then replaced back in <code class="reqn">\bm{Z}_{m+n}</code> and re-sampling is continued until the occurrence of all the <code class="reqn">C</code> possible pairs of edfs <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code>,  <code class="reqn">\omega \in \Omega</code>. The pairs of edf's may be coincident if there are ties in the data and each pair, <code class="reqn">F_m(x,\omega)</code> and <code class="reqn">G_n(x,\omega)</code> occurs with probability <code class="reqn">1/C</code>.
</p>
<p><code>conservative</code> is a logical variable whether the test should be conducted conservatively. By default, <code>conservative = F</code>, <code>KS2sample</code> returns the p-value that is defined through the conditional probability above. However, when the user has a priori knowledge that both samples are from a continuous distribution even if ties are present, for example, repeated observations are caused by rounding errors, the value <code>conservative = T</code> should be assigned, since the conditional probability is no longer relevant. In this case, <code>KS2sample</code> computes p-values for the Kolmogorov-Smirnov test assuming no ties are present, and returns a p-value which is an upper bound of the true p-value. Note that, if the null hypothesis is rejected using the calculated upper bound for the p-value, it should also be rejected with the true p-value.
</p>
<p><code>KS2sample</code> calculates the exact p-value of the KS test using an algorithm which generalizes the method due to Nikiforov (1994). If <code>tail = F</code>, <code>KS2sample</code> calculates the complementary p-value, <code class="reqn">1 - p</code>. For the purpose, an exact algorithm which generalizes the method due to Nikiforov (1994) is implemented. Alternatively, if <code>tail = T</code>, a version of the Nikiforov's recurrence proposed recently by Viehmann (2021) is implemented, which computes directly the p-value, with higher accuracy, giving up to 17 correct digits, but at up to 3 times higher computational cost. <code>KS2sample</code> ensures a total worst-case run-time of order <code class="reqn">O(nm)</code>. In comparison with other known algorithms, it not only allows the flexible choice of weights which in some cases improve the statistical power (see Dimitrova, Jia, Kaishev 2024), but also is more efficient and generally applicable for <em>large sample sizes</em>.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>statistic</code></td>
<td>
<p>the value of the test statistic <code>d</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>
<p>the p-value of the test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative</code></td>
<td>
<p>a character string describing the alternative
hypothesis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>
<p>a character string giving names of the data.</p>
</td>
</tr>
</table>
<h3>Source</h3>

<p>Based on the Fortran subroutine by Nikiforov (1994). See also Dimitrova, Jia, Kaishev (2024).
</p>


<h3>References</h3>

<p>Buning H (2001). "Kolmogorov-Smirnov- and Cramer-von Mises Type Two-sample Tests With Various Weight Functions." Communications in Statistics - Simulation and Computation, <b>30</b>(4), 847-865.
</p>
<p>Finner H, Gontscharuk V (2018). "Two-sample Kolmogorov-Smirnov-type tests revisited: Old and new tests in terms of local levels." The Annals of Statistics, <b>46</b>(6A), 3014-3037.
</p>
<p>Paul L. Canner (1975). "A Simulation Study of One- and Two-Sample Kolmogorov-Smirnov Statistics with a Particular Weight Function". Journal of the American Statistical Association, <b>70</b>(349), 209-211.
</p>
<p>Nikiforov, A. M. (1994). "Algorithm AS 288: Exact Smirnov Two-Sample Tests for Arbitrary Distributions." Journal of the Royal Statistical Society. Series C (Applied Statistics), <b>43</b>(1), 265-270.
</p>
<p>Viehmann, T. (2021). Numerically more stable computation of the p-values for the two-sample Kolmogorov-Smirnov test. <em>arXiv preprint</em> arXiv:2102.08037.
</p>
<p>Dimitrina S. Dimitrova, Yun Jia, Vladimir K. Kaishev (2024). "The R functions KS2sample and Kuiper2sample: Efficient Exact Calculation of P-values of the Two-sample Kolmogorov-Smirnov and Kuiper Tests". <em>submitted</em>
</p>


<h3>Examples</h3>

<pre><code class="language-R">##Computes p-value of two-sided unweighted test for continuous data 
data1 &lt;- rexp(750, 1)
data2 &lt;- rexp(800, 1)
KS2sample(data1, data2)
##Computes the complementary p-value
KS2sample(data1, data2, tail = FALSE)
##Computes p-value of one-sided test with Anderson-Darling weight function
KS2sample(data1, data2, alternative = "greater", weight = 0.5)

##Computes p-values of two-sided test with Buning's weight function for discrete data
data3 &lt;- rnbinom(100, size = 3, prob = 0.6)
data4 &lt;- rpois(120, lambda = 2)
f &lt;- function(t) 1 / sqrt( t * (2 - t) ) 
KS2sample(data3, data4, weight = f)
</code></pre>


</div>