<div class="container">

<table style="width: 100%;"><tr>
<td>bidirectional</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bidirectional wrapper for RNNs</h2>

<h3>Description</h3>

<p>Bidirectional wrapper for RNNs
</p>


<h3>Usage</h3>

<pre><code class="language-R">bidirectional(
  object,
  layer,
  merge_mode = "concat",
  weights = NULL,
  backward_layer = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li>
<p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li>
<p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li>
<p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>layer</code></td>
<td>
<p>A <code>RNN</code> layer instance, such as <code>layer_lstm()</code> or
<code>layer_gru()</code>. It could also be a <code>keras$layers$Layer</code> instance that
meets the following criteria:
</p>

<ol>
<li>
<p> Be a sequence-processing layer (accepts 3D+ inputs).
</p>
</li>
<li>
<p> Have a <code>go_backwards</code>, <code>return_sequences</code> and <code>return_state</code> attribute
(with the same semantics as for the <code>RNN</code> class).
</p>
</li>
<li>
<p> Have an <code>input_spec</code> attribute.
</p>
</li>
<li>
<p> Implement serialization via <code>get_config()</code> and <code>from_config()</code>. Note
that the recommended way to create new RNN layers is to write a custom RNN
cell and use it with <code>layer_rnn()</code>, instead of subclassing
<code>keras$layers$Layer</code> directly.
</p>
</li>
<li>
<p> When <code>returns_sequences = TRUE</code>, the output of the masked timestep will
be zero regardless of the layer's original <code>zero_output_for_mask</code> value.
</p>
</li>
</ol>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>merge_mode</code></td>
<td>
<p>Mode by which outputs of the forward and backward RNNs will
be combined. One of <code>'sum'</code>, <code>'mul'</code>, <code>'concat'</code>, <code>'ave'</code>, <code>NULL</code>. If
<code>NULL</code>, the outputs will not be combined, they will be returned as a list.
Default value is <code>'concat'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Split and propagated to the <code>initial_weights</code> attribute on the
forward and backward layer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>backward_layer</code></td>
<td>
<p>Optional <code>keras.layers.RNN</code>, or <code>keras.layers.Layer</code>
instance to be used to handle backwards input processing. If
<code>backward_layer</code> is not provided, the layer instance passed as the <code>layer</code>
argument will be used to generate the backward layer automatically. Note
that the provided <code>backward_layer</code> layer should have properties matching
those of the <code>layer</code> argument, in particular it should have the same values
for <code>stateful</code>, <code>return_states</code>, <code>return_sequences</code>, etc. In addition,
<code>backward_layer</code> and <code>layer</code> should have different <code>go_backwards</code> argument
values. A <code>ValueError</code> will be raised if these requirements are not met.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>standard layer arguments.</p>
</td>
</tr>
</table>
<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional">https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/layers/recurrent_layers/bidirectional/">https://keras.io/api/layers/recurrent_layers/bidirectional/</a>
</p>
</li>
</ul>
<p>Other layer wrappers: 
<code>time_distributed()</code>
</p>


</div>