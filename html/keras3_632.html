<div class="container">

<table style="width: 100%;"><tr>
<td>op_vectorized_map</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Parallel map of function <code>f</code> on the first axis of tensor(s) <code>elements</code>.</h2>

<h3>Description</h3>

<p>Schematically, <code>op_vectorized_map()</code> maps over the first dimension of the provided tensors.
If <code>elements</code> is a list of tensors, then each of the tensors are required to
have the same size first dimension, and they are iterated over together.
</p>


<h3>Usage</h3>

<pre><code class="language-R">op_vectorized_map(elements, f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>elements</code></td>
<td>
<p>see description</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>f</code></td>
<td>
<p>A function taking either a tensor, or list of tensors.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A tensor or list of tensors, the result of mapping <code>f</code> across <code>elements.</code>
</p>


<h3>Examples</h3>

<div class="sourceCode r"><pre>(x &lt;- op_arange(12L) |&gt; op_reshape(c(3, 4)))
</pre></div>
<div class="sourceCode"><pre>## tf.Tensor(
## [[ 0  1  2  3]
##  [ 4  5  6  7]
##  [ 8  9 10 11]], shape=(3, 4), dtype=int32)

</pre></div>
<div class="sourceCode r"><pre>x |&gt; op_vectorized_map(\(row) {row + 10})
</pre></div>
<div class="sourceCode"><pre>## tf.Tensor(
## [[10 11 12 13]
##  [14 15 16 17]
##  [18 19 20 21]], shape=(3, 4), dtype=int32)

</pre></div>
<div class="sourceCode r"><pre>list(x, x, x) |&gt; op_vectorized_map(\(rows) Reduce(`+`, rows))
</pre></div>
<div class="sourceCode"><pre>## tf.Tensor(
## [[ 0  3  6  9]
##  [12 15 18 21]
##  [24 27 30 33]], shape=(3, 4), dtype=int32)

</pre></div>
<p>Note that <code>f</code> may be traced and compiled. Meaning, the R function may only
evaluated once with symbolic tensors if using Jax or TensorFlow backends, and
not with eager tensors. See the output from <code>str()</code> in these examples:
</p>
<div class="sourceCode r"><pre># simplest case, map f over rows of x,
# where .x is 1 row of x
input &lt;- x
output &lt;- op_vectorized_map(input, function(.x) {
  str(.x)
  .x + 10
})
</pre></div>
<div class="sourceCode"><pre>## &lt;tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32&gt;

</pre></div>
<div class="sourceCode r"><pre>output
</pre></div>
<div class="sourceCode"><pre>## tf.Tensor(
## [[10 11 12 13]
##  [14 15 16 17]
##  [18 19 20 21]], shape=(3, 4), dtype=int32)

</pre></div>
<div class="sourceCode r"><pre># map f over two tensors simultaneously. Here, # `.x` is a list of two
# tensors. The return values from each call of `f(row)` are stacked to form the
# final output
input &lt;- list(x, x)
output &lt;- op_vectorized_map(input, function(.x) {
  str(.x)
  .x[[1]] + 10
})
</pre></div>
<div class="sourceCode"><pre>## List of 2
##  $ :&lt;tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32&gt;
##  $ :&lt;tf.Tensor 'loop_body/GatherV2_1:0' shape=(4) dtype=int32&gt;

</pre></div>
<div class="sourceCode r"><pre>output
</pre></div>
<div class="sourceCode"><pre>## tf.Tensor(
## [[10 11 12 13]
##  [14 15 16 17]
##  [18 19 20 21]], shape=(3, 4), dtype=int32)

</pre></div>
<div class="sourceCode r"><pre># same as above, but now returning two tensors in the final output
output &lt;- op_vectorized_map(input, function(.x) {
  str(.x)
  c(.x1, .x2) %&lt;-% .x
  list(.x1+10, .x2+20)
})
</pre></div>
<div class="sourceCode"><pre>## List of 2
##  $ :&lt;tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32&gt;
##  $ :&lt;tf.Tensor 'loop_body/GatherV2_1:0' shape=(4) dtype=int32&gt;

</pre></div>
<div class="sourceCode r"><pre>output
</pre></div>
<div class="sourceCode"><pre>## [[1]]
## tf.Tensor(
## [[10 11 12 13]
##  [14 15 16 17]
##  [18 19 20 21]], shape=(3, 4), dtype=int32)
##
## [[2]]
## tf.Tensor(
## [[20 21 22 23]
##  [24 25 26 27]
##  [28 29 30 31]], shape=(3, 4), dtype=int32)

</pre></div>
<div class="sourceCode r"><pre># passing named lists.
# WARNING: if passing a named list, the order of elements of `.x` supplied
# to `f` is not stable. Only retrieve elements by name.
input &lt;- list(name1 = x, name2 = x)
output &lt;- op_vectorized_map(input, function(.x) {
  str(.x)
  list(outname1 = .x$name1 + 10,
       outname2 = .x$name2 + 20)
})
</pre></div>
<div class="sourceCode"><pre>## List of 2
##  $ name1:&lt;tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32&gt;
##  $ name2:&lt;tf.Tensor 'loop_body/GatherV2_1:0' shape=(4) dtype=int32&gt;

</pre></div>
<div class="sourceCode r"><pre>output
</pre></div>
<div class="sourceCode"><pre>## $outname1
## tf.Tensor(
## [[10 11 12 13]
##  [14 15 16 17]
##  [18 19 20 21]], shape=(3, 4), dtype=int32)
##
## $outname2
## tf.Tensor(
## [[20 21 22 23]
##  [24 25 26 27]
##  [28 29 30 31]], shape=(3, 4), dtype=int32)

</pre></div>
<div class="sourceCode r"><pre># passing a tuple() is equivalent to passing an unnamed list()
input &lt;- tuple(x, x)
output &lt;- op_vectorized_map(input, function(.x) {
  str(.x)
  list(.x[[1]] + 10)
})
</pre></div>
<div class="sourceCode"><pre>## List of 2
##  $ :&lt;tf.Tensor 'loop_body/GatherV2:0' shape=(4) dtype=int32&gt;
##  $ :&lt;tf.Tensor 'loop_body/GatherV2_1:0' shape=(4) dtype=int32&gt;

</pre></div>
<div class="sourceCode r"><pre>output
</pre></div>
<div class="sourceCode"><pre>## [[1]]
## tf.Tensor(
## [[10 11 12 13]
##  [14 15 16 17]
##  [18 19 20 21]], shape=(3, 4), dtype=int32)

</pre></div>


<h3>Debugging <code>f</code>
</h3>

<p>Even in eager contexts, <code>op_vectorized_map()</code> may trace <code>f</code>. In that case, if
you want to eagerly debug <code>f</code> (e.g., with <code>browser()</code>), you can swap in a
manual (slow) implementation of <code>op_vectorized_map()</code>. Note this example
debug implementation does not handle all the same edge cases as
<code>op_vectorized_map()</code>, in particular, if <code>f</code> returns a structure of multiple
tensors.
</p>
<div class="sourceCode r"><pre>op_vectorized_map_debug &lt;- function(elements, fn) {

  if (!is.list(elements)) {
    # `elements` is a single tensor
    batch_size &lt;- op_shape(elements)[[1]]
    out &lt;- elements |&gt;
      op_split(batch_size) |&gt;
      lapply(fn) |&gt;
      op_stack()
    return(out)
  }

  # `elements` is a list of tensors
  batch_size &lt;- elements[[1]] |&gt; op_shape() |&gt; _[[1]]
  elements |&gt;
    lapply(\(e) op_split(e, batch_size)) |&gt;
    zip_lists() |&gt;
    lapply(fn) |&gt;
    op_stack()

}
</pre></div>


<h3>See Also</h3>

<p>Other core ops: <br><code>op_associative_scan()</code> <br><code>op_cast()</code> <br><code>op_cond()</code> <br><code>op_convert_to_numpy()</code> <br><code>op_convert_to_tensor()</code> <br><code>op_custom_gradient()</code> <br><code>op_dtype()</code> <br><code>op_fori_loop()</code> <br><code>op_is_tensor()</code> <br><code>op_map()</code> <br><code>op_scan()</code> <br><code>op_scatter()</code> <br><code>op_scatter_update()</code> <br><code>op_searchsorted()</code> <br><code>op_shape()</code> <br><code>op_slice()</code> <br><code>op_slice_update()</code> <br><code>op_stop_gradient()</code> <br><code>op_switch()</code> <br><code>op_unstack()</code> <br><code>op_while_loop()</code> <br></p>
<p>Other ops: <br><code>op_abs()</code> <br><code>op_add()</code> <br><code>op_all()</code> <br><code>op_any()</code> <br><code>op_append()</code> <br><code>op_arange()</code> <br><code>op_arccos()</code> <br><code>op_arccosh()</code> <br><code>op_arcsin()</code> <br><code>op_arcsinh()</code> <br><code>op_arctan()</code> <br><code>op_arctan2()</code> <br><code>op_arctanh()</code> <br><code>op_argmax()</code> <br><code>op_argmin()</code> <br><code>op_argpartition()</code> <br><code>op_argsort()</code> <br><code>op_array()</code> <br><code>op_associative_scan()</code> <br><code>op_average()</code> <br><code>op_average_pool()</code> <br><code>op_batch_normalization()</code> <br><code>op_binary_crossentropy()</code> <br><code>op_bincount()</code> <br><code>op_broadcast_to()</code> <br><code>op_cast()</code> <br><code>op_categorical_crossentropy()</code> <br><code>op_ceil()</code> <br><code>op_cholesky()</code> <br><code>op_clip()</code> <br><code>op_concatenate()</code> <br><code>op_cond()</code> <br><code>op_conj()</code> <br><code>op_conv()</code> <br><code>op_conv_transpose()</code> <br><code>op_convert_to_numpy()</code> <br><code>op_convert_to_tensor()</code> <br><code>op_copy()</code> <br><code>op_correlate()</code> <br><code>op_cos()</code> <br><code>op_cosh()</code> <br><code>op_count_nonzero()</code> <br><code>op_cross()</code> <br><code>op_ctc_decode()</code> <br><code>op_ctc_loss()</code> <br><code>op_cumprod()</code> <br><code>op_cumsum()</code> <br><code>op_custom_gradient()</code> <br><code>op_depthwise_conv()</code> <br><code>op_det()</code> <br><code>op_diag()</code> <br><code>op_diagonal()</code> <br><code>op_diff()</code> <br><code>op_digitize()</code> <br><code>op_divide()</code> <br><code>op_divide_no_nan()</code> <br><code>op_dot()</code> <br><code>op_dtype()</code> <br><code>op_eig()</code> <br><code>op_eigh()</code> <br><code>op_einsum()</code> <br><code>op_elu()</code> <br><code>op_empty()</code> <br><code>op_equal()</code> <br><code>op_erf()</code> <br><code>op_erfinv()</code> <br><code>op_exp()</code> <br><code>op_expand_dims()</code> <br><code>op_expm1()</code> <br><code>op_extract_sequences()</code> <br><code>op_eye()</code> <br><code>op_fft()</code> <br><code>op_fft2()</code> <br><code>op_flip()</code> <br><code>op_floor()</code> <br><code>op_floor_divide()</code> <br><code>op_fori_loop()</code> <br><code>op_full()</code> <br><code>op_full_like()</code> <br><code>op_gelu()</code> <br><code>op_get_item()</code> <br><code>op_greater()</code> <br><code>op_greater_equal()</code> <br><code>op_hard_sigmoid()</code> <br><code>op_hard_silu()</code> <br><code>op_hstack()</code> <br><code>op_identity()</code> <br><code>op_imag()</code> <br><code>op_image_affine_transform()</code> <br><code>op_image_crop()</code> <br><code>op_image_extract_patches()</code> <br><code>op_image_hsv_to_rgb()</code> <br><code>op_image_map_coordinates()</code> <br><code>op_image_pad()</code> <br><code>op_image_resize()</code> <br><code>op_image_rgb_to_grayscale()</code> <br><code>op_image_rgb_to_hsv()</code> <br><code>op_in_top_k()</code> <br><code>op_inv()</code> <br><code>op_irfft()</code> <br><code>op_is_tensor()</code> <br><code>op_isclose()</code> <br><code>op_isfinite()</code> <br><code>op_isinf()</code> <br><code>op_isnan()</code> <br><code>op_istft()</code> <br><code>op_leaky_relu()</code> <br><code>op_less()</code> <br><code>op_less_equal()</code> <br><code>op_linspace()</code> <br><code>op_log()</code> <br><code>op_log10()</code> <br><code>op_log1p()</code> <br><code>op_log2()</code> <br><code>op_log_sigmoid()</code> <br><code>op_log_softmax()</code> <br><code>op_logaddexp()</code> <br><code>op_logical_and()</code> <br><code>op_logical_not()</code> <br><code>op_logical_or()</code> <br><code>op_logical_xor()</code> <br><code>op_logspace()</code> <br><code>op_logsumexp()</code> <br><code>op_lstsq()</code> <br><code>op_lu_factor()</code> <br><code>op_map()</code> <br><code>op_matmul()</code> <br><code>op_max()</code> <br><code>op_max_pool()</code> <br><code>op_maximum()</code> <br><code>op_mean()</code> <br><code>op_median()</code> <br><code>op_meshgrid()</code> <br><code>op_min()</code> <br><code>op_minimum()</code> <br><code>op_mod()</code> <br><code>op_moments()</code> <br><code>op_moveaxis()</code> <br><code>op_multi_hot()</code> <br><code>op_multiply()</code> <br><code>op_nan_to_num()</code> <br><code>op_ndim()</code> <br><code>op_negative()</code> <br><code>op_nonzero()</code> <br><code>op_norm()</code> <br><code>op_normalize()</code> <br><code>op_not_equal()</code> <br><code>op_one_hot()</code> <br><code>op_ones()</code> <br><code>op_ones_like()</code> <br><code>op_outer()</code> <br><code>op_pad()</code> <br><code>op_power()</code> <br><code>op_prod()</code> <br><code>op_psnr()</code> <br><code>op_qr()</code> <br><code>op_quantile()</code> <br><code>op_ravel()</code> <br><code>op_real()</code> <br><code>op_reciprocal()</code> <br><code>op_relu()</code> <br><code>op_relu6()</code> <br><code>op_repeat()</code> <br><code>op_reshape()</code> <br><code>op_rfft()</code> <br><code>op_roll()</code> <br><code>op_round()</code> <br><code>op_rsqrt()</code> <br><code>op_scan()</code> <br><code>op_scatter()</code> <br><code>op_scatter_update()</code> <br><code>op_searchsorted()</code> <br><code>op_segment_max()</code> <br><code>op_segment_sum()</code> <br><code>op_select()</code> <br><code>op_selu()</code> <br><code>op_separable_conv()</code> <br><code>op_shape()</code> <br><code>op_sigmoid()</code> <br><code>op_sign()</code> <br><code>op_silu()</code> <br><code>op_sin()</code> <br><code>op_sinh()</code> <br><code>op_size()</code> <br><code>op_slice()</code> <br><code>op_slice_update()</code> <br><code>op_slogdet()</code> <br><code>op_softmax()</code> <br><code>op_softplus()</code> <br><code>op_softsign()</code> <br><code>op_solve()</code> <br><code>op_solve_triangular()</code> <br><code>op_sort()</code> <br><code>op_sparse_categorical_crossentropy()</code> <br><code>op_split()</code> <br><code>op_sqrt()</code> <br><code>op_square()</code> <br><code>op_squeeze()</code> <br><code>op_stack()</code> <br><code>op_std()</code> <br><code>op_stft()</code> <br><code>op_stop_gradient()</code> <br><code>op_subtract()</code> <br><code>op_sum()</code> <br><code>op_svd()</code> <br><code>op_swapaxes()</code> <br><code>op_switch()</code> <br><code>op_take()</code> <br><code>op_take_along_axis()</code> <br><code>op_tan()</code> <br><code>op_tanh()</code> <br><code>op_tensordot()</code> <br><code>op_tile()</code> <br><code>op_top_k()</code> <br><code>op_trace()</code> <br><code>op_transpose()</code> <br><code>op_tri()</code> <br><code>op_tril()</code> <br><code>op_triu()</code> <br><code>op_unstack()</code> <br><code>op_var()</code> <br><code>op_vdot()</code> <br><code>op_vectorize()</code> <br><code>op_vstack()</code> <br><code>op_where()</code> <br><code>op_while_loop()</code> <br><code>op_zeros()</code> <br><code>op_zeros_like()</code> <br></p>


</div>