<div class="container">

<table style="width: 100%;"><tr>
<td>layer_conv_lstm_3d</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>3D Convolutional LSTM</h2>

<h3>Description</h3>

<p>3D Convolutional LSTM
</p>


<h3>Usage</h3>

<pre><code class="language-R">layer_conv_lstm_3d(
  object,
  filters,
  kernel_size,
  strides = c(1L, 1L, 1L),
  padding = "valid",
  data_format = NULL,
  dilation_rate = c(1L, 1L, 1L),
  activation = "tanh",
  recurrent_activation = "hard_sigmoid",
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  recurrent_initializer = "orthogonal",
  bias_initializer = "zeros",
  unit_forget_bias = TRUE,
  kernel_regularizer = NULL,
  recurrent_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  recurrent_constraint = NULL,
  bias_constraint = NULL,
  return_sequences = FALSE,
  return_state = FALSE,
  go_backwards = FALSE,
  stateful = FALSE,
  dropout = 0,
  recurrent_dropout = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li>
<p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li>
<p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li>
<p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>filters</code></td>
<td>
<p>Integer, the dimensionality of the output space (i.e. the number of
output filters in the convolution).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel_size</code></td>
<td>
<p>An integer or list of n integers, specifying the
dimensions of the convolution window.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>strides</code></td>
<td>
<p>An integer or list of n integers, specifying the strides of
the convolution. Specifying any stride value != 1 is incompatible with
specifying any <code>dilation_rate</code> value != 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>padding</code></td>
<td>
<p>One of <code>"valid"</code> or <code>"same"</code> (case-insensitive). <code>"valid"</code> means no
padding. <code>"same"</code> results in padding evenly to the left/right or up/down
of the input such that output has the same height/width dimension as the
input.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data_format</code></td>
<td>
<p>A string, one of <code>channels_last</code> (default) or <code>channels_first</code>.
The ordering of the dimensions in the inputs. <code>channels_last</code> corresponds
to inputs with shape <code style="white-space: pre;">⁠(batch, time, ..., channels)⁠</code> while <code>channels_first</code>
corresponds to inputs with shape <code style="white-space: pre;">⁠(batch, time, channels, ...)⁠</code>. It
defaults to the <code>image_data_format</code> value found in your Keras config file
at <code style="white-space: pre;">⁠~/.keras/keras.json⁠</code>. If you never set it, then it will be
"channels_last".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dilation_rate</code></td>
<td>
<p>An integer or list of n integers, specifying the
dilation rate to use for dilated convolution. Currently, specifying any
<code>dilation_rate</code> value != 1 is incompatible with specifying any <code>strides</code>
value != 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>activation</code></td>
<td>
<p>Activation function to use. By default hyperbolic tangent
activation function is applied (<code>tanh(x)</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>recurrent_activation</code></td>
<td>
<p>Activation function to use for the recurrent step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_bias</code></td>
<td>
<p>Boolean, whether the layer uses a bias vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel_initializer</code></td>
<td>
<p>Initializer for the <code>kernel</code> weights matrix, used for
the linear transformation of the inputs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>recurrent_initializer</code></td>
<td>
<p>Initializer for the <code>recurrent_kernel</code> weights
matrix, used for the linear transformation of the recurrent state.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias_initializer</code></td>
<td>
<p>Initializer for the bias vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>unit_forget_bias</code></td>
<td>
<p>Boolean. If TRUE, add 1 to the bias of the forget gate at
initialization. Use in combination with <code>bias_initializer="zeros"</code>. This
is recommended in <a href="https://proceedings.mlr.press/v37/jozefowicz15.pdf">Jozefowicz et al., 2015</a></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel_regularizer</code></td>
<td>
<p>Regularizer function applied to the <code>kernel</code> weights
matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>recurrent_regularizer</code></td>
<td>
<p>Regularizer function applied to the
<code>recurrent_kernel</code> weights matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias_regularizer</code></td>
<td>
<p>Regularizer function applied to the bias vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>activity_regularizer</code></td>
<td>
<p>Regularizer function applied to.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel_constraint</code></td>
<td>
<p>Constraint function applied to the <code>kernel</code> weights
matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>recurrent_constraint</code></td>
<td>
<p>Constraint function applied to the <code>recurrent_kernel</code>
weights matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bias_constraint</code></td>
<td>
<p>Constraint function applied to the bias vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_sequences</code></td>
<td>
<p>Boolean. Whether to return the last output in the output
sequence, or the full sequence. (default FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_state</code></td>
<td>
<p>Boolean Whether to return the last state in addition to the
output. (default FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>go_backwards</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, process the input sequence
backwards.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stateful</code></td>
<td>
<p>Boolean (default FALSE). If TRUE, the last state for each sample
at index i in a batch will be used as initial state for the sample of
index i in the following batch.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for the linear
transformation of the inputs.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>recurrent_dropout</code></td>
<td>
<p>Float between 0 and 1. Fraction of the units to drop for
the linear transformation of the recurrent state.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>standard layer arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Similar to an LSTM layer, but the input transformations
and recurrent transformations are both convolutional.
</p>


<h3>See Also</h3>


<ul><li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM3D">https://www.tensorflow.org/api_docs/python/tf/keras/layers/ConvLSTM3D</a>
</p>
</li></ul>
</div>