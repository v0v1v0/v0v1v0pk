<div class="container">

<table style="width: 100%;"><tr>
<td>layer_torch_module_wrapper</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Torch module wrapper layer.</h2>

<h3>Description</h3>

<p><code>layer_torch_module_wrapper</code> is a wrapper class that can turn any
<code>torch.nn.Module</code> into a Keras layer, in particular by making its
parameters trackable by Keras.
</p>
<p><code>layer_torch_module_wrapper()</code> is only compatible with the PyTorch backend and
cannot be used with the TensorFlow or JAX backends.
</p>


<h3>Usage</h3>

<pre><code class="language-R">layer_torch_module_wrapper(object, module, name = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Object to compose the layer with. A tensor, array, or sequential model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>module</code></td>
<td>
<p><code>torch.nn.Module</code> instance. If it's a <code>LazyModule</code>
instance, then its parameters must be initialized before
passing the instance to <code>layer_torch_module_wrapper</code> (e.g. by calling
it once).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>The name of the layer (string).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For forward/backward compatability.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The return value depends on the value provided for the first argument.
If  <code>object</code> is:
</p>

<ul>
<li>
<p> a <code>keras_model_sequential()</code>, then the layer is added to the sequential model
(which is modified in place). To enable piping, the sequential model is also
returned, invisibly.
</p>
</li>
<li>
<p> a <code>keras_input()</code>, then the output tensor from calling <code>layer(input)</code> is returned.
</p>
</li>
<li> <p><code>NULL</code> or missing, then a <code>Layer</code> instance is returned.
</p>
</li>
</ul>
<h3>Example</h3>

<p>Here's an example of how the <code>layer_torch_module_wrapper()</code> can be used with vanilla
PyTorch modules.
</p>
<div class="sourceCode r"><pre># reticulate::py_install(
#   packages = c("torch", "torchvision", "torchaudio"),
#   envname = "r-keras",
#   pip_options = c("--index-url https://download.pytorch.org/whl/cpu")
# )
library(keras3)
use_backend("torch")
torch &lt;- reticulate::import("torch")
nn &lt;- reticulate::import("torch.nn")
nnf &lt;- reticulate::import("torch.nn.functional")

Classifier(keras$Model) \%py_class\% {
  initialize &lt;- function(...) {
    super$initialize(...)

    self$conv1 &lt;- layer_torch_module_wrapper(module = nn$Conv2d(
      in_channels = 1L,
      out_channels = 32L,
      kernel_size = tuple(3L, 3L)
    ))
    self$conv2 &lt;- layer_torch_module_wrapper(module = nn$Conv2d(
      in_channels = 32L,
      out_channels = 64L,
      kernel_size = tuple(3L, 3L)
    ))
    self$pool &lt;- nn$MaxPool2d(kernel_size = tuple(2L, 2L))
    self$flatten &lt;- nn$Flatten()
    self$dropout &lt;- nn$Dropout(p = 0.5)
    self$fc &lt;-
      layer_torch_module_wrapper(module = nn$Linear(1600L, 10L))
  }

  call &lt;- function(inputs) {
    x &lt;- nnf$relu(self$conv1(inputs))
    x &lt;- self$pool(x)
    x &lt;- nnf$relu(self$conv2(x))
    x &lt;- self$pool(x)
    x &lt;- self$flatten(x)
    x &lt;- self$dropout(x)
    x &lt;- self$fc(x)
    nnf$softmax(x, dim = 1L)
  }
}
model &lt;- Classifier()
model$build(shape(1, 28, 28))
cat("Output shape:", format(shape(model(torch$ones(1L, 1L, 28L, 28L)))))

model |&gt; compile(loss = "sparse_categorical_crossentropy",
                 optimizer = "adam",
                 metrics = "accuracy")
</pre></div>
<div class="sourceCode r"><pre>model |&gt; fit(train_loader, epochs = 5)
</pre></div>


<h3>See Also</h3>

<p>Other wrapping layers: <br><code>layer_flax_module_wrapper()</code> <br><code>layer_jax_model_wrapper()</code> <br></p>
<p>Other layers: <br><code>Layer()</code> <br><code>layer_activation()</code> <br><code>layer_activation_elu()</code> <br><code>layer_activation_leaky_relu()</code> <br><code>layer_activation_parametric_relu()</code> <br><code>layer_activation_relu()</code> <br><code>layer_activation_softmax()</code> <br><code>layer_activity_regularization()</code> <br><code>layer_add()</code> <br><code>layer_additive_attention()</code> <br><code>layer_alpha_dropout()</code> <br><code>layer_attention()</code> <br><code>layer_average()</code> <br><code>layer_average_pooling_1d()</code> <br><code>layer_average_pooling_2d()</code> <br><code>layer_average_pooling_3d()</code> <br><code>layer_batch_normalization()</code> <br><code>layer_bidirectional()</code> <br><code>layer_category_encoding()</code> <br><code>layer_center_crop()</code> <br><code>layer_concatenate()</code> <br><code>layer_conv_1d()</code> <br><code>layer_conv_1d_transpose()</code> <br><code>layer_conv_2d()</code> <br><code>layer_conv_2d_transpose()</code> <br><code>layer_conv_3d()</code> <br><code>layer_conv_3d_transpose()</code> <br><code>layer_conv_lstm_1d()</code> <br><code>layer_conv_lstm_2d()</code> <br><code>layer_conv_lstm_3d()</code> <br><code>layer_cropping_1d()</code> <br><code>layer_cropping_2d()</code> <br><code>layer_cropping_3d()</code> <br><code>layer_dense()</code> <br><code>layer_depthwise_conv_1d()</code> <br><code>layer_depthwise_conv_2d()</code> <br><code>layer_discretization()</code> <br><code>layer_dot()</code> <br><code>layer_dropout()</code> <br><code>layer_einsum_dense()</code> <br><code>layer_embedding()</code> <br><code>layer_feature_space()</code> <br><code>layer_flatten()</code> <br><code>layer_flax_module_wrapper()</code> <br><code>layer_gaussian_dropout()</code> <br><code>layer_gaussian_noise()</code> <br><code>layer_global_average_pooling_1d()</code> <br><code>layer_global_average_pooling_2d()</code> <br><code>layer_global_average_pooling_3d()</code> <br><code>layer_global_max_pooling_1d()</code> <br><code>layer_global_max_pooling_2d()</code> <br><code>layer_global_max_pooling_3d()</code> <br><code>layer_group_normalization()</code> <br><code>layer_group_query_attention()</code> <br><code>layer_gru()</code> <br><code>layer_hashed_crossing()</code> <br><code>layer_hashing()</code> <br><code>layer_identity()</code> <br><code>layer_integer_lookup()</code> <br><code>layer_jax_model_wrapper()</code> <br><code>layer_lambda()</code> <br><code>layer_layer_normalization()</code> <br><code>layer_lstm()</code> <br><code>layer_masking()</code> <br><code>layer_max_pooling_1d()</code> <br><code>layer_max_pooling_2d()</code> <br><code>layer_max_pooling_3d()</code> <br><code>layer_maximum()</code> <br><code>layer_mel_spectrogram()</code> <br><code>layer_minimum()</code> <br><code>layer_multi_head_attention()</code> <br><code>layer_multiply()</code> <br><code>layer_normalization()</code> <br><code>layer_permute()</code> <br><code>layer_random_brightness()</code> <br><code>layer_random_contrast()</code> <br><code>layer_random_crop()</code> <br><code>layer_random_flip()</code> <br><code>layer_random_rotation()</code> <br><code>layer_random_translation()</code> <br><code>layer_random_zoom()</code> <br><code>layer_repeat_vector()</code> <br><code>layer_rescaling()</code> <br><code>layer_reshape()</code> <br><code>layer_resizing()</code> <br><code>layer_rnn()</code> <br><code>layer_separable_conv_1d()</code> <br><code>layer_separable_conv_2d()</code> <br><code>layer_simple_rnn()</code> <br><code>layer_spatial_dropout_1d()</code> <br><code>layer_spatial_dropout_2d()</code> <br><code>layer_spatial_dropout_3d()</code> <br><code>layer_spectral_normalization()</code> <br><code>layer_string_lookup()</code> <br><code>layer_subtract()</code> <br><code>layer_text_vectorization()</code> <br><code>layer_tfsm()</code> <br><code>layer_time_distributed()</code> <br><code>layer_unit_normalization()</code> <br><code>layer_upsampling_1d()</code> <br><code>layer_upsampling_2d()</code> <br><code>layer_upsampling_3d()</code> <br><code>layer_zero_padding_1d()</code> <br><code>layer_zero_padding_2d()</code> <br><code>layer_zero_padding_3d()</code> <br><code>rnn_cell_gru()</code> <br><code>rnn_cell_lstm()</code> <br><code>rnn_cell_simple()</code> <br><code>rnn_cells_stack()</code> <br></p>


</div>