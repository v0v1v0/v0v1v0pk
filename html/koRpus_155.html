<div class="container">

<table style="width: 100%;"><tr>
<td>lex.div</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Analyze lexical diversity</h2>

<h3>Description</h3>

<p>These methods analyze the lexical diversity/complexity of a text corpus.
</p>


<h3>Usage</h3>

<pre><code class="language-R">lex.div(txt, ...)

## S4 method for signature 'kRp.text'
lex.div(
  txt,
  segment = 100,
  factor.size = 0.72,
  min.tokens = 9,
  MTLDMA.steps = 1,
  rand.sample = 42,
  window = 100,
  case.sens = FALSE,
  lemmatize = FALSE,
  detailed = FALSE,
  measure = c("TTR", "MSTTR", "MATTR", "C", "R", "CTTR", "U", "S", "K", "Maas", "HD-D",
    "MTLD", "MTLD-MA"),
  char = c("TTR", "MATTR", "C", "R", "CTTR", "U", "S", "K", "Maas", "HD-D", "MTLD",
    "MTLD-MA"),
  char.steps = 5,
  log.base = 10,
  force.lang = NULL,
  keep.tokens = FALSE,
  type.index = FALSE,
  corp.rm.class = "nonpunct",
  corp.rm.tag = c(),
  as.feature = FALSE,
  quiet = FALSE
)

## S4 method for signature 'character'
lex.div(
  txt,
  segment = 100,
  factor.size = 0.72,
  min.tokens = 9,
  MTLDMA.steps = 1,
  rand.sample = 42,
  window = 100,
  case.sens = FALSE,
  lemmatize = FALSE,
  detailed = FALSE,
  measure = c("TTR", "MSTTR", "MATTR", "C", "R", "CTTR", "U", "S", "K", "Maas", "HD-D",
    "MTLD", "MTLD-MA"),
  char = c("TTR", "MATTR", "C", "R", "CTTR", "U", "S", "K", "Maas", "HD-D", "MTLD",
    "MTLD-MA"),
  char.steps = 5,
  log.base = 10,
  force.lang = NULL,
  keep.tokens = FALSE,
  type.index = FALSE,
  corp.rm.class = "nonpunct",
  corp.rm.tag = c(),
  quiet = FALSE
)

## S4 method for signature 'missing'
lex.div(txt, measure)

## S4 method for signature 'kRp.TTR,ANY,ANY,ANY'
x[i]

## S4 method for signature 'kRp.TTR'
x[[i]]
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>txt</code></td>
<td>
<p>An object of class <code>kRp.text</code>,
containing the tagged text to be analyzed.
If <code>txt</code> is of class character, it is assumed to be the raw text to be analyzed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Only used for the method generic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>segment</code></td>
<td>
<p>An integer value for MSTTR,
defining how many tokens should form one segment.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor.size</code></td>
<td>
<p>A real number between 0 and 1, defining the MTLD factor size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min.tokens</code></td>
<td>
<p>An integer value,
how many tokens a full factor must at least have to be considered for the MTLD-MA result.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MTLDMA.steps</code></td>
<td>
<p>An integer value for MTLD-MA,
defining the step size for the moving window, in tokens. The original proposal
uses an incremet of 1. If you increase this value, computation will be faster,
but your value can only remain a good estimate if
the text is long enough.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rand.sample</code></td>
<td>
<p>An integer value,
how many tokens should be assumed to be drawn for calculating HD-D.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>window</code></td>
<td>
<p>An integer value for MATTR,
defining how many tokens the moving window should include.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>case.sens</code></td>
<td>
<p>Logical, whether types should be counted case sensitive.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lemmatize</code></td>
<td>
<p>Logical,
whether analysis should be carried out on the lemmatized tokens rather than all running word forms.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>detailed</code></td>
<td>
<p>Logical,
whether full details of the analysis should be calculated. This currently affects MTLD and MTLD-MA, defining
if all factors should be kept in the object. This slows down calculations considerably.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>measure</code></td>
<td>
<p>A character vector defining the measures which should be calculated. Valid elements are <code>"TTR"</code>,
<code>"MSTTR"</code>,
<code>"MATTR"</code>, <code>"C"</code>, <code>"R"</code>, <code>"CTTR"</code>, <code>"U"</code>, <code>"S"</code>, <code>"K"</code>,
<code>"Maas"</code>, <code>"HD-D"</code>, <code>"MTLD"</code>
and <code>"MTLD-MA"</code>. You can also set it to <code>"validation"</code> to get information on the current status of validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>char</code></td>
<td>
<p>A character vector defining whether data for plotting characteristic curves should be calculated. Valid elements are 
<code>"TTR"</code>, <code>"MATTR"</code>, <code>"C"</code>, <code>"R"</code>, <code>"CTTR"</code>, <code>"U"</code>,
<code>"S"</code>, <code>"K"</code>, <code>"Maas"</code>, <code>"HD-D"</code>,
<code>"MTLD"</code> and <code>"MTLD-MA"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>char.steps</code></td>
<td>
<p>An integer value defining the step size for characteristic curves,
in tokens.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>log.base</code></td>
<td>
<p>A numeric value defining the base of the logarithm. See <code>log</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>force.lang</code></td>
<td>
<p>A character string defining the language to be assumed for the text,
by force. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep.tokens</code></td>
<td>
<p>Logical. If <code>TRUE</code>,
all raw tokens and types will be preserved in the resulting object, in a slot called 
<code>tt</code>. For the types, also their frequency in the analyzed text will be listed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type.index</code></td>
<td>
<p>Logical. If <code>TRUE</code>,
the <code>tt</code> slot will contain two named lists of all types with the indices where that particular
type is to be found in the original tagged text (<code>type.in.txt</code>) or the list of tokens in these results (<code>type.in.result</code>),
respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>corp.rm.class</code></td>
<td>
<p>A character vector with word classes which should be dropped. The default value
<code>"nonpunct"</code> has special meaning and will cause the result of
<code>kRp.POS.tags(lang, tags=c("punct","sentc"), list.classes=TRUE)</code> to be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>corp.rm.tag</code></td>
<td>
<p>A character vector with POS tags which should be dropped.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>as.feature</code></td>
<td>
<p>Logical,
whether the output should be just the analysis results or the input object with
the results added as a feature. Use <code>corpusLexDiv</code>
to get the results from such an aggregated object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quiet</code></td>
<td>
<p>Logical. If <code>FALSE</code>, short status messages will be shown.
<code>TRUE</code> will also suppress all potential warnings regarding the validation status of measures.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An object of class <code>kRp.TTR</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>i</code></td>
<td>
<p>Defines the row selector (<code>[</code>) or the name to match (<code>[[</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>lex.div</code> calculates a variety of proposed indices for lexical diversity. In the following formulae,
<code class="reqn">N</code> refers to
the total number of tokens, and <code class="reqn">V</code> to the number of types:
</p>

<dl>
<dt>
<code>"TTR"</code>:</dt>
<dd>
<p>The ordinary <em>Type-Token Ratio</em>: </p>
<p style="text-align: center;"><code class="reqn">TTR = \frac{V}{N}</code>
</p>

<p>Wrapper function: <code>TTR</code></p>
</dd>
<dt>
<code>"MSTTR"</code>:</dt>
<dd>
<p>For the <em>Mean Segmental Type-Token Ratio</em> (sometimes referred to as <em>Split TTR</em>) tokens are split up into 
segments of the given size,
TTR for each segment is calculated and the mean of these values returned. Tokens at the end which do 
not make a full segment are ignored. The number of dropped tokens is reported.
</p>
<p>Wrapper function: <code>MSTTR</code></p>
</dd>
<dt>
<code>"MATTR"</code>:</dt>
<dd>
<p>The <em>Moving-Average Type-Token Ratio</em> (Covington &amp; McFall,
2010) calculates TTRs for a defined number of tokens
(called the "window"),
starting at the beginning of the text and moving this window over the text, until the last token is reached.
The mean of these TTRs is the MATTR.
</p>
<p>Wrapper function: <code>MATTR</code></p>
</dd>
<dt>
<code>"C"</code>:</dt>
<dd>
<p>Herdan's <em>C</em> (Herdan, 1960, as cited in Tweedie &amp; Baayen,
1998; sometimes referred to as <em>LogTTR</em>): </p>
<p style="text-align: center;"><code class="reqn">C = \frac{\lg{V}}{\lg{N}}</code>
</p>
</dd>
</dl>
<p>Wrapper function: <code>C.ld</code>
</p>
<dl>
<dt>
<code>"R"</code>:</dt>
<dd>
<p>Guiraud's <em>Root TTR</em> (Guiraud, 1954,
as cited in Tweedie &amp; Baayen, 1998): </p>
<p style="text-align: center;"><code class="reqn">R = \frac{V}{\sqrt{N}}</code>
</p>
</dd>
</dl>
<p>Wrapper function: <code>R.ld</code>
</p>
<dl>
<dt>
<code>"CTTR"</code>:</dt>
<dd>
<p>Carroll's <em>Corrected TTR</em>: </p>
<p style="text-align: center;"><code class="reqn">CTTR = \frac{V}{\sqrt{2N}}</code>
</p>
</dd>
</dl>
<p>Wrapper function: <code>CTTR</code>
</p>
<dl>
<dt>
<code>"U"</code>:</dt>
<dd>
<p>Dugast's <em>Uber Index</em>  (Dugast, 1978,
as cited in Tweedie &amp; Baayen, 1998): </p>
<p style="text-align: center;"><code class="reqn">U = \frac{(\lg{N})^2}{\lg{N} - \lg{V}}</code>
</p>
</dd>
</dl>
<p>Wrapper function: <code>U.ld</code>
</p>
<dl>
<dt>
<code>"S"</code>:</dt>
<dd>
<p>Summer's index: </p>
<p style="text-align: center;"><code class="reqn">S = \frac{\lg{\lg{V}}}{\lg{\lg{N}}}</code>
</p>
</dd>
</dl>
<p>Wrapper function: <code>S.ld</code>
</p>
<dl>
<dt>
<code>"K"</code>:</dt>
<dd>
<p>Yule's <em>K</em>  (Yule, 1944, as cited in Tweedie &amp; Baayen,
1998) is calculated by: </p>
<p style="text-align: center;"><code class="reqn">K = 10^4 \times \frac{(\sum_{X=1}^{X}{{f_X}X^2}) - N}{N^2}</code>
</p>

<p>where <code class="reqn">N</code> is the number of tokens,
<code class="reqn">X</code> is a vector with the frequencies of each type, and <code class="reqn">f_X</code> is
the frequencies for each X.
</p>
<p>Wrapper function: <code>K.ld</code></p>
</dd>
<dt>
<code>"Maas"</code>:</dt>
<dd>
<p>Maas' indices (<code class="reqn">a</code>,
<code class="reqn">\lg{V_0}</code> &amp; <code class="reqn">\lg{}_{e}{V_0}</code>): </p>
<p style="text-align: center;"><code class="reqn">a^2 = \frac{\lg{N} - \lg{V}}{\lg{N}^2}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lg{V_0} = \frac{\lg{V}}{\sqrt{1 - \frac{\lg{V}}{\lg{N}}^2}}</code>
</p>

<p>Earlier versions (<code>koRpus</code> &lt; 0.04-12) reported <code class="reqn">a^2</code>,
and not <code class="reqn">a</code>. The measure was derived from a formula by M\"uller (1969, as cited in Maas, 1972).
<code class="reqn">\lg{}_{e}{V_0}</code> is equivalent to <code class="reqn">\lg{V_0}</code>,
only with <code class="reqn">e</code> as the base for the logarithms. Also calculated are <code class="reqn">a</code>, <code class="reqn">\lg{V_0}</code> (both not the same
as before) and <code class="reqn">V'</code> as measures of relative vocabulary growth while the text progresses. To calculate these measures,
the first half of the text and the full text
will be examined (see Maas, 1972, p. 67 ff. for details).
</p>
<p>Wrapper function: <code>maas</code></p>
</dd>
<dt>
<code>"MTLD"</code>:</dt>
<dd>
<p>For the <em>Measure of Textual Lexical Diversity</em> (McCarthy &amp; Jarvis,
2010) so called factors are counted. Each factor is a subsequent stream of 
tokens which ends (and is then counted as a full factor) when the TTR value falls below the given factor size. The value of
remaining partial factors is estimated by the ratio of their current TTR to the factor size threshold. The MTLD is the total number 
of tokens divided by the number of factors. The procedure is done twice,
both forward and backward for all tokens, and the mean of 
both calculations is the final MTLD result.
</p>
<p>Wrapper function: <code>MTLD</code></p>
</dd>
<dt>
<code>"MTLD-MA"</code>:</dt>
<dd>
<p>The <em>Moving-Average Measure of Textual Lexical Diversity</em> (Jarvis,
no year) combines factor counting and a moving
window similar to MATTR: After each full factor the the next one is calculated from one token after the last starting point. This is repeated
until the end of text is reached for the first time. The average of all full factor lengths is the final MTLD-MA result. Factors below the
<code>min.tokens</code> threshold are dropped.
</p>
<p>Wrapper function: <code>MTLD</code></p>
</dd>
<dt>
<code>"HD-D"</code>:</dt>
<dd>
<p>The <em>HD-D</em> value can be interpreted as the idealized version of <em>vocd-D</em> (see McCarthy &amp; Jarvis,
2007). For each type,
the probability is computed (using the hypergeometric distribution) of drawing it at least one time when drawing randomly a certain
number of tokens from the text – 42 by default. The sum of these probabilities make up the HD-D value. The sum of probabilities relative to
the drawn sample size (ATTR) is also reported.
</p>
<p>Wrapper function: <code>HDD</code></p>
</dd>
</dl>
<p>By default, if the text has to be tagged yet,
the language definition is queried by calling <code>get.kRp.env(lang=TRUE)</code> 
internally.
Or, if <code>txt</code> has already been tagged,
by default the language definition of that tagged object is read
and used. Set <code>force.lang=get.kRp.env(lang=TRUE)</code> or to any other valid value,
if you want to forcibly overwrite this
default behaviour,
and only then. See <code>kRp.POS.tags</code> for all supported languages.
</p>


<h3>Value</h3>

<p>Depending on <code>as.feature</code>,
either an object of class <code>kRp.TTR</code>,
or an object of class <code>kRp.text</code> with the added feature <code>lex_div</code> containing it.
</p>


<h3>References</h3>

<p>Covington, M.A. &amp; McFall,
J.D. (2010). Cutting the Gordian Knot: The Moving-Average Type-Token Ratio (MATTR). 
<em>Journal of Quantitative Linguistics</em>, 17(2), 94–100.
</p>
<p>Maas, H.-D.,
(1972). \"Uber den Zusammenhang zwischen Wortschatzumfang und L\"ange eines Textes. <em>Zeitschrift f\"ur 
Literaturwissenschaft und Linguistik</em>, 2(8), 73–96.
</p>
<p>McCarthy, P.M. &amp; Jarvis,
S. (2007). vocd: A theoretical and empirical evaluation. <em>Language Testing</em>, 24(4), 459–488.
</p>
<p>McCarthy, P.M. &amp; Jarvis, S. (2010). MTLD, vocd-D,
and HD-D: A validation study of sophisticated approaces to lexical diversity 
assessment. <em>Behaviour Research Methods</em>, 42(2), 381–392.
</p>
<p>Tweedie. F.J. &amp; Baayen,
R.H. (1998). How Variable May a Constant Be? Measures of Lexical Richness in Perspective.
<em>Computers and the Humanities</em>, 32(5), 323–352.
</p>


<h3>See Also</h3>

<p><code>kRp.POS.tags</code>,
<code>kRp.text</code>,
<code>kRp.TTR</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># code is only run when the english language package can be loaded
if(require("koRpus.lang.en", quietly = TRUE)){
  sample_file &lt;- file.path(
    path.package("koRpus"), "examples", "corpus", "Reality_Winner.txt"
  )
  # call lex.div() on a tokenized text
  tokenized.obj &lt;- tokenize(
    txt=sample_file,
    lang="en"
  )
  # if you call lex.div() without arguments,
  # you will get its results directly
  ld.results &lt;- lex.div(tokenized.obj, char=c())

  # there are [ and [[ methods for these objects
  ld.results[["MSTTR"]]

  # alternatively, you can also store those results as a
  # feature in the object itself
  tokenized.obj &lt;- lex.div(
    tokenized.obj,
    char=c(),
    as.feature=TRUE
  )
  # results are now part of the object
  hasFeature(tokenized.obj)
  corpusLexDiv(tokenized.obj)
} else {}
</code></pre>


</div>