<div class="container">

<table style="width: 100%;"><tr>
<td>kergp-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Gaussian Process Laboratory 
</h2>

<h3>Description</h3>

<p>Laboratory Package for Gaussian Process interpolation, regression and
simulation, with an emphasis on user-defined covariance kernels.
</p>


<h3>Details</h3>


<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> kergp</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Title: </td>
<td style="text-align: left;"> Gaussian Process Laboratory</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 0.5.7</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2024-02-05</td>
</tr>
<tr>
<td style="text-align: left;">
Author: </td>
<td style="text-align: left;"> Yves Deville, David Ginsbourger, Olivier Roustant. Contributors: Nicolas Durrande.</td>
</tr>
<tr>
<td style="text-align: left;">
Maintainer: </td>
<td style="text-align: left;"> Olivier Roustant &lt;roustant@insa-toulouse.fr&gt;</td>
</tr>
<tr>
<td style="text-align: left;">
Description: </td>
<td style="text-align: left;"> Gaussian process regression with an emphasis on kernels.
    Quantitative and qualitative inputs are accepted. Some pre-defined
    kernels are available, such as radial or tensor-sum for
    quantitative inputs, and compound symmetry, low rank, group kernel
    for qualitative inputs. The user can define new kernels and
    composite kernels through a formula mechanism. Useful methods
    include parameter estimation by maximum likelihood, simulation,
    prediction and leave-one-out validation.</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
<td style="text-align: left;">
Depends: </td>
<td style="text-align: left;"> Rcpp (&gt;= 0.10.5), methods, testthat, nloptr, lattice</td>
</tr>
<tr>
<td style="text-align: left;">
Suggests: </td>
<td style="text-align: left;"> DiceKriging, DiceDesign, inline, foreach, knitr, ggplot2, reshape2, corrplot</td>
</tr>
<tr>
<td style="text-align: left;">
Imports: </td>
<td style="text-align: left;"> MASS, numDeriv, stats4, doParallel, doFuture, utils</td>
</tr>
<tr>
<td style="text-align: left;">
LinkingTo: </td>
<td style="text-align: left;"> Rcpp</td>
</tr>
<tr>
<td style="text-align: left;">
RoxygenNote: </td>
<td style="text-align: left;"> 6.0.1</td>
</tr>
<tr>
<td style="text-align: left;">
Collate: </td>
<td style="text-align: left;"> 'CovFormulas.R'
'allGenerics.R'
'checkGrad.R'
'covComp.R'
'covMan.R'
'covQual.R'
'q1CompSymm.R'
'q1Symm.R'
'q1LowRank.R'
'covQualNested.R'
'covQualOrd.R'
'covRadial.R'
'covTS.R'
'covTP.R'
'covANOVA.R'
'covZZAll.R'
'gp.R'
'kFuns.R'
'kernelNorm.R'
'kernels1d_Call.R'
'logLikFuns.R'
'methodGLS.R'
'methodMLE.R'
'miscUtils.R'
'prinKrige.R'
'q1Diag.R'
'simulate_gp.R'
'warpFuns.R'</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<h3>Warning</h3>

<p>As a lab, <span class="pkg">kergp</span> may strongly evolve in its future life. Users
interested in stable software for the Analysis of Computer Experiments
are encouraged to use other packages such as <span class="pkg">DiceKriging</span>
instead.
</p>


<h3>Note</h3>

<p>This package was developed within the frame of the ReDice Consortium,
gathering industrial partners (CEA, EDF, IFPEN, IRSN, Renault) and
academic partners (Mines Saint-Étienne, INRIA, and the University of
Bern) around advanced methods for Computer Experiments.
</p>


<h3>Author(s)</h3>

<p>Yves Deville (Alpestat), David Ginsbourger (University of Bern),
Olivier Roustant (INSA Toulouse), with contributions from
Nicolas Durrande (Mines Saint-Étienne).
</p>
<p>Maintainer: Olivier Roustant, &lt;roustant@insa-toulouse.fr&gt;
</p>


<h3>References</h3>

<p>Nicolas Durrande, David Ginsbourger, Olivier Roustant (2012).
"Additive covariance kernels for high-dimensional gaussian process modeling".
<em>Annales de la Faculté des Sciences de Toulouse</em>, 21 (3):
481-499.
<a href="https://afst.centre-mersenne.org/item/AFST_2012_6_21_3_481_0">link</a>
</p>
<p>Nicolas Durrande, David Ginsbourger, Olivier Roustant, Laurent Carraro
(2013).
"ANOVA kernels and RKHS of zero mean functions for model-based sensitivity analysis".
<em>Journal of Multivariate Analysis</em>, 115, 57-67.
<a href="https://www.sciencedirect.com/science/article/pii/S0047259X1200214X">link</a>
</p>
<p>David Ginsbourger, Xavier Bay, Olivier Roustant, Laurent Carraro
(2012).
"Argumentwise invariant kernels for the approximation of invariant functions".
<em>Annales de la Faculté des Sciences de Toulouse</em>, 21 (3):
501-527.
<a href="https://afst.centre-mersenne.org/item/AFST_2012_6_21_3_501_0/">link</a>
</p>
<p>David Ginsbourger, Nicolas Durrande, Olivier Roustant (2013).
"Kernels and designs for modelling invariant functions: From group invariance to additivity".
<em>mODa 10 - Advances in Model-Oriented Design and
Analysis. Contributions to Statistics</em>, 107-115.
<a href="https://link.springer.com/book/10.1007/978-3-319-00218-7">link</a>
</p>
<p>Olivier Roustant, David Ginsbourger, Yves Deville (2012).
"DiceKriging, DiceOptim: Two R Packages for the Analysis of
Computer Experiments by Kriging-Based Metamodeling and Optimization".
<em>Journal of Statistical Software</em>, 51(1), 1-55.
<a href="https://doi.org/10.18637/jss.v051.i01">doi:10.18637/jss.v051.i01</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## ------------------------------------------------------------------
## Gaussian process modelling of function with invariance properties, 
## by using an argumentwise invariant kernel
## ------------------------------------------------------------------

## -- define manually an argumentwise invariant kernel --

kernFun &lt;- function(x1, x2, par) {
  h &lt;- (abs(x1) - abs(x2)) / par[1]
  S &lt;- sum(h^2)
  d2 &lt;- exp(-S)
  K &lt;- par[2] * d2
  d1 &lt;- 2 * K * S / par[1]   
  attr(K, "gradient") &lt;- c(theta = d1,  sigma2 = d2)
  return(K)
}

## ---------------------------------------------------------------
## quicker: with Rcpp; see also an example  with package inline
## in "gp" doc. file. Note that the Rcpp "sugar" fucntions are
## vectorized, so no for loops is required.
## ---------------------------------------------------------------

## Not run: 

    cppFunction('
        NumericVector cppKernFun(NumericVector x1, NumericVector x2, 
                                 NumericVector par){
        int n1 = x1.size();
        double S, d1, d2; 
        NumericVector K(1), h(n1);
        h = (abs(x1) - abs(x2)) / par[0];  // sugar function "abs"
        S = sum(h * h);                    // sugar "*" and "sum" 
        d2 = exp(-S);
        K[0] = par[1] * d2;
        d1 = 2 * K[0] * S / par[0];   
        K.attr("gradient") = NumericVector::create(Named("theta", d1),
                                                   Named("sigma2", d2));
        return K;
     }')


## End(Not run)

## ---------------------------------------------------------------
## Below: with the R-based code for the kernel namely 'kernFun'.
## You can also replace 'kernFun' by 'cppKernFun' for speed.
## ---------------------------------------------------------------

covSymGauss &lt;- covMan(kernel = kernFun,
                      hasGrad = TRUE,
                      label = "argumentwise invariant",
                      d = 2,
                      parLower = c(theta = 0.0, sigma2 = 0.0),
                      parUpper = c(theta = Inf, sigma2 = Inf),
                      parNames = c("theta", "sigma2"),
                      par = c(theta = 0.5, sigma2 = 2))

covSymGauss

## -- simulate a path from the corresponding GP --

nGrid &lt;- 24; n &lt;- nGrid^2; d &lt;- 2
xGrid &lt;- seq(from = -1, to = 1, length.out = nGrid)
Xgrid &lt;- expand.grid(x1 = xGrid, x2 = xGrid)

Kmat &lt;- covMat(object = covSymGauss, X = Xgrid,
               compGrad = FALSE, index = 1L)

library(MASS)
set.seed(1)
ygrid &lt;- mvrnorm(mu = rep(0, n), Sigma = Kmat)

## -- extract a design and the corr. response from the grid --

nDesign &lt;- 25
tab &lt;- subset(cbind(Xgrid, ygrid), x1 &gt; 0 &amp; x2 &gt; 0)
rowIndex &lt;- seq(1, nrow(tab), length = nDesign)
X &lt;- tab[rowIndex, 1:2]
y &lt;- tab[rowIndex, 3]

opar &lt;- par(mfrow = c(1, 3))
contour(x = xGrid, y = xGrid,
        z = matrix(ygrid, nrow = nGrid, ncol = nGrid), 
        nlevels = 15)
abline(h = 0, v = 0, col = "SpringGreen3")
points(x2 ~ x1, data = X, type = "p", pch = 21,
       col = "orangered", bg = "yellow", cex = 0.8)
title("GRF Simulation")


## -- Fit the Gaussian process model (trend + covariance parameters) -- 
covSymGauss
symgp &lt;- gp(formula = y ~ 1, data = data.frame(y, X),
            inputs = names(X),
            cov = covSymGauss,
            parCovIni = c(0.1, 2),
            varNoiseIni = 1.0e-8,
            varNoiseLower = 0.9e-8, varNoiseUpper = 1.1e-8)

# mind that the noise is not a symmetric kernel
# so varNoiseUpper should be chosen as small as possible.

summary(symgp)

## -- predict and compare --

predSymgp &lt;- predict(object = symgp, newdata = Xgrid, type = "UK")

contour(x = xGrid, y = xGrid,
        z = matrix(predSymgp$mean, nrow = nGrid, ncol = nGrid),
        nlevels = 15)
abline(h = 0, v = 0, col = "SpringGreen3")
points(x2 ~ x1, data = X, type = "p", pch = 21,
       col = "orangered", bg = "yellow", cex = 0.8)
title("Kriging mean")

contour(x = xGrid, y = xGrid,
        z = matrix(predSymgp$sd, nrow = nGrid, ncol = nGrid),
        nlevels = 15)
abline(h = 0, v = 0, col = "SpringGreen3")
points(x2 ~ x1, data = X, type = "p", pch = 21,
       col = "orangered", bg = "yellow", cex = 0.8)
title("Kriging s.d.")

par(opar)
</code></pre>


</div>