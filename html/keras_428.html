<div class="container">

<table style="width: 100%;"><tr>
<td>learning_rate_schedule_piecewise_constant_decay</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>A LearningRateSchedule that uses a piecewise constant decay schedule</h2>

<h3>Description</h3>

<p>A LearningRateSchedule that uses a piecewise constant decay schedule
</p>


<h3>Usage</h3>

<pre><code class="language-R">learning_rate_schedule_piecewise_constant_decay(
  boundaries,
  values,
  ...,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>boundaries</code></td>
<td>
<p>A list of <code>Tensor</code>s or R numerics with strictly increasing
entries, and with all elements having the same type as the optimizer step.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>values</code></td>
<td>
<p>A list of <code>Tensor</code>s or R numerics that specifies the
values for the intervals defined by <code>boundaries</code>. It should have one more
element than <code>boundaries</code>, and all elements should have the same type.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>A string. Optional name of the operation. Defaults to
'PiecewiseConstant'.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function returns a 1-arg callable to compute the piecewise constant
when passed the current optimizer step. This can be useful for changing the
learning rate value across different invocations of optimizer functions.
</p>
<p>Example: use a learning rate that's 1.0 for the first 100001 steps, 0.5
for the next 10000 steps, and 0.1 for any additional steps.
</p>
<div class="sourceCode R"><pre>step &lt;- tf$Variable(0, trainable=FALSE)
boundaries &lt;- as.integer(c(100000, 110000))
values &lt;- c(1.0, 0.5, 0.1)
learning_rate_fn &lt;- learning_rate_schedule_piecewise_constant_decay(
    boundaries, values)

# Later, whenever we perform an optimization step, we pass in the step.
learning_rate &lt;- learning_rate_fn(step)
</pre></div>
<p>You can pass this schedule directly into a keras Optimizer
as the <code>learning_rate</code>.
</p>


<h3>See Also</h3>


<ul><li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay">https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay</a>
</p>
</li></ul>
</div>