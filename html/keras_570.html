<div class="container">

<table style="width: 100%;"><tr>
<td>time_distributed</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>This layer wrapper allows to apply a layer to every temporal slice of an input</h2>

<h3>Description</h3>

<p>This layer wrapper allows to apply a layer to every temporal slice of an input
</p>


<h3>Usage</h3>

<pre><code class="language-R">time_distributed(object, layer, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li>
<p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li>
<p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li>
<p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>layer</code></td>
<td>
<p>a <code>tf.keras.layers.Layer</code> instance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>standard layer arguments.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Every input should be at least 3D, and the dimension of index one of the
first input will be considered to be the temporal dimension.
</p>
<p>Consider a batch of 32 video samples, where each sample is a 128x128 RGB image
with <code>channels_last</code> data format, across 10 timesteps.
The batch input shape is <code style="white-space: pre;">⁠(32, 10, 128, 128, 3)⁠</code>.
</p>
<p>You can then use <code>TimeDistributed</code> to apply the same <code>Conv2D</code> layer to each
of the 10 timesteps, independently:
</p>
<div class="sourceCode R"><pre>input &lt;- layer_input(c(10, 128, 128, 3))
conv_layer &lt;- layer_conv_2d(filters = 64, kernel_size = c(3, 3))
output &lt;- input %&gt;% time_distributed(conv_layer)
output$shape # TensorShape([None, 10, 126, 126, 64])
</pre></div>
<p>Because <code>TimeDistributed</code> applies the same instance of <code>Conv2D</code> to each of the
timestamps, the same set of weights are used at each timestamp.
</p>


<h3>See Also</h3>


<ul><li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed">https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed</a>
</p>
</li></ul>
<p>Other layer wrappers: 
<code>bidirectional()</code>
</p>


</div>