<div class="container">

<table style="width: 100%;"><tr>
<td>TensorBoard</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>TensorBoard</h2>

<h3>Description</h3>

<p>Enable visualizations for TensorBoard.
</p>


<h3>Usage</h3>

<pre><code class="language-R">TensorBoard(
  log_dir = "logs",
  histogram_freq = 0,
  write_graph = TRUE,
  write_images = FALSE,
  update_freq = "epoch",
  profile_batch = 2,
  embeddings_freq = 0,
  embeddings_metadata = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>log_dir</code></td>
<td>
<p>the path of the directory where to save the log files to be parsed by TensorBoard.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>histogram_freq</code></td>
<td>
<p>frequency (in epochs) at which to compute activation and weight histograms 
for the layers of the model. If set to 0, histograms won't be computed. Validation data (or split) 
must be specified for histogram visualizations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>write_graph</code></td>
<td>
<p>whether to visualize the graph in TensorBoard. The log file can become quite 
large when write_graph is set to TRUE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>write_images</code></td>
<td>
<p>whether to write model weights to visualize as image in TensorBoard.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>update_freq</code></td>
<td>
<p>''batch'‘ or '’epoch'‘ or integer. When using '’batch'', writes the losses and 
metrics to TensorBoard after each batch. The same applies for ''epoch'‘. If using an integer, let’s 
say '1000', the callback will write the metrics and losses to TensorBoard every 1000 samples. 
Note that writing too frequently to TensorBoard can slow down your training.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>profile_batch</code></td>
<td>
<p>Profile the batch to sample compute characteristics. By default, it will 
profile the second batch. Set profile_batch=0 to disable profiling. Must run in 
TensorFlow eager mode.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embeddings_freq</code></td>
<td>
<p>frequency (in epochs) at which embedding layers will be visualized. 
If set to 0, embeddings won't be visualized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>embeddings_metadata</code></td>
<td>
<p>a dictionary which maps layer name to a file name in which metadata 
for this embedding layer is saved. 
See the [details]( https://www.tensorflow.org/how_tos/embedding_viz/#metadata_optional) about 
metadata files format. In case if the same metadata file is used for all embedding layers, 
string can be passed.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>TensorBoard is a visualization tool provided with TensorFlow. This callback logs events for TensorBoard, including:
* Metrics summary plots
* Training graph visualization
* Activation histograms
* Sampled profiling If you have installed TensorFlow with pip, you should be able
to launch TensorBoard from the command line: “'sh
tensorboard –logdir=path_to_your_logs
“' You can find more information about TensorBoard
[here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).
</p>


<h3>Value</h3>

<p>None
</p>


<h3>Raises</h3>

<p>ValueError: If histogram_freq is set and no validation data is provided.
</p>


</div>