<div class="container">

<table style="width: 100%;"><tr>
<td>layer_dropout</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Applies Dropout to the input.</h2>

<h3>Description</h3>

<p>Dropout consists in randomly setting a fraction <code>rate</code> of input units to 0 at
each update during training time, which helps prevent overfitting.
</p>


<h3>Usage</h3>

<pre><code class="language-R">layer_dropout(
  object,
  rate,
  noise_shape = NULL,
  seed = NULL,
  input_shape = NULL,
  batch_input_shape = NULL,
  batch_size = NULL,
  name = NULL,
  trainable = NULL,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>What to compose the new <code>Layer</code> instance with. Typically a
Sequential model or a Tensor (e.g., as returned by <code>layer_input()</code>).
The return value depends on <code>object</code>. If <code>object</code> is:
</p>

<ul>
<li>
<p> missing or <code>NULL</code>, the <code>Layer</code> instance is returned.
</p>
</li>
<li>
<p> a <code>Sequential</code> model, the model with an additional layer is returned.
</p>
</li>
<li>
<p> a Tensor, the output tensor from <code>layer_instance(object)</code> is returned.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rate</code></td>
<td>
<p>float between 0 and 1. Fraction of the input units to drop.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>noise_shape</code></td>
<td>
<p>1D integer tensor representing the shape of the binary
dropout mask that will be multiplied with the input. For instance, if your
inputs have shape <code style="white-space: pre;">⁠(batch_size, timesteps, features)⁠</code> and you want the
dropout mask to be the same for all timesteps, you can use
<code>noise_shape=c(batch_size, 1, features)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>integer to use as random seed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_shape</code></td>
<td>
<p>Dimensionality of the input (integer) not including the
samples axis. This argument is required when using this layer as the first
layer in a model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batch_input_shape</code></td>
<td>
<p>Shapes, including the batch size. For instance,
<code>batch_input_shape=c(10, 32)</code> indicates that the expected input will be
batches of 10 32-dimensional vectors. <code>batch_input_shape=list(NULL, 32)</code>
indicates batches of an arbitrary number of 32-dimensional vectors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batch_size</code></td>
<td>
<p>Fixed batch size for layer</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>An optional name string for the layer. Should be unique in a
model (do not reuse the same name twice). It will be autogenerated if it
isn't provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trainable</code></td>
<td>
<p>Whether the layer weights will be updated during training.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Initial weights for layer.</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p>Other core layers: 
<code>layer_activation()</code>,
<code>layer_activity_regularization()</code>,
<code>layer_attention()</code>,
<code>layer_dense()</code>,
<code>layer_dense_features()</code>,
<code>layer_flatten()</code>,
<code>layer_input()</code>,
<code>layer_lambda()</code>,
<code>layer_masking()</code>,
<code>layer_permute()</code>,
<code>layer_repeat_vector()</code>,
<code>layer_reshape()</code>
</p>
<p>Other dropout layers: 
<code>layer_spatial_dropout_1d()</code>,
<code>layer_spatial_dropout_2d()</code>,
<code>layer_spatial_dropout_3d()</code>
</p>


</div>