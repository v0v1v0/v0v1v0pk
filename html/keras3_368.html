<div class="container">

<table style="width: 100%;"><tr>
<td>metric_r2_score</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Computes R2 score.</h2>

<h3>Description</h3>

<p>Formula:
</p>
<div class="sourceCode r"><pre>sum_squares_residuals &lt;- sum((y_true - y_pred) ** 2)
sum_squares &lt;- sum((y_true - mean(y_true)) ** 2)
R2 &lt;- 1 - sum_squares_residuals / sum_squares
</pre></div>
<p>This is also called the
<a href="https://en.wikipedia.org/wiki/Coefficient_of_determination">coefficient of determination</a>.
</p>
<p>It indicates how close the fitted regression line
is to ground-truth data.
</p>

<ul>
<li>
<p> The highest score possible is 1.0. It indicates that the predictors
perfectly accounts for variation in the target.
</p>
</li>
<li>
<p> A score of 0.0 indicates that the predictors do not
account for variation in the target.
</p>
</li>
<li>
<p> It can also be negative if the model is worse than random.
</p>
</li>
</ul>
<p>This metric can also compute the "Adjusted R2" score.
</p>


<h3>Usage</h3>

<pre><code class="language-R">metric_r2_score(
  ...,
  class_aggregation = "uniform_average",
  num_regressors = 0L,
  name = "r2_score",
  dtype = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For forward/backward compatability.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class_aggregation</code></td>
<td>
<p>Specifies how to aggregate scores corresponding to
different output classes (or target dimensions),
i.e. different dimensions on the last axis of the predictions.
Equivalent to <code>multioutput</code> argument in Scikit-Learn.
Should be one of
<code>NULL</code> (no aggregation), <code>"uniform_average"</code>,
<code>"variance_weighted_average"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_regressors</code></td>
<td>
<p>Number of independent regressors used
("Adjusted R2" score). 0 is the standard R2 score.
Defaults to <code>0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>Optional. string name of the metric instance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dtype</code></td>
<td>
<p>Optional. data type of the metric result.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a <code>Metric</code> instance is returned. The <code>Metric</code> instance can be passed
directly to <code>compile(metrics = )</code>, or used as a standalone object. See
<code>?Metric</code> for example usage.
</p>


<h3>Examples</h3>

<div class="sourceCode r"><pre>y_true &lt;- rbind(1, 4, 3)
y_pred &lt;- rbind(2, 4, 4)
metric &lt;- metric_r2_score()
metric$update_state(y_true, y_pred)
metric$result()
</pre></div>
<div class="sourceCode"><pre>## tf.Tensor(0.57142854, shape=(), dtype=float32)

</pre></div>


<h3>See Also</h3>

<p>Other regression metrics: <br><code>metric_cosine_similarity()</code> <br><code>metric_log_cosh_error()</code> <br><code>metric_mean_absolute_error()</code> <br><code>metric_mean_absolute_percentage_error()</code> <br><code>metric_mean_squared_error()</code> <br><code>metric_mean_squared_logarithmic_error()</code> <br><code>metric_root_mean_squared_error()</code> <br></p>
<p>Other metrics: <br><code>Metric()</code> <br><code>custom_metric()</code> <br><code>metric_auc()</code> <br><code>metric_binary_accuracy()</code> <br><code>metric_binary_crossentropy()</code> <br><code>metric_binary_focal_crossentropy()</code> <br><code>metric_binary_iou()</code> <br><code>metric_categorical_accuracy()</code> <br><code>metric_categorical_crossentropy()</code> <br><code>metric_categorical_focal_crossentropy()</code> <br><code>metric_categorical_hinge()</code> <br><code>metric_cosine_similarity()</code> <br><code>metric_f1_score()</code> <br><code>metric_false_negatives()</code> <br><code>metric_false_positives()</code> <br><code>metric_fbeta_score()</code> <br><code>metric_hinge()</code> <br><code>metric_huber()</code> <br><code>metric_iou()</code> <br><code>metric_kl_divergence()</code> <br><code>metric_log_cosh()</code> <br><code>metric_log_cosh_error()</code> <br><code>metric_mean()</code> <br><code>metric_mean_absolute_error()</code> <br><code>metric_mean_absolute_percentage_error()</code> <br><code>metric_mean_iou()</code> <br><code>metric_mean_squared_error()</code> <br><code>metric_mean_squared_logarithmic_error()</code> <br><code>metric_mean_wrapper()</code> <br><code>metric_one_hot_iou()</code> <br><code>metric_one_hot_mean_iou()</code> <br><code>metric_poisson()</code> <br><code>metric_precision()</code> <br><code>metric_precision_at_recall()</code> <br><code>metric_recall()</code> <br><code>metric_recall_at_precision()</code> <br><code>metric_root_mean_squared_error()</code> <br><code>metric_sensitivity_at_specificity()</code> <br><code>metric_sparse_categorical_accuracy()</code> <br><code>metric_sparse_categorical_crossentropy()</code> <br><code>metric_sparse_top_k_categorical_accuracy()</code> <br><code>metric_specificity_at_sensitivity()</code> <br><code>metric_squared_hinge()</code> <br><code>metric_sum()</code> <br><code>metric_top_k_categorical_accuracy()</code> <br><code>metric_true_negatives()</code> <br><code>metric_true_positives()</code> <br></p>


</div>