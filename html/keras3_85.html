<div class="container">

<table style="width: 100%;"><tr>
<td>callback_early_stopping</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Stop training when a monitored metric has stopped improving.</h2>

<h3>Description</h3>

<p>Assuming the goal of a training is to minimize the loss. With this, the
metric to be monitored would be <code>'loss'</code>, and mode would be <code>'min'</code>. A
<code>model$fit()</code> training loop will check at end of every epoch whether
the loss is no longer decreasing, considering the <code>min_delta</code> and
<code>patience</code> if applicable. Once it's found no longer decreasing,
<code>model$stop_training</code> is marked <code>TRUE</code> and the training terminates.
</p>
<p>The quantity to be monitored needs to be available in <code>logs</code> list.
To make it so, pass the loss or metrics at <code>model$compile()</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">callback_early_stopping(
  monitor = "val_loss",
  min_delta = 0L,
  patience = 0L,
  verbose = 0L,
  mode = "auto",
  baseline = NULL,
  restore_best_weights = FALSE,
  start_from_epoch = 0L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>monitor</code></td>
<td>
<p>Quantity to be monitored. Defaults to <code>"val_loss"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_delta</code></td>
<td>
<p>Minimum change in the monitored quantity to qualify as an
improvement, i.e. an absolute change of less than min_delta, will
count as no improvement. Defaults to <code>0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>patience</code></td>
<td>
<p>Number of epochs with no improvement after which training will
be stopped. Defaults to <code>0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1 displays
messages when the callback takes an action. Defaults to <code>0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>
<p>One of <code style="white-space: pre;">⁠{"auto", "min", "max"}⁠</code>. In <code>min</code> mode, training will stop
when the quantity monitored has stopped decreasing; in <code>"max"</code> mode
it will stop when the quantity monitored has stopped increasing; in
<code>"auto"</code> mode, the direction is automatically inferred from the name
of the monitored quantity. Defaults to <code>"auto"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>baseline</code></td>
<td>
<p>Baseline value for the monitored quantity. If not <code>NULL</code>,
training will stop if the model doesn't show improvement over the
baseline. Defaults to <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>restore_best_weights</code></td>
<td>
<p>Whether to restore model weights from the epoch
with the best value of the monitored quantity. If <code>FALSE</code>, the model
weights obtained at the last step of training are used. An epoch
will be restored regardless of the performance relative to the
<code>baseline</code>. If no epoch improves on <code>baseline</code>, training will run
for <code>patience</code> epochs and restore weights from the best epoch in
that set. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start_from_epoch</code></td>
<td>
<p>Number of epochs to wait before starting to monitor
improvement. This allows for a warm-up period in which no
improvement is expected and thus training will not be stopped.
Defaults to <code>0</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A <code>Callback</code> instance that can be passed to <code>fit.keras.src.models.model.Model()</code>.
</p>


<h3>Examples</h3>

<div class="sourceCode r"><pre>callback &lt;- callback_early_stopping(monitor = 'loss',
                                   patience = 3)
# This callback will stop the training when there is no improvement in
# the loss for three consecutive epochs.
model &lt;- keras_model_sequential() %&gt;%
  layer_dense(10)
model %&gt;% compile(optimizer = optimizer_sgd(), loss = 'mse')
history &lt;- model %&gt;% fit(x = op_ones(c(5, 20)),
                         y = op_zeros(5),
                         epochs = 10, batch_size = 1,
                         callbacks = list(callback),
                         verbose = 0)
nrow(as.data.frame(history))  # Only 4 epochs are run.
</pre></div>
<div class="sourceCode"><pre>## [1] 10

</pre></div>


<h3>See Also</h3>


<ul><li> <p><a href="https://keras.io/api/callbacks/early_stopping#earlystopping-class">https://keras.io/api/callbacks/early_stopping#earlystopping-class</a>
</p>
</li></ul>
<p>Other callbacks: <br><code>Callback()</code> <br><code>callback_backup_and_restore()</code> <br><code>callback_csv_logger()</code> <br><code>callback_lambda()</code> <br><code>callback_learning_rate_scheduler()</code> <br><code>callback_model_checkpoint()</code> <br><code>callback_reduce_lr_on_plateau()</code> <br><code>callback_remote_monitor()</code> <br><code>callback_swap_ema_weights()</code> <br><code>callback_tensorboard()</code> <br><code>callback_terminate_on_nan()</code> <br></p>


</div>