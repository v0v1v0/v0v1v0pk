<div class="container">

<table style="width: 100%;"><tr>
<td>application_resnet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Instantiates the ResNet architecture</h2>

<h3>Description</h3>

<p>Instantiates the ResNet architecture
</p>


<h3>Usage</h3>

<pre><code class="language-R">application_resnet50(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  ...
)

application_resnet101(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  ...
)

application_resnet152(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  ...
)

application_resnet50_v2(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

application_resnet101_v2(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

application_resnet152_v2(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  pooling = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  ...
)

resnet_preprocess_input(x)

resnet_v2_preprocess_input(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>include_top</code></td>
<td>
<p>Whether to include the fully-connected
layer at the top of the network. Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>One of <code>NULL</code> (random initialization),
<code>'imagenet'</code> (pre-training on ImageNet),
or the path to the weights file to be loaded. Defaults to <code>'imagenet'</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_tensor</code></td>
<td>
<p>Optional Keras tensor
(i.e. output of <code>layer_input()</code>)
to use as image input for the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_shape</code></td>
<td>
<p>optional shape list, only to be specified
if <code>include_top</code> is FALSE (otherwise the input shape
has to be <code>c(224, 224, 3)</code> (with <code>'channels_last'</code> data format)
or <code>c(3, 224, 224)</code> (with <code>'channels_first'</code> data format).
It should have exactly 3 inputs channels,
and width and height should be no smaller than 32.
E.g. <code>c(200, 200, 3)</code> would be one valid value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pooling</code></td>
<td>
<p>Optional pooling mode for feature extraction
when <code>include_top</code> is <code>FALSE</code>. Defaults to <code>NULL</code>.
</p>

<ul>
<li> <p><code>NULL</code> means that the output of the model will be
the 4D tensor output of the
last convolutional layer.
</p>
</li>
<li> <p><code>'avg'</code> means that global average pooling
will be applied to the output of the
last convolutional layer, and thus
the output of the model will be a 2D tensor.
</p>
</li>
<li> <p><code>'max'</code> means that global max pooling will
be applied.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classes</code></td>
<td>
<p>Optional number of classes to classify images into, only to be
specified if <code>include_top</code> is TRUE, and if no <code>weights</code> argument is
specified. Defaults to 1000 (number of ImageNet classes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For backwards and forwards compatibility</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classifier_activation</code></td>
<td>
<p>A string or callable. The activation function to
use on the "top" layer. Ignored unless <code>include_top = TRUE</code>. Set
<code>classifier_activation = NULL</code> to return the logits of the "top" layer.
Defaults to <code>'softmax'</code>. When loading pretrained weights,
<code>classifier_activation</code> can only be <code>NULL</code> or <code>"softmax"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>preprocess_input()</code> takes an array or floating point tensor, 3D or
4D with 3 color channels, with values in the range <code style="white-space: pre;">⁠[0, 255]⁠</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Reference:
</p>

<ul><li> <p><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a> (CVPR 2015)
</p>
</li></ul>
<p>For image classification use cases, see
<a href="https://keras.io/api/applications/#usage-examples-for-image-classification-models">this page for detailed examples</a>.
</p>
<p>For transfer learning use cases, make sure to read the
<a href="https://keras.io/guides/transfer_learning/">guide to transfer learning &amp; fine-tuning</a>.
</p>
<p>Note: each Keras Application expects a specific kind of input preprocessing.
For ResNet, call <code>tf.keras.applications.resnet.preprocess_input</code> on your
inputs before passing them to the model.
<code>resnet.preprocess_input</code> will convert the input images from RGB to BGR,
then will zero-center each color channel with respect to the ImageNet dataset,
without scaling.
</p>


<h3>See Also</h3>


<ul>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet101">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet101</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet152">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/ResNet152</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet101V2">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet101V2</a>
</p>
</li>
<li> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet152V2">https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet152V2</a>
</p>
</li>
<li> <p><a href="https://keras.io/api/applications/">https://keras.io/api/applications/</a>
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
library(keras)

# instantiate the model
model &lt;- application_resnet50(weights = 'imagenet')

# load the image
img_path &lt;- "elephant.jpg"
img &lt;- image_load(img_path, target_size = c(224,224))
x &lt;- image_to_array(img)

# ensure we have a 4d tensor with single element in the batch dimension,
# the preprocess the input for prediction using resnet50
x &lt;- array_reshape(x, c(1, dim(x)))
x &lt;- imagenet_preprocess_input(x)

# make predictions then decode and print them
preds &lt;- model %&gt;% predict(x)
imagenet_decode_predictions(preds, top = 3)[[1]]

## End(Not run)
</code></pre>


</div>