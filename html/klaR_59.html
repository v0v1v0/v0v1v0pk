<div class="container">

<table style="width: 100%;"><tr>
<td>predict.locpvs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>predict method for locpvs objects</h2>

<h3>Description</h3>

<p>Prediction of class membership and posterior probabilities in local models using pairwise variable selection.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'locpvs'
predict(object,newdata, quick = FALSE, return.subclass.prediction = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>an object of class ‘<code>locpvs</code>’, as that created by the function “<code>locpvs</code>”</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>
<p>a data frame or matrix containing new data. If not given the same datas as used for training the ‘<code>pvs</code>’-model are used. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quick</code></td>
<td>
<p>indicator (logical), whether a quick, but less accurate computation of posterior probabalities should be used or not.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return.subclass.prediction</code></td>
<td>
<p>indicator (logical), whether the returned object includes posterior probabilities for each date in each subclass </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments are passed to underlying <code>predict</code> calls.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Posterior probabilities are predicted as if object is a standard ‘<code>pvs</code>’-model with the subclasses as classes. Then the posterior probabalities are summed over all subclasses for each class. The class with the highest value becomes the prediction.
</p>
<p>If “<code>quick=FALSE</code>” the posterior probabilites for each case are computed using the pairwise coupling algorithm presented by Hastie, Tibshirani (1998). If “<code>quick=FALSE</code>” a much quicker solution is used, which leads to less accurate posterior probabalities. In almost all cases it doesn't has a negative effect on the classification result.
</p>


<h3>Value</h3>

<p>a list with components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>class</code></td>
<td>
<p>the predicted (upper) classes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>posterior</code></td>
<td>
<p>posterior probabilities for the (upper) classes</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subclass.posteriors</code></td>
<td>
<p>(only if “<code>return.subclass.prediction=TRUE</code>”. A matrix containing posterior probabalities for the subclasses. </p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Gero Szepannek, <a href="mailto:szepannek@statistik.tu-dortmund.de">szepannek@statistik.tu-dortmund.de</a>, Christian Neumann</p>


<h3>References</h3>

<p>Szepannek, G. and Weihs, C. (2006) Local Modelling in Classification on Different Feature Subspaces. 
In <em>Advances in Data Mining.</em>, ed Perner, P., LNAI 4065, pp. 226-234. Springer, Heidelberg.</p>


<h3>See Also</h3>

<p><code>locpvs</code> for learning ‘<code>locpvs</code>’-models and examples for applying this predict method, <code>pvs</code> for pairwise variable selection without modeling subclasses, <code>predict.pvs</code> for predicting ‘<code>pvs</code>’-models 
</p>


</div>