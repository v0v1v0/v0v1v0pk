<div class="container">

<table style="width: 100%;"><tr>
<td>train.kknn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Training kknn</h2>

<h3>Description</h3>

<p>Training of kknn method via leave-one-out (<code>train.kknn</code>) or k-fold (<code>cv.kknn</code>) crossvalidation. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">train.kknn(formula, data, kmax = 11, ks = NULL, distance = 2, kernel = "optimal",
	ykernel = NULL, scale = TRUE, contrasts = c('unordered' = "contr.dummy",
	ordered = "contr.ordinal"), ...)
cv.kknn(formula, data, kcv = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>A formula object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Matrix or data frame. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kmax</code></td>
<td>
<p>Maximum number of k, if <code>ks</code> is not specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ks</code></td>
<td>
<p>A vector specifying values of k. If not null, this takes precedence over <code>kmax</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distance</code></td>
<td>
<p>Parameter of Minkowski distance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>Kernel to use. Possible choices are "rectangular" 
(which is standard unweighted knn), "triangular", "epanechnikov" 
(or beta(2,2)), "biweight" (or beta(3,3)), "triweight" (or beta(4,4)), 
"cos", "inv", "gaussian" and "optimal".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ykernel</code></td>
<td>
<p>Window width of an y-kernel, especially for prediction 
of ordinal classes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>logical, scale variable to have equal sd.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contrasts</code></td>
<td>
<p>A vector containing the 'unordered' and 'ordered' contrasts to use.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kcv</code></td>
<td>
<p>Number of partitions for k-fold cross validation. </p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>train.kknn</code> performs leave-one-out crossvalidation 
and is computatioanlly very efficient. <code>cv.kknn</code> performs k-fold crossvalidation and is generally slower and does not yet contain the test of different models yet.</p>


<h3>Value</h3>

<p><code>train.kknn</code> returns a list-object of class <code>train.kknn</code> including
the components. 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>MISCLASS</code></td>
<td>
<p>Matrix of misclassification errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MEAN.ABS</code></td>
<td>
<p>Matrix of mean absolute errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MEAN.SQU</code></td>
<td>
<p>Matrix of mean squared errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>List of predictions for all combinations of kernel and k.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best.parameters</code></td>
<td>
<p>List containing the best parameter value for kernel and k.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>response</code></td>
<td>
<p>Type of response variable, one of <em>continuous</em>, <em>nominal</em> or <em>ordinal</em>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distance</code></td>
<td>
<p>Parameter of Minkowski distance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>The matched call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>terms</code></td>
<td>
<p>The 'terms' object used.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p> Klaus P. Schliep <a href="mailto:klaus.schliep@gmail.com">klaus.schliep@gmail.com</a> </p>


<h3>References</h3>

<p>Hechenbichler K. and Schliep K.P. (2004)  <em>Weighted k-Nearest-Neighbor Techniques
and Ordinal Classification</em>, Discussion Paper 399, SFB 386, Ludwig-Maximilians University Munich
(<a href="http://www.stat.uni-muenchen.de/sfb386/papers/dsp/paper399.ps">http://www.stat.uni-muenchen.de/sfb386/papers/dsp/paper399.ps</a>)
</p>
<p>Hechenbichler K. (2005)  <em>Ensemble-Techniken und ordinale Klassifikation</em>, PhD-thesis
</p>
<p>Samworth, R.J. (2012) <em>Optimal weighted nearest neighbour classifiers.</em> Annals of Statistics, 40, 2733-2763.
(avaialble from <a href="http://www.statslab.cam.ac.uk/~rjs57/Research.html">http://www.statslab.cam.ac.uk/~rjs57/Research.html</a>) 
</p>


<h3>See Also</h3>

 <p><code>kknn</code> and <code>simulation</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">library(kknn)
## Not run: 
data(miete)
(train.con &lt;- train.kknn(nmqm ~ wfl + bjkat + zh, data = miete, 
	kmax = 25, kernel = c("rectangular", "triangular", "epanechnikov",
	"gaussian", "rank", "optimal")))
plot(train.con)
(train.ord &lt;- train.kknn(wflkat ~ nm + bjkat + zh, miete, kmax = 25,
 	kernel = c("rectangular", "triangular", "epanechnikov", "gaussian", 
 	"rank", "optimal")))
plot(train.ord)
(train.nom &lt;- train.kknn(zh ~ wfl + bjkat + nmqm, miete, kmax = 25, 
	kernel = c("rectangular", "triangular", "epanechnikov", "gaussian", 
	"rank", "optimal")))
plot(train.nom)

## End(Not run)
data(glass)
glass &lt;- glass[,-1]
(fit.glass1 &lt;- train.kknn(Type ~ ., glass, kmax = 15, kernel = 
	c("triangular", "rectangular", "epanechnikov", "optimal"), distance = 1))
(fit.glass2 &lt;- train.kknn(Type ~ ., glass, kmax = 15, kernel = 
	c("triangular", "rectangular", "epanechnikov", "optimal"), distance = 2))
plot(fit.glass1)
plot(fit.glass2)

</code></pre>


</div>