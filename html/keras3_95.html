<div class="container">

<table style="width: 100%;"><tr>
<td>clone_model</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Clone a Functional or Sequential <code>Model</code> instance.</h2>

<h3>Description</h3>

<p>Model cloning is similar to calling a model on new inputs,
except that it creates new layers (and thus new weights) instead
of sharing the weights of the existing layers.
</p>
<p>Note that
<code>clone_model()</code> will not preserve the uniqueness of shared objects within the
model (e.g. a single variable attached to two distinct layers will be
restored as two separate variables).
</p>


<h3>Usage</h3>

<pre><code class="language-R">clone_model(
  model,
  input_tensors = NULL,
  clone_function = NULL,
  call_function = NULL,
  recursive = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>Instance of <code>Model</code>
(could be a Functional model or a Sequential model).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_tensors</code></td>
<td>
<p>Optional list of input tensors
to build the model upon. If not provided,
new <code>keras_input()</code> objects will be created.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clone_function</code></td>
<td>
<p>Callable with signature <code style="white-space: pre;">⁠function(layer)⁠</code>
to be used to clone each layer in the target
model (except <code>Input</code> instances). It takes as argument the
layer instance to be cloned, and returns the corresponding layer
instance to be used in the model copy. If unspecified, this callable
defaults to the following serialization/deserialization function:
<code>function(layer) layer$`__class__`$from_config(layer$get_config())</code>.
By passing a custom callable, you can customize your copy of the
model, e.g. by wrapping certain layers of interest (you might want
to replace all <code>LSTM</code> instances with equivalent
<code>Bidirectional(LSTM(...))</code> instances, for example).
Defaults to <code>NULL</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call_function</code></td>
<td>
<p>Callable with signature
<code style="white-space: pre;">⁠function(layer, ...)⁠</code> to be used to call each
cloned layer and a set of inputs. It takes the layer instance,
and the call arguments, and returns the
call outputs. If unspecified, this callable defaults to
the regular <code>call()</code> method:
<code>function(layer, ...) do.call(layer, list(...))</code>.
By passing a custom callable, you can insert new layers before or
after a given layer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>recursive</code></td>
<td>
<p>Note, This argument can only be used with
Functional models.
Boolean. Whether to recursively clone any Sequential
or Functional models encountered in the original
Sequential/Functional model. If <code>FALSE</code>,
then inner models are cloned by calling <code>clone_function()</code>.
If <code>TRUE</code>, then inner models are cloned by calling <code>clone_model()</code>
with the same <code>clone_function</code>, <code>call_function</code>, and <code>recursive</code>
arguments. Note that in this case, <code>call_function</code>
will not be propagated to any Sequential model
(since it is not applicable to Sequential models).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For forward/backward compatability.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An instance of <code>Model</code> reproducing the behavior
of the original model, on top of new inputs tensors,
using newly instantiated weights. The cloned model may behave
differently from the original model if a custom <code>clone_function</code>
or <code>call_function</code> modifies a layer or layer call.
</p>


<h3>Examples</h3>

<div class="sourceCode r"><pre># Create a test Sequential model.
model &lt;- keras_model_sequential(input_shape = c(728)) |&gt;
  layer_dense(32, activation = 'relu') |&gt;
  layer_dense(1, activation = 'sigmoid')

# Create a copy of the test model (with freshly initialized weights).
new_model &lt;- clone_model(model)
</pre></div>
<p>Using a <code>clone_function</code> to make a model deterministic by setting the
random seed everywhere:
</p>
<div class="sourceCode r"><pre>clone_function &lt;- function(layer) {
  config &lt;- layer$get_config()
  if ("seed" %in% names(config))
    config$seed &lt;- 1337L
  layer$`__class__`$from_config(config)
}

new_model &lt;- clone_model(model, clone_function = clone_function)
</pre></div>
<p>Using a <code>call_function</code> to add a <code>Dropout</code> layer after each <code>Dense</code> layer
(without recreating new layers):
</p>
<div class="sourceCode r"><pre>call_function &lt;- function(layer, ...) {
  out &lt;- layer(...)
  if (inherits(layer, keras$layers$Dense))
    out &lt;- out |&gt; layer_dropout(0.5)
  out
}

inputs &lt;- keras_input(c(728))
outputs &lt;- inputs |&gt;
  layer_dense(32, activation = 'relu') |&gt;
  layer_dense(1, activation = 'sigmoid')
model &lt;- keras_model(inputs, outputs)

new_model &lt;- clone_model(
  model,
  clone_function = function(x) x, # Reuse the same layers.
  call_function = call_function,
)
new_model
</pre></div>
<div class="sourceCode"><pre>## Model: "functional_4"
## +-----------------------------------+--------------------------+---------------+
## | Layer (type)                      | Output Shape             |       Param # |
## +===================================+==========================+===============+
## | keras_tensor_8 (InputLayer)       | (None, 728)              |             0 |
## +-----------------------------------+--------------------------+---------------+
## | dense_2 (Dense)                   | (None, 32)               |        23,328 |
## +-----------------------------------+--------------------------+---------------+
## | dropout (Dropout)                 | (None, 32)               |             0 |
## +-----------------------------------+--------------------------+---------------+
## | dense_3 (Dense)                   | (None, 1)                |            33 |
## +-----------------------------------+--------------------------+---------------+
## | dropout_1 (Dropout)               | (None, 1)                |             0 |
## +-----------------------------------+--------------------------+---------------+
##  Total params: 23,361 (91.25 KB)
##  Trainable params: 23,361 (91.25 KB)
##  Non-trainable params: 0 (0.00 B)

</pre></div>
<p>Note that subclassed models cannot be cloned by default,
since their internal layer structure is not known.
To achieve equivalent functionality
as <code>clone_model</code> in the case of a subclassed model, simply make sure
that the model class implements <code>get_config()</code>
(and optionally <code>from_config()</code>), and call:
</p>
<div class="sourceCode r"><pre>new_model &lt;- model$`__class__`$from_config(model$get_config())
</pre></div>
<p>In the case of a subclassed model, you cannot using a custom
<code>clone_function</code>.
</p>


</div>