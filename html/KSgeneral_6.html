<div class="container">

<table style="width: 100%;"><tr>
<td>disc_ks_test</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Computes the p-value for a one-sample two-sided Kolmogorov-Smirnov test when the cdf under the null hypothesis is purely discrete
</h2>

<h3>Description</h3>

<p>Computes the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, when <code class="reqn">F(x)</code> is purely discrete, using the Exact-KS-FFT method expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using FFT (see Dimitrova, Kaishev, Tan (2020)).
</p>


<h3>Usage</h3>

<pre><code class="language-R">disc_ks_test(x, y, ..., exact = NULL, tol = 1e-08, sim.size = 1e+06, num.sim = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>a numeric vector of data sample values <code class="reqn">\{x_{1}, ..., x_{n}\}</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>a pre-specified discrete cdf, <code class="reqn">F(x)</code>, under the null hypothesis.
Note that <code>y</code> should be a step function within the class: <code>stepfun</code>, of which <code>ecdf</code> is a subclass!
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>values of the parameters of the cdf, <code class="reqn">F(x)</code>, specified (as a character string) by <code>y</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exact</code></td>
<td>

<p>logical variable specifying whether one wants to compute exact p-value <code class="reqn">P(D_{n} \ge d_{n})</code> using the Exact-KS-FFT method, in which case <code>exact = TRUE</code> or wants to compute an approximate p-value <code class="reqn">P(D_{n} \ge d_{n})</code> using the simulation-based algorithm of Wood and Altavela (1978), in which case <code>exact = FALSE</code>. When <code>exact = NULL</code> and <code>n &lt;= 100000</code>, the exact <code class="reqn">P(D_{n} \ge d_{n})</code> will be computed using the Exact-KS-FFT method. Otherwise, the asymptotic complementary cdf is computed based on Wood and Altavela (1978). By default, <code>exact = NULL</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>

<p>the value of <code class="reqn">\epsilon</code> that is used to compute the values of <code class="reqn">A_{i}</code> and <code class="reqn">B_{i}</code>, <code class="reqn">i = 1, ..., n</code>, as detailed in Step 1 of Section 2.1 in Dimitrova, Kaishev and Tan (2020) (see also (ii) in the Procedure Exact-KS-FFT therein). By default, <code>tol = 1e-08</code>. Note that a value of <code>NA</code> or <code>0</code> will lead to an error!
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sim.size</code></td>
<td>

<p>the required number of simulated trajectories in order to produce one Monte Carlo estimate (one MC run) of the asymptotic p-value using the algorithm of Wood and Altavela (1978). By default, <code>sim.size = 1e+06</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.sim</code></td>
<td>

<p>the number of MC runs, each producing one estimate (based on <code>sim.size</code> number of trajectories), which are then averaged in order to produce the final estimate for the asymptotic p-value. This is done in order to reduce the variance of the final estimate. By default, <code>num.sim = 10</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Given a random sample <code class="reqn">\{X_{1}, ..., X_{n}\}</code> of size <code>n</code> with an empirical cdf <code class="reqn">F_{n}(x)</code>, the two-sided Kolmogorov-Smirnov goodness-of-fit statistic is defined as <code class="reqn">D_{n} = \sup | F_{n}(x) - F(x) | </code>, where <code class="reqn">F(x)</code> is the cdf of a prespecified theoretical distribution under the null hypothesis <code class="reqn">H_{0}</code>, that <code class="reqn">\{X_{1}, ..., X_{n}\}</code> comes from <code class="reqn">F(x)</code>.
</p>
<p>The function <code>disc_ks_test</code> implements the Exact-KS-FFT method expressing the p-value as a double-boundary non-crossing probability for a homogeneous Poisson process, which is then efficiently computed using FFT (see Dimitrova, Kaishev, Tan (2020)).
It represents an accurate and fast (run time <code class="reqn">O(n^{2}log(n))</code>) alternative to the function <code>ks.test</code> from the package <span class="pkg">dgof</span>, which computes a p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, where <code class="reqn">d_{n}</code> is the value of the KS test statistic computed based on a user provided data sample <code class="reqn">\{x_{1}, ..., x_{n}\}</code>, assuming <code class="reqn">F(x)</code> is purely discrete.
</p>
<p>In the function <code>ks.test</code>, the p-value for a one-sample two-sided KS test is calculated by combining the approaches of Gleser (1985) and Niederhausen (1981). However, the function <code>ks.test</code> due to Arnold and Emerson (2011) only provides exact p-values for <code>n</code> <code class="reqn">\le</code> 30, since as noted by the authors, when <code>n</code> is large, numerical instabilities may occur. In the latter case, <code>ks.test</code> uses simulation to approximate p-values, which may be rather slow and inaccurate (see Table 6 of Dimitrova, Kaishev, Tan (2020)).
</p>
<p>Thus, making use of the Exact-KS-FFT method, the function <code>disc_ks_test</code> provides an exact and highly computationally efficient (alternative) way of computing the p-value <code class="reqn">P(D_{n} \ge d_{n})</code>, when <code class="reqn">F(x)</code> is purely discrete.
</p>
<p>Lastly, incorporated into the function <code>disc_ks_test</code> is the MC simulation-based method of Wood and Altavela (1978) for estimating the asymptotic p-value of <code class="reqn">D_{n}</code>. The latter method is the default method behind <code>disc_ks_test</code> when the sample size <code>n</code> is <code>n</code> <code class="reqn">\ge</code> 100000.
</p>


<h3>Value</h3>

<p>A list with class "htest" containing the following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>statistic </code></td>
<td>
<p>the value of the statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value </code></td>
<td>
<p>the p-value of the test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alternative </code></td>
<td>
<p>"two-sided".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name </code></td>
<td>
<p>a character string giving the name of the data.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Arnold T.A., Emerson J.W. (2011). "Nonparametric Goodness-of-Fit Tests for Discrete Null Distributions". The R Journal, <b>3</b>(2), 34-39.
</p>
<p>Dimitrina S. Dimitrova, Vladimir K. Kaishev, Senren Tan. (2020) "Computing the Kolmogorov-Smirnov Distribution When the Underlying CDF is Purely Discrete, Mixed or Continuous". Journal of Statistical Software, <b>95</b>(10): 1-42. doi:10.18637/jss.v095.i10.
</p>
<p>Gleser L.J. (1985). "Exact Power of Goodness-of-Fit Tests of Kolmogorov Type for Discontinuous Distributions". Journal of the American Statistical Association, <b>80</b>(392), 954-958.
</p>
<p>Niederhausen H. (1981). "Sheffer Polynomials for Computing Exact Kolmogorov-Smirnov and Renyi Type Distributions". The Annals of Statistics, 58-64.
</p>
<p>Wood C.L., Altavela M.M. (1978). "Large-Sample Results for Kolmogorov-Smirnov Statistics for Discrete Distributions". Biometrika, <b>65</b>(1), 235-239.
</p>


<h3>See Also</h3>

<p><code>ks.test</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Comparison of results obtained from dgof::ks.test
# and KSgeneral::disc_ks_test, when F(x) follows the discrete
# Uniform[1, 10] distribution as in Example 3.5 of
# Dimitrova, Kaishev, Tan (2020)

# When the sample size is larger than 100, the
# function dgof::ks.test will be numerically
# unstable

x3 &lt;- sample(1:10, 25, replace = TRUE)
KSgeneral::disc_ks_test(x3, ecdf(1:10), exact = TRUE)
dgof::ks.test(x3, ecdf(1:10), exact = TRUE)
KSgeneral::disc_ks_test(x3, ecdf(1:10), exact = TRUE)$p -
          dgof::ks.test(x3, ecdf(1:10), exact = TRUE)$p

x4 &lt;- sample(1:10, 500, replace = TRUE)
KSgeneral::disc_ks_test(x4, ecdf(1:10), exact = TRUE)
dgof::ks.test(x4, ecdf(1:10), exact = TRUE)
KSgeneral::disc_ks_test(x4, ecdf(1:10), exact = TRUE)$p -
          dgof::ks.test(x4, ecdf(1:10), exact = TRUE)$p

# Using stepfun() to specify the same discrete distribution as defined by ecdf():

steps &lt;- stepfun(1:10, cumsum(c(0, rep(0.1, 10))))
KSgeneral::disc_ks_test(x3, steps, exact = TRUE)

</code></pre>


</div>